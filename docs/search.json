[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"people gets turn statistics; reality Stats allow human development, use stats, without even knowing, almost every life choice make.theory, Statistics requires mathematical background, practice, stats simply creating knowledge/information observations/data.Let provide example find pretty cool.late 1879, just going holidays, Louis Pasteur told one assistants inject chickens fresh culture Cholera part experiment find vaccine.way, thanks guy, Pasteur, milk breakfast morning; one discovered Pasteurization process sterilize food without damaging flavors, allowed store highly perishable foods long time.Moving story… presume Pasteur’s assistant things day, may just wanted go holidays; forgot inoculate chickens, left bacterial culture outside.month later, upon returning holidays, assistant injected chickens old culture, nothing happened chickens.moment, put position Pasteur think done?.Sad admit, probably upset. interpreted action careless, plus psychological torture poor chickens staring month lethal doses bacteria.addition, sadly, probably interpreted results nothing happening chickens, simply bacterial culture got ruined outside long. restarted experiment new chickens new bacterial cultures.thought result “failed” experiment?. Take moment think.\nFigure 0.1: Pasteur\nIntriguingly, Pasteur told assistant inoculate chickens fresh bacterial cultures observed chickens got mildly sick succumb deadly bacteria. chickens immune bacteria.Essentially, Pasteour just made one major discoveries humanity: vaccine.discovery came called Attenuated Vaccine, virulence bacteria reduced oxygen allowing body fight bug.method saved millions chickens, people well. method used many deadly diseases, put Pasteur history books.Nothing known happened lab assistant.several things made case successful story. Obviously, Pasteur knew well get even smallest hints people interpreted failure, also methodic knew stats well. able gather knowledge observations. applied statistics well.game-changer example use statistics. mentioned earlier, stats used almost time, almost every decision made.Even simple things like clothes wearing right now choice made likely based stats.morning cold, probably choose wear jacked. Feeling cold taking data use analytically make decision wear jacket.aim class give basic ) methodological, ii) analytical, iii) data visualization skills stats.nutshell, want learn identify question, define protocol respond , analyze data collected, display results convincingly.","code":""},{"path":"introduction.html","id":"book-data-collection","chapter":"Introduction","heading":"Book data collection","text":"introduced numerous “non-belonging” letters throughout book. tell much letters belong. now letters called tokens.need collect tokens move along create database tokens. Collect data meticulously can.three motivations exercise.Firsts, make realize reality science. times, data clear, may find letter clearly belong .times, however, wonder letter error token. real life, nature clarify things . data collect right, go become part noise data.Second, end book, analyze data collected statistical test.Finally, want ensure read book much detail.Good luck token hunting.goes first token: aBy way, please stress collection tokens, come move along.","code":""},{"path":"introduction.html","id":"what-is-r","chapter":"Introduction","heading":"What is R?","text":"second goal course become familiar use R; may use Microsoft Excel sporadically.R like Rolls-Royce, king among softwares; revolutionary free program come become popular many disciplines; several reasons :importantly, free.nature open-source, thousands people around world contributed work form “packages”, allowed R increase scope, used almost anything statistical analysis, figures, movies, animations, videos, name .R Packages like phone apps download install phone use diversity things. Currently, 16,000 R-Packages, providing different tools almost anything.also large group users willing help face struggle. Oh, help free, well.Onlined platforms Stackoverflow blogs people helping issue R. Every question nicely cataloged, times may even alternative solutions problem.reality many millions people using R, chances problem, someone else probably problem , thus, solution likely already ready web.Finally, R can handle load. R, can run codes small run calculator large ones run super computers.matter professional path take life, use R.","code":""},{"path":"introduction.html","id":"do-not-dispair-please","chapter":"Introduction","heading":"Do not dispair, please","text":"R new . addition, found years teaching class large disparity among students prior exposure mathematical concepts, let alone coding. let’s realistic, learning R hard initially, , can .part, created online resource course detailed possible can get simply following steps. also included comments section bottom section, can communicate problem get feedback everyone.penalized asking question forum, may get rewarded answer correctly. penalized answering wrong. please let’s use discussion platform.please nice asking responding questions.get frustrated figuring something, two likely paths.One getting upset, uses half brain power half trying figure solution. path cool , entire brain power working solving problem. pathway makes sense?Finding solutions R problems key skill save hours labor, dedicated section find answers sea information web.Using Nathaniel Phillips word’s R Bookdown YaRrr! Pirate’s Guide R, R much like relationship. Like relationships, two major truths R programming:nothing frustrating code workThere nothing frustrating code workThere nothing satisfying code work!nothing satisfying code work!\nFigure 0.2: R like love relationship, Nathaniel Phillips\ntimes, run error error pound fists table screaming: “ISN’T CODE WORKING?!?!? must something wrong stupid software!!!” spend hours trying find bug code, find - frustratingly enough, extra space missed comma somewhere. Taken Nathaniel Phillips.go “nightmare” R, alone. went . tell , go away. proficient become, likely push boundaries possible known, certainly many times codes work. Think Pasteur, moments.steep learning curve, get keep cool, desperate. face roadblock; first, calm . , Google help .Please think : next year , hopefully, working company /grad school. moment, really need mastered capacity solve problems . Gaining independence give huge advantage.important figure best method find solutions R problems. Learning find solutions problems web part learning class, later exercises .done best looking solution problem, failed, , reach . happy help . want know hand best figure solution problem .Learning R become increasingly easier time. become proficient, start making sophisticated things R. comes things, R, sky limit.\nR become nicer time, Nathaniel Phillips\nFigure 0.3: R become nicer time, Nathaniel Phillips\nwant caution, however, course requires “good quality” “time commitment”.Note double intonation “good quality” “time commitment”.Please study times distracted. emphasize enough spending lots time studying studying well.codes become longer complex, mind eventually need focus conceptualize entire code. can tell certainty much harder, border line impossible, visualize large codes, distracted.Learning R done one hour exam. take much time can study. practice come perfection.Finally, worth mentioning knowing use R skill want learn. classes take University, one want put CV. Saying know R desirable skill job end .z","code":""},{"path":"class-expectations.html","id":"class-expectations","chapter":"Class expectations","heading":"Class expectations","text":"inherently difficult class, given mathematical nature content disparity skills among students. However, course set assume basic prior understanding programs, major mathematical skills.introductory, advanced, class stats. general, expect end class can design experiment, collect, handle analyze data; oh, professional plots. Primarily using R.Next, outlined specific expectations. can already meet expectations, class basic , probably benefit advanced course. , class , help meet standards.","code":""},{"path":"class-expectations.html","id":"scientific-method","chapter":"Class expectations","heading":"1. Scientific method","text":"expected faced problem, can design robust experiment solve identify given problem.includes identifying dependent independent variables,provide proper treatments controls, collect data, know replication, independence, etc.","code":""},{"path":"class-expectations.html","id":"data-manipulation","chapter":"Class expectations","heading":"2. Data manipulation","text":"know basic methods load create databases R, plus basic functions manipulate data, like sorting, filtering, merging, pivoting, etc.","code":""},{"path":"class-expectations.html","id":"data-display","chapter":"Class expectations","heading":"3. Data display","text":"know publication quality plots. Basic plots like scatterplot, histogram, boxplot, maps.","code":""},{"path":"class-expectations.html","id":"descriptive-stats","chapter":"Class expectations","heading":"4. Descriptive stats","text":"know calculate basic metrics central tendency variability data.","code":""},{"path":"class-expectations.html","id":"correlation","chapter":"Class expectations","heading":"5. Correlation","text":"know run interpret results correlation analysis.","code":""},{"path":"class-expectations.html","id":"regression","chapter":"Class expectations","heading":"6. Regression","text":"know run interpret results regression analysis.","code":""},{"path":"class-expectations.html","id":"hyphothesis-testing","chapter":"Class expectations","heading":"7. Hyphothesis testing","text":"know : State hypotheses,","code":""},{"path":"class-expectations.html","id":"one-sample-test","chapter":"Class expectations","heading":"8. One sample test","text":"Run one sample test using Z-Score T-score,","code":""},{"path":"class-expectations.html","id":"two-sample-test","chapter":"Class expectations","heading":"9. Two sample test","text":"Run two sample test using Z-Score T-score,","code":""},{"path":"class-expectations.html","id":"more-than-two-sample-test","chapter":"Class expectations","heading":"10. More than two sample test","text":"Run ANOVA,Run post-hoc test,Test assumptions (outliers, normality, homogeneity variances).","code":""},{"path":"class-expectations.html","id":"grading","chapter":"Class expectations","heading":"Grading","text":"Grading class subjective matter. end class, able look back work assess number expectations meet satisfaction.satisfaction, mean able answer question relates 10 expectations , well apply learned statistical method different versions related problems.number expectations satisfy proportional expected grade.give extra reward students followed instructions start class, collected data methodically analyzed end, final essay adds 10% grade.deliver final essay addition meeting 10 expectations earn +. table indicates expected grade given number expectations:\nFigure 0.4: Grading expectations\nmake self-assessment, suggest review final homework chapter. feel confident defend work , simply copying pasting, knowing line code , assume dominate satisfaction given expectation.Please formulate questions expectation, answer self. question, may ask confirm meet expectation, simple “tell know topic”?. case, can formulate questions answer .end class, ask grade think deserve, topics want ask . simply ask random questions topics claim know confirm requested grade legit, grade.Depending time left class, able take assessment test several times.much worry grade, worry ensure walk away class knowing planned learn start. want study try many times can get best grade deserve.disclaim , teaching philosophy, grading among ultimate expectations rather knowing learned content class.confident 10 years time remember grade got class, may well remember methods learned, may even dream job skills class helping , hopefully remember professor Mora challenged best .","code":""},{"path":"the-scientific-method.html","id":"the-scientific-method","chapter":"1 The scientific method","heading":"1 The scientific method","text":"\nFigure 1.1: Knowledge ignorance\nscientific method approach robust knowledge acquired. approach can applied diverse situations, science.probably learned scientific method third fourth grade, like refresh general concepts commonly see students formulating experiments clear question, analyzes whose results answer question, etc.Knowing exact protocol go question answer avoid wasting time call rabbit holes; basically, lot effort put work help ultimate goal proposedd.","code":""},{"path":"the-scientific-method.html","id":"the-problem","chapter":"1 The scientific method","heading":"The problem","text":"first step scientific method observe problem. However, defining problem trivial may think.complexity process first time observed problem time specifically define problem want solve scientific method.Let’s use real case example.Let’s assume just joined one many organizations Hawaii interested land restoration.\nFigure 1.2: Carbon Neutrality Project\nOne first observations make speed cut trees much faster speed plant trees. matter fact, Honolulu, cut 15,000 trees year, 4,000 thousand trees planted.\nFigure 1.3: Invasive Guava forrest Hawaii\nsecond observation likely make loosing land many introduced species like guava, halekoa, albizia, several grazes, etc. species aggressive secluding/pushing brick native species.observations mind, first likely question make approach land restoration efficient?","code":""},{"path":"the-scientific-method.html","id":"narrow-the-problem","chapter":"1 The scientific method","heading":"Narrow the problem","text":"simple question make restoration efficient can take tens different pathways, , brings attention importance keeping focus methodic.Lets assume choose focus production seedlings, many seedlings die planting cheap.\nFigure 1.4: problems seedling production\n","code":""},{"path":"the-scientific-method.html","id":"search-prior-knowledge","chapter":"1 The scientific method","heading":"Search prior knowledge","text":"second step scientific method find already done problem.need collect information better define problem . start working first idea occurs . May else thought idea already, may better ideas, may ideas give even better idea.Ultimately, risk getting rabbit hole people already checked , worse reinventing wheal.\nFigure 1.5: Search information\nSearching prior knowledge can done different ways.can start general Google search. example restoration, can ask simple question like “seedling mortality high”. Ask questions like ask person. specific get better.information web likely collected without using scientific method, cautious using information. reason consider web general source information contains cumulative experiences millions people, bring another source information, gaining expertise people. Find people working problem, ask questions asked Google.Upon gathering prior knowledge form experiences via webpages interviews, need scale quality information search using Google Scholar.\nFigure 1.6: Scholar Page\nGoogle Scholar search engine scientific publications. many databases can use look papers like PubMed Jstor, Scholar alone likely enough. Several studies shown almost search Scholar returns papers searches specific databases.\nFigure 1.7: PDFs Scholar\ndatabases may give title summary paper (.e., call citation), finding full paper another deal.freely available web, Google Scholar provide PDF papers hyperlink highlighted red square figure .email student account, can also try get PDF via local library, link provided besides citation Google Scholar (green square figure ). links available search within university’s network.can also click “versions” tab (Highlighted red arrow image ); commonly PDFs well.rush, can click citation, take web-page journal, get email address author send person message asking PDF.also web page commonly shared among students called Sci-Hub, contains PDFs almost paper. another one provides books Z-Library. familiar legality projects, aware exists. can read Sci-Hub , Z-Library ., important know sources information. apply common sense, use information.Please following exercise:Using words “many species Earth”, search Google Google Scholar.Check first ten citations search.differences see?social implications differences?\nObviously, find PDFs papers, read . papers may provide new citations look .step information/literature search taken much seriousness. really want sure know well already known ; need become expert whatever want work . good understanding prior cumulative knowledge allow quickly judge something worth working . also give ideas things.Pasteur famously said, “chance favours prepared mind”. Given told , think important, , know literature well?\nFigure 1.8: information search demanding, done well\n","code":""},{"path":"the-scientific-method.html","id":"back-to-defining-the-problem","chapter":"1 The scientific method","heading":"Back to defining the problem","text":"non-trivial exercise looking prior information, probable go back re-defining problem , specific can.actually replicate example forest restoration, find one, among many problems, seedlings probably want healthy seedlings grown nursery maximize survival planting.seedlings growing fast can also reduce time spend nursery reducing overhead costs. Tall healthy seedlings can better cope stress planting, escape ground competition weeds.probably also found water food (form nutrients) critical making seedlings grow faster healthier. good information search, certainly, also found importance soil microbes, specifically Mycorrhizae.\nFigure 1.9: Mycorrhizae roots\nMycorrhizae group species fungi finds home roots trees, creating mutualistic relationships tree. break organic matter nitrogen compounds can adsorbed faster seedling.point, likely become clear obvious question ask Mycorrhizae effect seedlings.","code":""},{"path":"the-scientific-method.html","id":"the-hyphotesis","chapter":"1 The scientific method","heading":"The hyphotesis","text":"\nFigure 1.10: hyphotesis\n=oThe third step scientific method solving problem define hypothesis.clear question, relatively certain one asked question , answer insufficiently, move next phase scientific method, formulate question specifically. simple :Mycorrhizae increase body size plants?purpose scientific method need specific want study. See instance, question explicit fungi, affecting specifically body size plants. nuances formulating question, talk deal designing experiment.also reformulate specific question form hypothesis, like:Mycorrhizae significant positive effect body size plantsYou now note hypothesis version question now include expectation effect positive. addition hypothesis word “significant”, meaning effect find “considerably” larger effect find use Mycorrhizae.Mathematically, hypothesis defined two alternatives can choose : 1) “Null hypothesis” 2) “Alternative hypothesis”.","code":""},{"path":"the-scientific-method.html","id":"the-null-hypothesis-h0","chapter":"1 The scientific method","heading":"The null hypothesis H0","text":"null hypothesis denoted symbol H0. commonly represents statement “effect,” “difference”.restoration example,H0 Mycorrhizae significant effect body size plants","code":""},{"path":"the-scientific-method.html","id":"the-alternate-hypothesis-h1","chapter":"1 The scientific method","heading":"The alternate hypothesis H1","text":"alternate hypothesis denoted symbol H1. commonly represents hypothesis differs null hypothesis. defined way accepted null hypothesis rejected.restoration example,H1 Mycorrhizae positive significant effect body size plants.","code":""},{"path":"the-scientific-method.html","id":"the-experiment","chapter":"1 The scientific method","heading":"The experiment","text":"process developing experiment answer question test hypothesis called “Experimental Design”, full nuances (commonly called “demonic intrusions”) render entire work meaningless, designing good experiment critical obtain robust data.design experiment, important know several terms.k","code":""},{"path":"the-scientific-method.html","id":"population-sample-subject","chapter":"1 The scientific method","heading":"Population, sample, subject","text":"Three important terms know experimental design subject/individual, sample population.Population refers every individual interest. sample refers individuals interest. quantify given variable entire population called census. statistic based entire population called “point stimate”.Drag terms think belong.need appreciate statistics samples can vary sample sample, whereas statistics population fixed given population. instance, figure , yellow birds represent 1 ten birds (.e., 10% sample) sample outlined solid line. Yet another sample (outlined dotted purple line), ten individuals two yellow birds (.e., 20%).important appreciate differences sample population, times differences exactly want measure test. Say know average heart rate people 80 beats per minute 90 beats per minute. rate significantly higher expected?\ncase, can compare hearths rate average population.\nLater study test mathematically.","code":""},{"path":"the-scientific-method.html","id":"variables","chapter":"1 The scientific method","heading":"Variables","text":"experimental design, word “Variables” can mean several things, important specific.dependent variable\ndependent variable, instance, characteristic individual measured observed. also called “response variable”. words, dependent variable attribute system expect change, plan measure. case restoration hypothesis, “body size” plants.independent variable\nindependent variable manipulate experiment. can also called factor. case restoration hypothesis, presence absence Mycorrhizae. can also use different concentrations Mycorrhiza. Collectively, concentrations called independent variable, concentration call “level”. likely level independent variable can also called treatment.Quantitative variable\nVariables also used referring type data collect. measure individuals numerical (.e., can measured numbers, instance, height weight), called quantitative variable.Qualitative variable\nqualitative variable describes individual placing individual category group (instance, male female).","code":""},{"path":"the-scientific-method.html","id":"the-control-and-treatment","chapter":"1 The scientific method","heading":"The control and treatment","text":"\nFigure 1.11: population\nexperimental design, testing effects given independent variable, important see happens individuals absence effect independent variable.Individuals group subject independent variable called collectively “control” group. groups created individuals exposed independent variable collectively called “treatment” group.difference response variable control treatment attributed independent variable.Say individuals control group average 100g, given treatment 120g.comparison, can see treatment created 20% increase weight.course, individuals exactly weight (-call variability), later , see use variability statistical methods determine different statistically significant .","code":""},{"path":"the-scientific-method.html","id":"replication","chapter":"1 The scientific method","heading":"Replication","text":"experimental design, replication refers number independent individuals control treatment upon test hypothesis. Replication critical element experimental design determines robustness conclusion.Drag terms think belong.hIn almost experiment random variation response. Thus, observed difference control treatments mistakenly attributed cause--effect relationship source difference may just random variation. short, difference may simply due noise rather signal. type error affected considerably amount replication .Let’s use example. nothing wrong coin, know probably head tail 50%. However, test hypothesis one replicate, let’s say landed tails, conclude tails occur 100% times.try second time, lands tails , conclusion remains . heads, now change conclusion now either side 50% change.Let’s say try , regardless lands, probability either side coin now changed 75%.can continue numerous trials, eventually probability rest 50% either side coin, nothing wrong coin.example , can see reduced replication can lead variation conclusions.Let’s review effect replication mathematically exercise, measured weight 1000 seedlings nursery. case, done census measured every single individual. plotted number seedlings weight, obtaining following figure:average weight individuals population 100.13Now let’s see happen take samples different sizes population.figure , point average sample number individuals shown x-axis. red line true average population.figure , can see samples fewer number replicated individuals much larger variability mean weight samples individuals.Basically, variability samples reduces increase size replicated individuals. population 1,000 individuals, closer sample number, accurate results sample.better visualize relationship number replicates variability, let’s take 100 samples sample size:, can see samples fewer replicated individuals variable samples many replicated individuals.set number replicates use experiment optimum depends degree variability variable measuring. Later quantify optimum sample size given population.Sample size replication confusing terms times interrelated. Say want compare group individuals population, case individual replicated together sample size.However, experiment requires take multiple samples, sample given number individuals, sample treated independent measures, case, sample replicate.Remember, replicate needs independent .","code":""},{"path":"the-scientific-method.html","id":"pseudo-replication","chapter":"1 The scientific method","heading":"Pseudo-Replication","text":"One important assumption use statistics replicates independent (.e., one replicate depend another), can tricky times.\nFigure 1.12: Pseudo Replication\nLet’s assume want experiment fishes see certain diet better . already identified optimum sample size 1,000 fish. , put 1000 fishes one aquarium 1000 fishes another aquarium, feed fish different diets, later , measure heavy fishes .example typical example pseudo-replication. may think 1,000 replicates, reality one, aquarium fish.case, response find fish independent fishes one aquarium equally affected whatever happens aquarium.one true replicate?. data experiment reliable?famous paper Hurlbert Ecological Monographs 1984 outlines many things can go wrong due pseudoreplication.\nFigure 1.13: likely confusions emerge due Pseudo Replication\n","code":""},{"path":"the-scientific-method.html","id":"randomness","chapter":"1 The scientific method","heading":"Randomness","text":"Another issue mindful experiments ensure variable test applied randomly individuals experiment.effect variables control even know called “demonic intrusions”. Basically, variables can introduce evil effects response variable, can controlled ensuring everything randomly.Let’s use example clarify .Let’s image run experiment two treatments, 100 replicated aquarium. Say put aquarium one treatment one side lab 100 aquarium treatment side lab.type demonic intrusion think case?image side lab facing sun morning less hot aquariums side. May one side get light . May windows, thus different airflow, affecting oxygen water….list can go .variables can affect fish aquarium grow. consequence, results may find difference fishes different aquariums due diet demonic intrusions, resulting putting aquariums one treatment one side lab, treatment side.Time feed another non-control variable.. fish feed morning less stress fish feed afternoon?.list potential artifacts long, likely effect can avoided ensuring aspect setting experiment done randomly. instance, locating aquariums randomly laboratory.","code":""},{"path":"the-scientific-method.html","id":"design-experiment","chapter":"1 The scientific method","heading":"Design experiment","text":"considerations , eight rules need enforce design experiment (PeerJ)1.Begin identifying hypothesis topic interested . Testable predictions generated allow formulate hypothesis. hypothesis explanation think system works based observation. hypothesis either accepted rejected based data collected.2.Define parameters experiment clear concise wording. clearly defining terms, can focus experimental methods avoid ambiguity. ensures results accurate less flexibility experimental design, increasing accuracy (Hurlbert, 1984).3.Decide like perform mensurative manipulative experiment. mensurative experiment involves making measurements different times different areas. manipulative experiment involves physically altering treatment group, thus always two treatments (Hurlbert, 1984).4.Choose appropriate sample size fitting results wish obtain. Generally, smaller sample size produces results inaccurate generalization. smaller sample size also produce smaller effect size measure, efficacy treatment, thus avoided (Ionnidis, 2005).5.Introduce control group. biology, systems tend exhibit temporal change, influencing third variable. order isolate changes experimental treatment alone, control necessary.6.Randomize assignment. randomizing sample units different treatment groups, experimenter bias avoided. Randomization critical facet experimental design intersperses samples tested (Hurlbert, 1984).7.Replicate! number replicates necessary vary design, however ensures precision experiments (Oksanen, 2001).8.Ensure samples dispersed space time avoid pseudoreplication. ensures replicates statistically independent. Often, experimenters make inferences based data collected quantify samples unit independent, however reality samples come unit, thus genuine replication (Oksanen, 2001).","code":""},{"path":"the-scientific-method.html","id":"data-collection","chapter":"1 The scientific method","heading":"Data collection","text":"designed started run experiment need start measuring response variable (call data).important systematic, methodic organized collect data. Create logbook document observation may , change variables, responses individuals, etc. Document date time observation. lose logbook.critical several copies data different places. Almost everyone terrible experience losing data. case, lost log-book airport. Hard drives fail, computers get stolen, etc. Account possibility; last thing want lose data experiment.","code":""},{"path":"the-scientific-method.html","id":"analyze-your-data","chapter":"1 The scientific method","heading":"Analyze your data","text":"finish experiment data nicely organized. relay mathematics draw conclusion. step called “Hypothesis testing”, numerous methods can use. following chapters,introduce several statistical methods may use test hypothesis correct .","code":""},{"path":"the-scientific-method.html","id":"vizualize-the-data","chapter":"1 The scientific method","heading":"Vizualize the data","text":"great scientific story one can told simple figure. Latter , introduce several types figures can use visualize data.\nFigure 1.14: impacts climate change diseases one figure\n","code":""},{"path":"the-scientific-method.html","id":"write-report","chapter":"1 The scientific method","heading":"Write report","text":"publish results, almost research. paper needs clear, detailed ensure person can replicate study find results.Due issues related poor experimental design, statistical test lack clarify done, found considerable amount scientific studies difficult replicate.2016 poll 1,500 scientists reported 70% failed reproduce least one scientist’s experiment (50% failed reproduce one experiments), leading currently call replicability crisis.","code":""},{"path":"the-scientific-method.html","id":"excercises","chapter":"1 The scientific method","heading":"Excercises","text":"","code":""},{"path":"the-scientific-method.html","id":"exercise-1","chapter":"1 The scientific method","heading":"Exercise 1","text":"scientific methodd process.Drag boxes right boxes left order think question answered using scientific method.","code":""},{"path":"the-scientific-method.html","id":"exercise-2","chapter":"1 The scientific method","heading":"Exercise 2","text":"Key terms statistics","code":""},{"path":"the-scientific-method.html","id":"homework","chapter":"1 The scientific method","heading":"Homework","text":"Please following exercise:Based content chapter, think problem observed create flow chart outling steps take relibable experiment.Using small figure sketch draw likely experiment, name parts.","code":""},{"path":"installing-programs.html","id":"installing-programs","chapter":"2 Installing programs","heading":"2 Installing programs","text":"going take break stats following two chapters install learn basics R.","code":""},{"path":"installing-programs.html","id":"installing-r","chapter":"2 Installing programs","heading":"Installing R","text":"mentioned earlier, R free can downloaded .page click CRAN (see red arrow figure ).\nFigure 2.1: RProject Webpage\nNext select mirror. Mirrors servers around world maintain copies R packages. can click “0-Cloud”, mirror fine (see image )\nFigure 2.2: Installing R\nNext,select system computer. recommend use Windows. small differences systems, work system. Apple, . several perks Apple, big deal, aware due compatibility settings, issues may emerge.\nFigure 2.3: Installing R\nNext, download executable file R, indicated read arrow figure .\nFigure 2.4: Installing R\ndownloaded, file “Downloads” folder. Double click accept default settings. R icon now appear bottom tab Windows menu (See arrows image ).\nFigure 2.5: Installing R\nClick icon, welcome R. Crazy screen look like much portal world opportunities.\nFigure 2.6: Installing R\n","code":""},{"path":"installing-programs.html","id":"tinn-r","chapter":"2 Installing programs","heading":"Tinn-R","text":"run line code R, un-done. commonly, re-run lines code.reason, better write code text editor program, running R.\ncan save text file, next time, simply copy paste.can save R code word processor. Notepad Windows just fine. can also use Microsoft Word, mindful software commonly capitalizes first letter new line. R case sensitive, Word worth trouble.personally use Tinn-R. allows save codes single file, gives hints code, etc.Please install Tinn-R .create file Tinn-R, click Tinn-R icon (see arrow image ). , click “File”, “New”. create clean sheet start writing codes. use type sheets save codes, move along.\nFigure 2.7: Installing Tinn-R\n","code":""},{"path":"installing-programs.html","id":"r-studio","chapter":"2 Installing programs","heading":"R-Studio","text":"also popular GUI (Graphical User Interface) called R-Studio, allows run R functionality Tinn-R.Please know R R studio. R-Studio, R almost hidden background, important still know run R without R-Studio.said, R-studio facilitates considerably learning R, downside think R-studio R.can download R-studio ; use free version. Follow instructions page install software.installation R-Studio appear icon image .\nFigure 2.8: R-Studio\nnext video show use R-Studio.","code":""},{"path":"installing-programs.html","id":"installing-packages","chapter":"2 Installing programs","heading":"Installing packages","text":"Part power R tools developed users around world can integrated R’s general functionality. tools integrated containers called packages, deposited R repository anyone use. many tools already developed chances packages anything may need.primary way install package using command:brackets name package want install. prompted select mirror. first time installing package, also asked select folder install packages. suggest accept default suggestions provided.installed local harddrive, need load packages console every time want use . , use command:quotations name raster. Rlease remember R case sensitive.","code":"\n# install.packages(\"raster\")\nlibrary(\"raster\")## Loading required package: sp"},{"path":"installing-programs.html","id":"asking-for-help","chapter":"2 Installing programs","heading":"Asking for help","text":"can access help specific R function using question mark sign, followed name function. instance, ask help mean, type:window available help function pop-(like one image ).\nFigure 2.9: Asking help R\nOne super nice thing R’s help provides examples function used. See, instance, image , example (indicated red arrow) use mean function R. can simply copy lines commands paste console. becomes useful, can simply adjust given code given data.","code":"\n# ?mean"},{"path":"installing-programs.html","id":"exercise","chapter":"2 Installing programs","heading":"Exercise","text":"Please install R R-studio computer. install load package “raster”. Run example .","code":"\nlibrary (raster)\n\n# check for help by simply typing the question mark followed by the function name (like: ?raster)\n\n#load a raster already saved in the raster package\nf <- system.file(\"external/test.grd\", package=\"raster\") #file direction\n\n#turn it into a raster\nr <- raster(f)\n\n#plot the raster\nplot(r)"},{"path":"basics-on-data-manipulation-in-r.html","id":"basics-on-data-manipulation-in-r","chapter":"3 Basics on data manipulation in R","heading":"3 Basics on data manipulation in R","text":"\nFigure 3.1: R console\nthink R advance scientific calculator like ones used high school. Basically, set basic functions already installed R, can use data.can also install packages, gives access additional functions.Use Google find packages may functions need. Say want genotypic analysis. Simply Google “R packages genotypic analysis”. want animations, search “animation R”.","code":""},{"path":"basics-on-data-manipulation-in-r.html","id":"variables-1","chapter":"3 Basics on data manipulation in R","heading":"Variables","text":"Variables R names used storage objects can manipulate. instance, let create variable “”, whicha want value 1. Basically, R console type:click “Enter”. command, just created variable , value 1.check, type “” +“Enter”.Let’s now create variable called B, equal 2.can now use two variables see happens add :cal also create new variable based variables. instance:can check variables created using command ls()can see, moment created three variables, named , B C.try now. Open R computer use console . console exactly R computer. use type window instances book, recommend practices computer.Create variable called D=10 called z=5, calculate thhe difference D z.","code":"\nA=1\nA## [1] 1\nB=2\nA+B## [1] 3\nC=A-B\nC## [1] -1\nls()##  [1] \"A\"              \"B\"              \"C\"              \"f\"             \n##  [5] \"i\"              \"MeanPopulation\" \"MeanSample\"     \"Merge\"         \n##  [9] \"Population\"     \"r\"              \"Results\"        \"Sample\"        \n## [13] \"SampleSize\"     \"trial\""},{"path":"basics-on-data-manipulation-in-r.html","id":"comments","chapter":"3 Basics on data manipulation in R","heading":"Comments","text":"start coding, always good practice explain words line code intended .tell number times, gone back old codes ask , purpose line. thinking time?ensure codes can easy understood later , use comments. R comments text added code, R process.comment R preceded number sign (#). instance:w","code":"\nA=10 # Here I used R to show how to create a variable\nB=20 # In this case, i wanted my variable B to be 2\nA+B## [1] 30"},{"path":"basics-on-data-manipulation-in-r.html","id":"operators","chapter":"3 Basics on data manipulation in R","heading":"Operators","text":"","code":""},{"path":"basics-on-data-manipulation-in-r.html","id":"assignment-operators","chapter":"3 Basics on data manipulation in R","heading":"Assignment operators","text":"noted previous page, used equal sign (=) assign value letter variable; called assignment operator. Another broadly recommended assignment operator >-, used like :Note code use >- instead =can verify , typing R console hitting enter.","code":"\na<-10 # in this case I used <- as the assigment operators\na## [1] 10"},{"path":"basics-on-data-manipulation-in-r.html","id":"arithmetic-operators","chapter":"3 Basics on data manipulation in R","heading":"Arithmetic operators","text":"R preloaded lot built-mathematical operators. basic ones:Lets say variable =145.677, one stimate largest integer number, thenGive try operators, .time need operator, know R, simply ask friend Google. Say want calculate cosine number?. Simply search Google “calculate cosine R”.","code":"\na=145.677\nb=ceiling(a)\nb## [1] 146"},{"path":"basics-on-data-manipulation-in-r.html","id":"character-operators","chapter":"3 Basics on data manipulation in R","heading":"Character operators","text":"times, want handle numbers words. R also functions .Lets try examples:function paste another function use lot.want nothing separate words, put nothing brackets sep, like ","code":"\na=\"camilo1989\" #here I have a character variable, but want to remove that number, so\nb=gsub(\"1989\", \"\", a) #here I replace the value indicated in between the first quotations, for what is in between the second quotations, in this case nothing.\nb## [1] \"camilo\"\na=\"camilo\" #here I have a character variable, that I want to concatenate with another one. \nb=\"1989\" #second variable.\nc=paste(a,b,sep=\"_\") #here I merge a and b, and separate them with an underscore\nc## [1] \"camilo_1989\"\nc=paste(a,b,sep=\"\")\nc## [1] \"camilo1989\""},{"path":"basics-on-data-manipulation-in-r.html","id":"custom-made-functions","chapter":"3 Basics on data manipulation in R","heading":"Custom made functions","text":"become better coding, probably want start creating functions. can even create functions, use functions. Think like lego game, thousands functions (legos) can use create whatever want. Just Legos game, creating functions simple.structure R function follow:name want functionWhat arguments needed functionBetween {} place want argumentsOutline want output functionLet’s example. Say, two numbers (12.78454 1.34893439), want first multiple, divide result 2, estimate cosine, multiple pi, estimate ceiling; want four times different starting numbers. lets start coding ,see code , wrote 8 lines code get result first two set numbers. want say three set numbers, write 24 lines code, mention chance error.Since general operation cases, can simply create function, reduce lenght code, ensuring use exactly procedure numbers. Let’s ,see, copy entire process first set values, replace b, arguments function, add {} name function. just created function, called CamilosFunction, requires two values, process indicated , return result. Lets see,can now reuse function different numbers, time requiring one line code.Create function now. take three numbers (4,2,3), calculate average, multiple result 4, estimate sin, finally calculate square.","code":"\na=12.78454              #I place  first number in a variable, so I do not have to retype all numbers\nb=1.34893439            #same for second number\nMultiple_AB=a*b         #first command I have to do. Create new varaible multiplying a and b\nDivide= Multiple_AB/2   #second command is to divide the output by 2\nCosine= cos(Divide)     #third command is to estimate the cosine in the results\nPI=Cosine*pi            #four command is to multiply result by pi\nCealing=ceiling(PI)     #finally, estimate the largest integer\nCealing                 #here is the result of that operation above## [1] -2\nCamilosFunction <- function(argument1, argument2) { #Argument 1 and 2, are the two numbers I have to run in my function\nMultiple_AB=argument1*argument2         #first command I have to do\nDivide= Multiple_AB/2                   #second command is to divide the output by 2\nCosine= cos(Divide)                     #third command is to estimate the cosine in the results\nPI=Cosine*pi                            #four command is to multiply result by pi\nCealing=ceiling(PI)                     #finally, estimate the largest integer\nreturn (Cealing)                        #here is the result of that operation above\n}                 \na=12.78454\nb=1.34893439\nCamilosFunction (a, b) #here is my function, which run many commands and give me a single result.## [1] -2\nCamilosFunction (12.78454,10002.78454) ## [1] -2\nCamilosFunction (120.78454,102.78454) ## [1] 3\nCamilosFunction (912.74,10002.78454) ## [1] -1"},{"path":"basics-on-data-manipulation-in-r.html","id":"data-structure-types","chapter":"3 Basics on data manipulation in R","heading":"Data structure types","text":"R provides numerous ways hold data. Let’s check .","code":""},{"path":"basics-on-data-manipulation-in-r.html","id":"vectors","chapter":"3 Basics on data manipulation in R","heading":"Vectors","text":"vector collection values. call individual values “elements” vector.can make vectors c( ). c means “combine”. Say three numbers 1,4,5 just want type every time. can put numbers vector.can also run operations vector. Lets use example , want multiply value vector 2.","code":"\nc(1,4,5) #here I have a vector with three numbers## [1] 1 4 5\na=c(1,4,5) #here create a variable that contains my vector of three numbers\na*2        #here I multiply my variable (vector with three numbers)  by 2.## [1]  2  8 10"},{"path":"basics-on-data-manipulation-in-r.html","id":"matrix","chapter":"3 Basics on data manipulation in R","heading":"Matrix","text":"can merge multiple vectors create matrix. can merge vectors columns using function cbind rows using function rbind. Lets example clarify.See result , vector became column.May prefer merge rowsYou can now see two vectors merged rows.","code":"\nVector1=c(1,4,5)                          #here I have vector 1 with three numbers\nVector2=c(56,42,93)                       #here I have vector 2 with three numbers\nColumnMergedVector=cbind(Vector1,Vector2) #I use cbind to merge the vector by column\nColumnMergedVector##      Vector1 Vector2\n## [1,]       1      56\n## [2,]       4      42\n## [3,]       5      93\nRowMergedVector=rbind(Vector1,Vector2) #I use rbind to merge the vector by rows\nRowMergedVector##         [,1] [,2] [,3]\n## Vector1    1    4    5\n## Vector2   56   42   93"},{"path":"basics-on-data-manipulation-in-r.html","id":"dataframes","chapter":"3 Basics on data manipulation in R","heading":"DataFrames","text":"Dataframes common type data structure R. similar topology matrix, diverse types data can use. Dataframes, like “Sheet” version Excel. create dataframe use data.frame function. Lets example.sDataframes also allow rename column row names, different ways . one,probably asking difference matrix data.frame?. differences:","code":"\nDataFrame=data.frame(Vector1,Vector2) #I use data.frame to merge two vectros of data\nDataFrame##   Vector1 Vector2\n## 1       1      56\n## 2       4      42\n## 3       5      93\ncolnames(DataFrame)=c(\"Height\",\"Width\") #Here I rename the two columsn in the dataframe, with the names used in a vector. \nDataFrame##   Height Width\n## 1      1    56\n## 2      4    42\n## 3      5    93"},{"path":"basics-on-data-manipulation-in-r.html","id":"loading-your-own-data-into-r","chapter":"3 Basics on data manipulation in R","heading":"Loading your own data into R","text":"R also allows import data diversity formats. use basic one, import .csv files (-called comma delimited data). type file, data listed rows, number commas row indicating columns.load .csv file R, use command read.csv(). brackets put path file located. write path quotation. sounds complicated, simple. Let’s just try example.Create folder local desktop called “Data”. good practice keep data codes separated folders can easily identify name alone.Create folder local desktop called “Data”. good practice keep data codes separated folders can easily identify name alone.Download csv file . Right click page click “Save page ” pop-window. Name file “Countries_GDP.csv”, navigate “Data” folder just created save file . Click “Save”. file now appear “Data” folder.Download csv file . Right click page click “Save page ” pop-window. Name file “Countries_GDP.csv”, navigate “Data” folder just created save file . Click “Save”. file now appear “Data” folder.Now csv file local hard-drive, can load R. need couple things. First, get path file . , click windows explorer (button looks like folder desktop, see image )Now csv file local hard-drive, can load R. need couple things. First, get path file . , click windows explorer (button looks like folder desktop, see image )\nFigure 3.2: Windows explorer\nNavigate folder Data saved file, put mouse cursor selectable window (See arrow image ). reveal path file saved computer.\nFigure 3.3: Getting path file\nNext, right click window, click Copy. copy path file (See image ).\nFigure 3.4: Getting path file\nOpen R, right click anywhere inside main window R click “Paste”. look something like :\nFigure 3.5: Getting path file\nNow need replace back-slash forward-slash path. position keys keyboard shown image .\nFigure 3.6: Slash keys keyboard\npath file change ::Now, path folder file, need add file name, like :tell got started R. colleague sent file told open file R. sounded simple time, took two days figure tiny things setting file correctly. Back days internet full useful tutorials . Ok, let’s keep going.Now add path R function used read csv files, “read.csv()”, like :suggest attach file variable name, can call later., now loaded data R. Check looking top part databaseBy way, know csv file web deleted moved, can read data web directly using URL file, instead path. Like ,","code":"\n# \"D:/GEO380/Datasets/\"\n# \"D:/GEO380/Datasets/\"\n# \"D:/GEO380/Datasets/Countries_GDP.csv\"\n# read.csv(\"D:/GEO380/Datasets/Countries_GDP.csv\")\nGDPData=read.csv(\"D:/GEO380/Datasets/Countries_GDP.csv\")\nhead (GDPData)##       country continent year gdpPercap\n## 1 Afghanistan      Asia 1952  779.4453\n## 2 Afghanistan      Asia 1957  820.8530\n## 3 Afghanistan      Asia 1962  853.1007\n## 4 Afghanistan      Asia 1967  836.1971\n## 5 Afghanistan      Asia 1972  739.9811\n## 6 Afghanistan      Asia 1977  786.1134\nGDPData=read.csv(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/Countries_GDP.csv\")"},{"path":"basics-on-data-manipulation-in-r.html","id":"calling-elements-in-a-data-frame","chapter":"3 Basics on data manipulation in R","heading":"Calling elements in a data frame","text":"Ok, now know store data R. need learn see data. see given data container, can simply typeb name click enter. instance,ok way see data data container big. However, lots data command fill screen. Instead, can use function head tail, let see top five bottom five rows dataframe. Lets see.Let first create medium size dataframe:code , just create dummy dataframe three columns 250 rows using functions already described chapter arithmetic operators.try see full database, just type name dataframe click enter. However, notice calling full dataframe use lot screen space attempt display data.","code":"\nDataFrame##   Height Width\n## 1      1    56\n## 2      4    42\n## 3      5    93\nDataFrame<- data.frame( x1 = c(rep(1,250)),     # in Column 1 I repeat the number 1 for 25 times\n                        x2 = seq(1:250), #Column 2 I create a sequence of numbers from 1 to 25\n                        x3 = sample(seq(1:1000),250)) # select 25 random numbers between 1 and 10000\nDataFrame##     x1  x2   x3\n## 1    1   1  596\n## 2    1   2  891\n## 3    1   3  520\n## 4    1   4  152\n## 5    1   5  717\n## 6    1   6  887\n## 7    1   7  408\n## 8    1   8  616\n## 9    1   9   20\n## 10   1  10  842\n## 11   1  11  100\n## 12   1  12  151\n## 13   1  13  158\n## 14   1  14  472\n## 15   1  15   57\n## 16   1  16  441\n## 17   1  17  526\n## 18   1  18  556\n## 19   1  19  804\n## 20   1  20  331\n## 21   1  21  112\n## 22   1  22   25\n## 23   1  23  956\n## 24   1  24  445\n## 25   1  25  782\n## 26   1  26  982\n## 27   1  27  809\n## 28   1  28  554\n## 29   1  29  790\n## 30   1  30    4\n## 31   1  31  284\n## 32   1  32   58\n## 33   1  33  295\n## 34   1  34  282\n## 35   1  35  252\n## 36   1  36  973\n## 37   1  37  276\n## 38   1  38  836\n## 39   1  39  697\n## 40   1  40  321\n## 41   1  41  563\n## 42   1  42  661\n## 43   1  43  506\n## 44   1  44  905\n## 45   1  45   26\n## 46   1  46  421\n## 47   1  47   43\n## 48   1  48  489\n## 49   1  49  622\n## 50   1  50  127\n## 51   1  51  129\n## 52   1  52  801\n## 53   1  53  326\n## 54   1  54  566\n## 55   1  55  281\n## 56   1  56  484\n## 57   1  57  262\n## 58   1  58  651\n## 59   1  59  928\n## 60   1  60  137\n## 61   1  61  358\n## 62   1  62  417\n## 63   1  63  606\n## 64   1  64  931\n## 65   1  65  586\n## 66   1  66  364\n## 67   1  67  924\n## 68   1  68  873\n## 69   1  69  614\n## 70   1  70  914\n## 71   1  71   79\n## 72   1  72  872\n## 73   1  73  590\n## 74   1  74  819\n## 75   1  75   60\n## 76   1  76  415\n## 77   1  77  805\n## 78   1  78  624\n## 79   1  79  429\n## 80   1  80   48\n## 81   1  81  761\n## 82   1  82  835\n## 83   1  83   24\n## 84   1  84  633\n## 85   1  85  297\n## 86   1  86  471\n## 87   1  87  564\n## 88   1  88  570\n## 89   1  89  645\n## 90   1  90  583\n## 91   1  91  760\n## 92   1  92  496\n## 93   1  93  175\n## 94   1  94  547\n## 95   1  95  503\n## 96   1  96  324\n## 97   1  97    7\n## 98   1  98  213\n## 99   1  99  197\n## 100  1 100  516\n## 101  1 101  399\n## 102  1 102  459\n## 103  1 103  422\n## 104  1 104  140\n## 105  1 105  378\n## 106  1 106  640\n## 107  1 107  708\n## 108  1 108  831\n## 109  1 109   14\n## 110  1 110  844\n## 111  1 111  426\n## 112  1 112  384\n## 113  1 113  704\n## 114  1 114  667\n## 115  1 115  910\n## 116  1 116  432\n## 117  1 117  256\n## 118  1 118  821\n## 119  1 119  825\n## 120  1 120  610\n## 121  1 121  710\n## 122  1 122  514\n## 123  1 123  571\n## 124  1 124  327\n## 125  1 125  490\n## 126  1 126  588\n## 127  1 127  126\n## 128  1 128  845\n## 129  1 129  101\n## 130  1 130  391\n## 131  1 131  540\n## 132  1 132  283\n## 133  1 133  393\n## 134  1 134   81\n## 135  1 135  707\n## 136  1 136  672\n## 137  1 137  340\n## 138  1 138  885\n## 139  1 139  938\n## 140  1 140    5\n## 141  1 141  196\n## 142  1 142  113\n## 143  1 143  473\n## 144  1 144  630\n## 145  1 145  430\n## 146  1 146   37\n## 147  1 147  205\n## 148  1 148  655\n## 149  1 149  748\n## 150  1 150   22\n## 151  1 151  802\n## 152  1 152  332\n## 153  1 153  103\n## 154  1 154   65\n## 155  1 155  769\n## 156  1 156  888\n## 157  1 157  604\n## 158  1 158  314\n## 159  1 159  878\n## 160  1 160  214\n## 161  1 161   50\n## 162  1 162  864\n## 163  1 163  380\n## 164  1 164  886\n## 165  1 165  198\n## 166  1 166  202\n## 167  1 167  329\n## 168  1 168  451\n## 169  1 169  839\n## 170  1 170  737\n## 171  1 171  834\n## 172  1 172  960\n## 173  1 173  759\n## 174  1 174  869\n## 175  1 175  589\n## 176  1 176   68\n## 177  1 177   70\n## 178  1 178  293\n## 179  1 179  303\n## 180  1 180  721\n## 181  1 181  194\n## 182  1 182  289\n## 183  1 183  987\n## 184  1 184   73\n## 185  1 185  385\n## 186  1 186  203\n## 187  1 187  339\n## 188  1 188  763\n## 189  1 189  232\n## 190  1 190  718\n## 191  1 191  594\n## 192  1 192  392\n## 193  1 193  695\n## 194  1 194  779\n## 195  1 195  944\n## 196  1 196  487\n## 197  1 197  365\n## 198  1 198  783\n## 199  1 199  893\n## 200  1 200  375\n## 201  1 201  546\n## 202  1 202  773\n## 203  1 203  231\n## 204  1 204  871\n## 205  1 205  879\n## 206  1 206  674\n## 207  1 207   96\n## 208  1 208  341\n## 209  1 209  575\n## 210  1 210  301\n## 211  1 211  840\n## 212  1 212  155\n## 213  1 213  957\n## 214  1 214  420\n## 215  1 215  658\n## 216  1 216  145\n## 217  1 217  567\n## 218  1 218  260\n## 219  1 219  529\n## 220  1 220  584\n## 221  1 221  512\n## 222  1 222  350\n## 223  1 223   71\n## 224  1 224  229\n## 225  1 225  562\n## 226  1 226  509\n## 227  1 227  111\n## 228  1 228  788\n## 229  1 229  929\n## 230  1 230  222\n## 231  1 231  860\n## 232  1 232  136\n## 233  1 233  411\n## 234  1 234  494\n## 235  1 235  474\n## 236  1 236  337\n## 237  1 237   94\n## 238  1 238   15\n## 239  1 239  169\n## 240  1 240  173\n## 241  1 241  407\n## 242  1 242  379\n## 243  1 243  569\n## 244  1 244 1000\n## 245  1 245  307\n## 246  1 246  966\n## 247  1 247  150\n## 248  1 248   29\n## 249  1 249   74\n## 250  1 250  189"},{"path":"basics-on-data-manipulation-in-r.html","id":"head","chapter":"3 Basics on data manipulation in R","heading":"Head","text":"Alternatively, can just check top rows using head function. Like :","code":"\nhead(DataFrame)##   x1 x2  x3\n## 1  1  1 596\n## 2  1  2 891\n## 3  1  3 520\n## 4  1  4 152\n## 5  1  5 717\n## 6  1  6 887"},{"path":"basics-on-data-manipulation-in-r.html","id":"tail","chapter":"3 Basics on data manipulation in R","heading":"Tail","text":"bottom rows using tail function. Like :","code":"\ntail(DataFrame)##     x1  x2  x3\n## 245  1 245 307\n## 246  1 246 966\n## 247  1 247 150\n## 248  1 248  29\n## 249  1 249  74\n## 250  1 250 189"},{"path":"basics-on-data-manipulation-in-r.html","id":"index","chapter":"3 Basics on data manipulation in R","heading":"Index","text":"can also check specific elements dataframe using index function, R indicated square brackets [row,column]. number left comma row number, number right column number. add number, display columns rows. instance, check number column 3 2th row?","code":"\nDataFrame[2,3]## [1] 891"},{"path":"basics-on-data-manipulation-in-r.html","id":"calling-columns-by-name","chapter":"3 Basics on data manipulation in R","heading":"Calling columns by name","text":"call column name dataframe, use dollar sign $ merge name dataframe name column, like ,","code":"\nhead(DataFrame$x3) #here I only display the top values of the column Country_Name## [1] 596 891 520 152 717 887"},{"path":"basics-on-data-manipulation-in-r.html","id":"filter-data","chapter":"3 Basics on data manipulation in R","heading":"Filter data","text":"recurring task data analytics filter data, means select specific subsets/chucks data. Filters can used create new variables, apply new functions, see specific data, etc. numerous ways filter data R, wall use function filter package “dplyr”.Now, lets check first rows GDP database loaded earlier,subset data , can see GDPData database four columns, “year” column, can tell data GDP (gdpPercap) repeated year. Hmm, just want see data countries Asia?. use function filter.syntax filter function reads like :\nFigure 3.7: Filter function\nNow know syntax filter function dplr package, lets test .results , can see data Asia selected.","code":"\n# install.packages(\"dplyr\")     #First, I install the package dplyr and tidyverse, since I have not installed it previously\n# install.packages(\"tidyverse\") \n\nlibrary(tidyverse) #next I load the packages into the current section of R.\nlibrary(dplyr)            \ntail(GDPData)             #lets look at the column head of the GDP data we loaded earlier.##       country continent year gdpPercap\n## 1699 Zimbabwe    Africa 1982  788.8550\n## 1700 Zimbabwe    Africa 1987  706.1573\n## 1701 Zimbabwe    Africa 1992  693.4208\n## 1702 Zimbabwe    Africa 1997  792.4500\n## 1703 Zimbabwe    Africa 2002  672.0386\n## 1704 Zimbabwe    Africa 2007  469.7093\nGDPData %>% filter(continent==\"Asia\")       ##                country continent year   gdpPercap\n## 1          Afghanistan      Asia 1952    779.4453\n## 2          Afghanistan      Asia 1957    820.8530\n## 3          Afghanistan      Asia 1962    853.1007\n## 4          Afghanistan      Asia 1967    836.1971\n## 5          Afghanistan      Asia 1972    739.9811\n## 6          Afghanistan      Asia 1977    786.1134\n## 7          Afghanistan      Asia 1982    978.0114\n## 8          Afghanistan      Asia 1987    852.3959\n## 9          Afghanistan      Asia 1992    649.3414\n## 10         Afghanistan      Asia 1997    635.3414\n## 11         Afghanistan      Asia 2002    726.7341\n## 12         Afghanistan      Asia 2007    974.5803\n## 13             Bahrain      Asia 1952   9867.0848\n## 14             Bahrain      Asia 1957  11635.7995\n## 15             Bahrain      Asia 1962  12753.2751\n## 16             Bahrain      Asia 1967  14804.6727\n## 17             Bahrain      Asia 1972  18268.6584\n## 18             Bahrain      Asia 1977  19340.1020\n## 19             Bahrain      Asia 1982  19211.1473\n## 20             Bahrain      Asia 1987  18524.0241\n## 21             Bahrain      Asia 1992  19035.5792\n## 22             Bahrain      Asia 1997  20292.0168\n## 23             Bahrain      Asia 2002  23403.5593\n## 24             Bahrain      Asia 2007  29796.0483\n## 25          Bangladesh      Asia 1952    684.2442\n## 26          Bangladesh      Asia 1957    661.6375\n## 27          Bangladesh      Asia 1962    686.3416\n## 28          Bangladesh      Asia 1967    721.1861\n## 29          Bangladesh      Asia 1972    630.2336\n## 30          Bangladesh      Asia 1977    659.8772\n## 31          Bangladesh      Asia 1982    676.9819\n## 32          Bangladesh      Asia 1987    751.9794\n## 33          Bangladesh      Asia 1992    837.8102\n## 34          Bangladesh      Asia 1997    972.7700\n## 35          Bangladesh      Asia 2002   1136.3904\n## 36          Bangladesh      Asia 2007   1391.2538\n## 37            Cambodia      Asia 1952    368.4693\n## 38            Cambodia      Asia 1957    434.0383\n## 39            Cambodia      Asia 1962    496.9136\n## 40            Cambodia      Asia 1967    523.4323\n## 41            Cambodia      Asia 1972    421.6240\n## 42            Cambodia      Asia 1977    524.9722\n## 43            Cambodia      Asia 1982    624.4755\n## 44            Cambodia      Asia 1987    683.8956\n## 45            Cambodia      Asia 1992    682.3032\n## 46            Cambodia      Asia 1997    734.2852\n## 47            Cambodia      Asia 2002    896.2260\n## 48            Cambodia      Asia 2007   1713.7787\n## 49               China      Asia 1952    400.4486\n## 50               China      Asia 1957    575.9870\n## 51               China      Asia 1962    487.6740\n## 52               China      Asia 1967    612.7057\n## 53               China      Asia 1972    676.9001\n## 54               China      Asia 1977    741.2375\n## 55               China      Asia 1982    962.4214\n## 56               China      Asia 1987   1378.9040\n## 57               China      Asia 1992   1655.7842\n## 58               China      Asia 1997   2289.2341\n## 59               China      Asia 2002   3119.2809\n## 60               China      Asia 2007   4959.1149\n## 61    Hong Kong, China      Asia 1952   3054.4212\n## 62    Hong Kong, China      Asia 1957   3629.0765\n## 63    Hong Kong, China      Asia 1962   4692.6483\n## 64    Hong Kong, China      Asia 1967   6197.9628\n## 65    Hong Kong, China      Asia 1972   8315.9281\n## 66    Hong Kong, China      Asia 1977  11186.1413\n## 67    Hong Kong, China      Asia 1982  14560.5305\n## 68    Hong Kong, China      Asia 1987  20038.4727\n## 69    Hong Kong, China      Asia 1992  24757.6030\n## 70    Hong Kong, China      Asia 1997  28377.6322\n## 71    Hong Kong, China      Asia 2002  30209.0152\n## 72    Hong Kong, China      Asia 2007  39724.9787\n## 73               India      Asia 1952    546.5657\n## 74               India      Asia 1957    590.0620\n## 75               India      Asia 1962    658.3472\n## 76               India      Asia 1967    700.7706\n## 77               India      Asia 1972    724.0325\n## 78               India      Asia 1977    813.3373\n## 79               India      Asia 1982    855.7235\n## 80               India      Asia 1987    976.5127\n## 81               India      Asia 1992   1164.4068\n## 82               India      Asia 1997   1458.8174\n## 83               India      Asia 2002   1746.7695\n## 84               India      Asia 2007   2452.2104\n## 85           Indonesia      Asia 1952    749.6817\n## 86           Indonesia      Asia 1957    858.9003\n## 87           Indonesia      Asia 1962    849.2898\n## 88           Indonesia      Asia 1967    762.4318\n## 89           Indonesia      Asia 1972   1111.1079\n## 90           Indonesia      Asia 1977   1382.7021\n## 91           Indonesia      Asia 1982   1516.8730\n## 92           Indonesia      Asia 1987   1748.3570\n## 93           Indonesia      Asia 1992   2383.1409\n## 94           Indonesia      Asia 1997   3119.3356\n## 95           Indonesia      Asia 2002   2873.9129\n## 96           Indonesia      Asia 2007   3540.6516\n## 97                Iran      Asia 1952   3035.3260\n## 98                Iran      Asia 1957   3290.2576\n## 99                Iran      Asia 1962   4187.3298\n## 100               Iran      Asia 1967   5906.7318\n## 101               Iran      Asia 1972   9613.8186\n## 102               Iran      Asia 1977  11888.5951\n## 103               Iran      Asia 1982   7608.3346\n## 104               Iran      Asia 1987   6642.8814\n## 105               Iran      Asia 1992   7235.6532\n## 106               Iran      Asia 1997   8263.5903\n## 107               Iran      Asia 2002   9240.7620\n## 108               Iran      Asia 2007  11605.7145\n## 109               Iraq      Asia 1952   4129.7661\n## 110               Iraq      Asia 1957   6229.3336\n## 111               Iraq      Asia 1962   8341.7378\n## 112               Iraq      Asia 1967   8931.4598\n## 113               Iraq      Asia 1972   9576.0376\n## 114               Iraq      Asia 1977  14688.2351\n## 115               Iraq      Asia 1982  14517.9071\n## 116               Iraq      Asia 1987  11643.5727\n## 117               Iraq      Asia 1992   3745.6407\n## 118               Iraq      Asia 1997   3076.2398\n## 119               Iraq      Asia 2002   4390.7173\n## 120               Iraq      Asia 2007   4471.0619\n## 121             Israel      Asia 1952   4086.5221\n## 122             Israel      Asia 1957   5385.2785\n## 123             Israel      Asia 1962   7105.6307\n## 124             Israel      Asia 1967   8393.7414\n## 125             Israel      Asia 1972  12786.9322\n## 126             Israel      Asia 1977  13306.6192\n## 127             Israel      Asia 1982  15367.0292\n## 128             Israel      Asia 1987  17122.4799\n## 129             Israel      Asia 1992  18051.5225\n## 130             Israel      Asia 1997  20896.6092\n## 131             Israel      Asia 2002  21905.5951\n## 132             Israel      Asia 2007  25523.2771\n## 133              Japan      Asia 1952   3216.9563\n## 134              Japan      Asia 1957   4317.6944\n## 135              Japan      Asia 1962   6576.6495\n## 136              Japan      Asia 1967   9847.7886\n## 137              Japan      Asia 1972  14778.7864\n## 138              Japan      Asia 1977  16610.3770\n## 139              Japan      Asia 1982  19384.1057\n## 140              Japan      Asia 1987  22375.9419\n## 141              Japan      Asia 1992  26824.8951\n## 142              Japan      Asia 1997  28816.5850\n## 143              Japan      Asia 2002  28604.5919\n## 144              Japan      Asia 2007  31656.0681\n## 145             Jordan      Asia 1952   1546.9078\n## 146             Jordan      Asia 1957   1886.0806\n## 147             Jordan      Asia 1962   2348.0092\n## 148             Jordan      Asia 1967   2741.7963\n## 149             Jordan      Asia 1972   2110.8563\n## 150             Jordan      Asia 1977   2852.3516\n## 151             Jordan      Asia 1982   4161.4160\n## 152             Jordan      Asia 1987   4448.6799\n## 153             Jordan      Asia 1992   3431.5936\n## 154             Jordan      Asia 1997   3645.3796\n## 155             Jordan      Asia 2002   3844.9172\n## 156             Jordan      Asia 2007   4519.4612\n## 157   Korea, Dem. Rep.      Asia 1952   1088.2778\n## 158   Korea, Dem. Rep.      Asia 1957   1571.1347\n## 159   Korea, Dem. Rep.      Asia 1962   1621.6936\n## 160   Korea, Dem. Rep.      Asia 1967   2143.5406\n## 161   Korea, Dem. Rep.      Asia 1972   3701.6215\n## 162   Korea, Dem. Rep.      Asia 1977   4106.3012\n## 163   Korea, Dem. Rep.      Asia 1982   4106.5253\n## 164   Korea, Dem. Rep.      Asia 1987   4106.4923\n## 165   Korea, Dem. Rep.      Asia 1992   3726.0635\n## 166   Korea, Dem. Rep.      Asia 1997   1690.7568\n## 167   Korea, Dem. Rep.      Asia 2002   1646.7582\n## 168   Korea, Dem. Rep.      Asia 2007   1593.0655\n## 169        Korea, Rep.      Asia 1952   1030.5922\n## 170        Korea, Rep.      Asia 1957   1487.5935\n## 171        Korea, Rep.      Asia 1962   1536.3444\n## 172        Korea, Rep.      Asia 1967   2029.2281\n## 173        Korea, Rep.      Asia 1972   3030.8767\n## 174        Korea, Rep.      Asia 1977   4657.2210\n## 175        Korea, Rep.      Asia 1982   5622.9425\n## 176        Korea, Rep.      Asia 1987   8533.0888\n## 177        Korea, Rep.      Asia 1992  12104.2787\n## 178        Korea, Rep.      Asia 1997  15993.5280\n## 179        Korea, Rep.      Asia 2002  19233.9882\n## 180        Korea, Rep.      Asia 2007  23348.1397\n## 181             Kuwait      Asia 1952 108382.3529\n## 182             Kuwait      Asia 1957 113523.1329\n## 183             Kuwait      Asia 1962  95458.1118\n## 184             Kuwait      Asia 1967  80894.8833\n## 185             Kuwait      Asia 1972 109347.8670\n## 186             Kuwait      Asia 1977  59265.4771\n## 187             Kuwait      Asia 1982  31354.0357\n## 188             Kuwait      Asia 1987  28118.4300\n## 189             Kuwait      Asia 1992  34932.9196\n## 190             Kuwait      Asia 1997  40300.6200\n## 191             Kuwait      Asia 2002  35110.1057\n## 192             Kuwait      Asia 2007  47306.9898\n## 193            Lebanon      Asia 1952   4834.8041\n## 194            Lebanon      Asia 1957   6089.7869\n## 195            Lebanon      Asia 1962   5714.5606\n## 196            Lebanon      Asia 1967   6006.9830\n## 197            Lebanon      Asia 1972   7486.3843\n## 198            Lebanon      Asia 1977   8659.6968\n## 199            Lebanon      Asia 1982   7640.5195\n## 200            Lebanon      Asia 1987   5377.0913\n## 201            Lebanon      Asia 1992   6890.8069\n## 202            Lebanon      Asia 1997   8754.9639\n## 203            Lebanon      Asia 2002   9313.9388\n## 204            Lebanon      Asia 2007  10461.0587\n## 205           Malaysia      Asia 1952   1831.1329\n## 206           Malaysia      Asia 1957   1810.0670\n## 207           Malaysia      Asia 1962   2036.8849\n## 208           Malaysia      Asia 1967   2277.7424\n## 209           Malaysia      Asia 1972   2849.0948\n## 210           Malaysia      Asia 1977   3827.9216\n## 211           Malaysia      Asia 1982   4920.3560\n## 212           Malaysia      Asia 1987   5249.8027\n## 213           Malaysia      Asia 1992   7277.9128\n## 214           Malaysia      Asia 1997  10132.9096\n## 215           Malaysia      Asia 2002  10206.9779\n## 216           Malaysia      Asia 2007  12451.6558\n## 217           Mongolia      Asia 1952    786.5669\n## 218           Mongolia      Asia 1957    912.6626\n## 219           Mongolia      Asia 1962   1056.3540\n## 220           Mongolia      Asia 1967   1226.0411\n## 221           Mongolia      Asia 1972   1421.7420\n## 222           Mongolia      Asia 1977   1647.5117\n## 223           Mongolia      Asia 1982   2000.6031\n## 224           Mongolia      Asia 1987   2338.0083\n## 225           Mongolia      Asia 1992   1785.4020\n## 226           Mongolia      Asia 1997   1902.2521\n## 227           Mongolia      Asia 2002   2140.7393\n## 228           Mongolia      Asia 2007   3095.7723\n## 229            Myanmar      Asia 1952    331.0000\n## 230            Myanmar      Asia 1957    350.0000\n## 231            Myanmar      Asia 1962    388.0000\n## 232            Myanmar      Asia 1967    349.0000\n## 233            Myanmar      Asia 1972    357.0000\n## 234            Myanmar      Asia 1977    371.0000\n## 235            Myanmar      Asia 1982    424.0000\n## 236            Myanmar      Asia 1987    385.0000\n## 237            Myanmar      Asia 1992    347.0000\n## 238            Myanmar      Asia 1997    415.0000\n## 239            Myanmar      Asia 2002    611.0000\n## 240            Myanmar      Asia 2007    944.0000\n## 241              Nepal      Asia 1952    545.8657\n## 242              Nepal      Asia 1957    597.9364\n## 243              Nepal      Asia 1962    652.3969\n## 244              Nepal      Asia 1967    676.4422\n## 245              Nepal      Asia 1972    674.7881\n## 246              Nepal      Asia 1977    694.1124\n## 247              Nepal      Asia 1982    718.3731\n## 248              Nepal      Asia 1987    775.6325\n## 249              Nepal      Asia 1992    897.7404\n## 250              Nepal      Asia 1997   1010.8921\n## 251              Nepal      Asia 2002   1057.2063\n## 252              Nepal      Asia 2007   1091.3598\n## 253               Oman      Asia 1952   1828.2303\n## 254               Oman      Asia 1957   2242.7466\n## 255               Oman      Asia 1962   2924.6381\n## 256               Oman      Asia 1967   4720.9427\n## 257               Oman      Asia 1972  10618.0385\n## 258               Oman      Asia 1977  11848.3439\n## 259               Oman      Asia 1982  12954.7910\n## 260               Oman      Asia 1987  18115.2231\n## 261               Oman      Asia 1992  18616.7069\n## 262               Oman      Asia 1997  19702.0558\n## 263               Oman      Asia 2002  19774.8369\n## 264               Oman      Asia 2007  22316.1929\n## 265           Pakistan      Asia 1952    684.5971\n## 266           Pakistan      Asia 1957    747.0835\n## 267           Pakistan      Asia 1962    803.3427\n## 268           Pakistan      Asia 1967    942.4083\n## 269           Pakistan      Asia 1972   1049.9390\n## 270           Pakistan      Asia 1977   1175.9212\n## 271           Pakistan      Asia 1982   1443.4298\n## 272           Pakistan      Asia 1987   1704.6866\n## 273           Pakistan      Asia 1992   1971.8295\n## 274           Pakistan      Asia 1997   2049.3505\n## 275           Pakistan      Asia 2002   2092.7124\n## 276           Pakistan      Asia 2007   2605.9476\n## 277        Philippines      Asia 1952   1272.8810\n## 278        Philippines      Asia 1957   1547.9448\n## 279        Philippines      Asia 1962   1649.5522\n## 280        Philippines      Asia 1967   1814.1274\n## 281        Philippines      Asia 1972   1989.3741\n## 282        Philippines      Asia 1977   2373.2043\n## 283        Philippines      Asia 1982   2603.2738\n## 284        Philippines      Asia 1987   2189.6350\n## 285        Philippines      Asia 1992   2279.3240\n## 286        Philippines      Asia 1997   2536.5349\n## 287        Philippines      Asia 2002   2650.9211\n## 288        Philippines      Asia 2007   3190.4810\n## 289       Saudi Arabia      Asia 1952   6459.5548\n## 290       Saudi Arabia      Asia 1957   8157.5912\n## 291       Saudi Arabia      Asia 1962  11626.4197\n## 292       Saudi Arabia      Asia 1967  16903.0489\n## 293       Saudi Arabia      Asia 1972  24837.4287\n## 294       Saudi Arabia      Asia 1977  34167.7626\n## 295       Saudi Arabia      Asia 1982  33693.1753\n## 296       Saudi Arabia      Asia 1987  21198.2614\n## 297       Saudi Arabia      Asia 1992  24841.6178\n## 298       Saudi Arabia      Asia 1997  20586.6902\n## 299       Saudi Arabia      Asia 2002  19014.5412\n## 300       Saudi Arabia      Asia 2007  21654.8319\n## 301          Singapore      Asia 1952   2315.1382\n## 302          Singapore      Asia 1957   2843.1044\n## 303          Singapore      Asia 1962   3674.7356\n## 304          Singapore      Asia 1967   4977.4185\n## 305          Singapore      Asia 1972   8597.7562\n## 306          Singapore      Asia 1977  11210.0895\n## 307          Singapore      Asia 1982  15169.1611\n## 308          Singapore      Asia 1987  18861.5308\n## 309          Singapore      Asia 1992  24769.8912\n## 310          Singapore      Asia 1997  33519.4766\n## 311          Singapore      Asia 2002  36023.1054\n## 312          Singapore      Asia 2007  47143.1796\n## 313          Sri Lanka      Asia 1952   1083.5320\n## 314          Sri Lanka      Asia 1957   1072.5466\n## 315          Sri Lanka      Asia 1962   1074.4720\n## 316          Sri Lanka      Asia 1967   1135.5143\n## 317          Sri Lanka      Asia 1972   1213.3955\n## 318          Sri Lanka      Asia 1977   1348.7757\n## 319          Sri Lanka      Asia 1982   1648.0798\n## 320          Sri Lanka      Asia 1987   1876.7668\n## 321          Sri Lanka      Asia 1992   2153.7392\n## 322          Sri Lanka      Asia 1997   2664.4773\n## 323          Sri Lanka      Asia 2002   3015.3788\n## 324          Sri Lanka      Asia 2007   3970.0954\n## 325              Syria      Asia 1952   1643.4854\n## 326              Syria      Asia 1957   2117.2349\n## 327              Syria      Asia 1962   2193.0371\n## 328              Syria      Asia 1967   1881.9236\n## 329              Syria      Asia 1972   2571.4230\n## 330              Syria      Asia 1977   3195.4846\n## 331              Syria      Asia 1982   3761.8377\n## 332              Syria      Asia 1987   3116.7743\n## 333              Syria      Asia 1992   3340.5428\n## 334              Syria      Asia 1997   4014.2390\n## 335              Syria      Asia 2002   4090.9253\n## 336              Syria      Asia 2007   4184.5481\n## 337             Taiwan      Asia 1952   1206.9479\n## 338             Taiwan      Asia 1957   1507.8613\n## 339             Taiwan      Asia 1962   1822.8790\n## 340             Taiwan      Asia 1967   2643.8587\n## 341             Taiwan      Asia 1972   4062.5239\n## 342             Taiwan      Asia 1977   5596.5198\n## 343             Taiwan      Asia 1982   7426.3548\n## 344             Taiwan      Asia 1987  11054.5618\n## 345             Taiwan      Asia 1992  15215.6579\n## 346             Taiwan      Asia 1997  20206.8210\n## 347             Taiwan      Asia 2002  23235.4233\n## 348             Taiwan      Asia 2007  28718.2768\n## 349           Thailand      Asia 1952    757.7974\n## 350           Thailand      Asia 1957    793.5774\n## 351           Thailand      Asia 1962   1002.1992\n## 352           Thailand      Asia 1967   1295.4607\n## 353           Thailand      Asia 1972   1524.3589\n## 354           Thailand      Asia 1977   1961.2246\n## 355           Thailand      Asia 1982   2393.2198\n## 356           Thailand      Asia 1987   2982.6538\n## 357           Thailand      Asia 1992   4616.8965\n## 358           Thailand      Asia 1997   5852.6255\n## 359           Thailand      Asia 2002   5913.1875\n## 360           Thailand      Asia 2007   7458.3963\n## 361            Vietnam      Asia 1952    605.0665\n## 362            Vietnam      Asia 1957    676.2854\n## 363            Vietnam      Asia 1962    772.0492\n## 364            Vietnam      Asia 1967    637.1233\n## 365            Vietnam      Asia 1972    699.5016\n## 366            Vietnam      Asia 1977    713.5371\n## 367            Vietnam      Asia 1982    707.2358\n## 368            Vietnam      Asia 1987    820.7994\n## 369            Vietnam      Asia 1992    989.0231\n## 370            Vietnam      Asia 1997   1385.8968\n## 371            Vietnam      Asia 2002   1764.4567\n## 372            Vietnam      Asia 2007   2441.5764\n## 373 West Bank and Gaza      Asia 1952   1515.5923\n## 374 West Bank and Gaza      Asia 1957   1827.0677\n## 375 West Bank and Gaza      Asia 1962   2198.9563\n## 376 West Bank and Gaza      Asia 1967   2649.7150\n## 377 West Bank and Gaza      Asia 1972   3133.4093\n## 378 West Bank and Gaza      Asia 1977   3682.8315\n## 379 West Bank and Gaza      Asia 1982   4336.0321\n## 380 West Bank and Gaza      Asia 1987   5107.1974\n## 381 West Bank and Gaza      Asia 1992   6017.6548\n## 382 West Bank and Gaza      Asia 1997   7110.6676\n## 383 West Bank and Gaza      Asia 2002   4515.4876\n## 384 West Bank and Gaza      Asia 2007   3025.3498\n## 385        Yemen, Rep.      Asia 1952    781.7176\n## 386        Yemen, Rep.      Asia 1957    804.8305\n## 387        Yemen, Rep.      Asia 1962    825.6232\n## 388        Yemen, Rep.      Asia 1967    862.4421\n## 389        Yemen, Rep.      Asia 1972   1265.0470\n## 390        Yemen, Rep.      Asia 1977   1829.7652\n## 391        Yemen, Rep.      Asia 1982   1977.5570\n## 392        Yemen, Rep.      Asia 1987   1971.7415\n## 393        Yemen, Rep.      Asia 1992   1879.4967\n## 394        Yemen, Rep.      Asia 1997   2117.4845\n## 395        Yemen, Rep.      Asia 2002   2234.8208\n## 396        Yemen, Rep.      Asia 2007   2280.7699"},{"path":"basics-on-data-manipulation-in-r.html","id":"pivot-table","chapter":"3 Basics on data manipulation in R","heading":"Pivot table","text":"Pivottables functionality originally developed Excel, allows summarize data attributes. Lets example see work.look GDP database , see data also includes years GDPs. want summarize data country? Say country, just want average GDPs different years?. use function summarize dplr package. Like :Ok, now let code talk . Code like reading book; read first word forward start making visual representation sentence saying.Coding different. Lets take code read left right, like image . image can see part code saying.\nFigure 3.8: Filter function\ngood practice read code. Lets tray translate code (look image translation). go….first take dataframe called GDPData, group dataframe country, summarize data GDP mean values, oh, want resulting mean called mean_GDP. Easy right!.","code":"\ntail(GDPData)             #lets look at the column head of the GDP data we loaded earlier.##       country continent year gdpPercap\n## 1699 Zimbabwe    Africa 1982  788.8550\n## 1700 Zimbabwe    Africa 1987  706.1573\n## 1701 Zimbabwe    Africa 1992  693.4208\n## 1702 Zimbabwe    Africa 1997  792.4500\n## 1703 Zimbabwe    Africa 2002  672.0386\n## 1704 Zimbabwe    Africa 2007  469.7093\nGDPData %>% group_by(country) %>% summarize(mean_GDP = mean(gdpPercap))"},{"path":"basics-on-data-manipulation-in-r.html","id":"merge-data","chapter":"3 Basics on data manipulation in R","heading":"Merge data","text":"One common operation R coding merge dataframes common attributes (.e., common column).section Data structure types, sow merge matrices dataframes using rbind cbind functions, work different databases can paired simply appending one database . instance, columns exact order two databases.use merge function, call full_join dplr package, works cases data paired simply appending one database another. instance, columns /rows exact order.\nFigure 3.9: Merging function\nLet’s use example. know already loaded current section R database GPDs countries world.now collect another database average life expectancy per country, want put two databases together?Since data comes difference sources, chances differ number columns, order columns, number rows, etc. Basically, use rbind cbind case.pairing two database brutal force, copying data country one database, pasting row given country database. Say operation takes ten seconds country, 250 countries, job take 40 minutes, mention chance errors.Oh, remember country 40 years data. multiplyy 40 minutes times 40 years, end copying pasting day. Alternatively R merging . Lets try .First, lets load data life expectancy, placed Github folderIt good practice always check least portion database check loaded correctly,Lets check GDP database well.Ok, now two databases loaded R, one data GDP data life expectancy. Lets merge together, like :Now lets try read, line code, like :\nFigure 3.10: Merging function\ntranslate …basically, create new dataframe called MergeData, want merge full database GDPData ExpectancyData common attribute country year.","code":"\nExpectancyData=read.csv(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/Countries_LifeExpectancy.csv\")\ntail(ExpectancyData)      #lets look at the column head of the Expectancy data we just loaded.##         X  country continent year lifeExp\n## 1699 1699 Zimbabwe    Africa 1982  60.363\n## 1700 1700 Zimbabwe    Africa 1987  62.351\n## 1701 1701 Zimbabwe    Africa 1992  60.377\n## 1702 1702 Zimbabwe    Africa 1997  46.809\n## 1703 1703 Zimbabwe    Africa 2002  39.989\n## 1704 1704 Zimbabwe    Africa 2007  43.487\ntail(GDPData)            #lets look at the column head of the GDP data we loaded earlier.##       country continent year gdpPercap\n## 1699 Zimbabwe    Africa 1982  788.8550\n## 1700 Zimbabwe    Africa 1987  706.1573\n## 1701 Zimbabwe    Africa 1992  693.4208\n## 1702 Zimbabwe    Africa 1997  792.4500\n## 1703 Zimbabwe    Africa 2002  672.0386\n## 1704 Zimbabwe    Africa 2007  469.7093\nMergeData <- full_join(GDPData, ExpectancyData, by = c(\"country\",\"year\"))\ntail(MergeData)            #Check the results##       country continent.x year gdpPercap    X continent.y lifeExp\n## 1699 Zimbabwe      Africa 1982  788.8550 1699      Africa  60.363\n## 1700 Zimbabwe      Africa 1987  706.1573 1700      Africa  62.351\n## 1701 Zimbabwe      Africa 1992  693.4208 1701      Africa  60.377\n## 1702 Zimbabwe      Africa 1997  792.4500 1702      Africa  46.809\n## 1703 Zimbabwe      Africa 2002  672.0386 1703      Africa  39.989\n## 1704 Zimbabwe      Africa 2007  469.7093 1704      Africa  43.487"},{"path":"basics-on-data-manipulation-in-r.html","id":"subsetting-columns","chapter":"3 Basics on data manipulation in R","heading":"Subsetting columns","text":"new database just created, can see columns came original databases, need want use. , can create new database columns want delete columns like. Lets try.","code":""},{"path":"basics-on-data-manipulation-in-r.html","id":"deleting-columns","chapter":"3 Basics on data manipulation in R","heading":"Deleting columns","text":"simplest approach. Basically, set column want delete NULL. Like ,Now, try delete column “continent.x”.","code":"\nMergeData$X= NULL            #with this code I delete the column called X, which is probably an index number used by one of the data sources"},{"path":"basics-on-data-manipulation-in-r.html","id":"selecting-columns","chapter":"3 Basics on data manipulation in R","heading":"Selecting columns","text":"Obviously, many columns need, deleting columns may take , type column name want delete. Alternatively, can simply select columns need. Like ,syntax familiar already. indexing function used earlier [rows, columns].read code , basically….created new database called SelectedColumns, takes database MergeData select rows (nothing left comma) four columns listed vector comma.f","code":"\nSelectedColumns=MergeData[, c(\"country\",\"year\",  \"gdpPercap\", \"lifeExp\" ) ]\nhead(SelectedColumns)##       country year gdpPercap lifeExp\n## 1 Afghanistan 1952  779.4453  28.801\n## 2 Afghanistan 1957  820.8530  30.332\n## 3 Afghanistan 1962  853.1007  31.997\n## 4 Afghanistan 1967  836.1971  34.020\n## 5 Afghanistan 1972  739.9811  36.088\n## 6 Afghanistan 1977  786.1134  38.438"},{"path":"basics-on-data-manipulation-in-r.html","id":"adding-results-to-databases","chapter":"3 Basics on data manipulation in R","heading":"Adding results to databases","text":"point, simply manipulated data people collected. now want analysis data? Piece cake……lets tray, instance, new index, want see much cost year life country. Basically, divide much person country (.e., GDP per capita) life expectancy people country. Like ,cant translate code , column called ValueofLife dataframe SelectedColumns, divide gdpPercap lifeExp.Lets check results,Lets quiick summary see average per country,look result . Isn’t fascinating Afghanistan increase life expectancy one year simply people making $21.8 dollars !","code":"\nSelectedColumns$ValueofLife = SelectedColumns$gdpPercap / SelectedColumns$lifeExp \nhead(SelectedColumns)##       country year gdpPercap lifeExp ValueofLife\n## 1 Afghanistan 1952  779.4453  28.801    27.06313\n## 2 Afghanistan 1957  820.8530  30.332    27.06228\n## 3 Afghanistan 1962  853.1007  31.997    26.66190\n## 4 Afghanistan 1967  836.1971  34.020    24.57957\n## 5 Afghanistan 1972  739.9811  36.088    20.50491\n## 6 Afghanistan 1977  786.1134  38.438    20.45146\nSelectedColumns %>% group_by(country) %>% summarize(mean_valueOfLife = mean(ValueofLife))## # A tibble: 142 x 2\n##    country     mean_valueOfLife\n##    <chr>                  <dbl>\n##  1 Afghanistan             21.8\n##  2 Albania                 46.7\n##  3 Algeria                 73.7\n##  4 Angola                  97.2\n##  5 Argentina              129. \n##  6 Australia              263. \n##  7 Austria                273. \n##  8 Bahrain                271. \n##  9 Bangladesh              16.3\n## 10 Belgium                266. \n## # ... with 132 more rows"},{"path":"basics-on-data-manipulation-in-r.html","id":"exercise-3","chapter":"3 Basics on data manipulation in R","heading":"Exercise","text":"","code":""},{"path":"basics-on-data-manipulation-in-r.html","id":"homework-1","chapter":"3 Basics on data manipulation in R","heading":"Homework","text":"following exercise:Open new file Tinn-R. write R code following:Load GDP life expectancy databases, already loaded. Also add database called, “Countries_Population.csv”, path used two databases thata re online Github folder.Load GDP life expectancy databases, already loaded. Also add database called, “Countries_Population.csv”, path used two databases thata re online Github folder.Merge three databases, country year.Merge three databases, country year.Remove unnecessary columns (want country, year, GDP per capita, life expectancy population).Remove unnecessary columns (want country, year, GDP per capita, life expectancy population).Calculate total GDP nation (basically, multiple per capita GDP number people).Calculate total GDP nation (basically, multiple per capita GDP number people).Calculate average Total GDP country.Calculate average Total GDP country.Save necessary code Tinn ready next class.","code":""},{"path":"basic-plots.html","id":"basic-plots","chapter":"4 Basic plots","heading":"4 Basic plots","text":"Making good quality plots fundamental successful delivery scientific finding. best story one can told figures o.surprising, making good figures demanding endeavor scientific process, least two steps .First, need decide type figure best illustrates point make. deceiving reader, rather use convincing available figure. course, problem different needs, just need familiar different types figures available, better know best figure case problem.\nFigure 4.1: R plots\nR several built-functions sorts plots. can even create types plots. packages even allow create plots online, people can interact data. Others let animate data.can check gallery R plots .\nFigure 4.2: Animated R plot\nSecond, issue standards figure. relates editorial guidelines need follow deliver figure.scientific journal different guidelines figures.journals allow place multiple figures together, others like letters given size font type, journals like black white, others want figures certain dimensions, etc.need know guidelines specific journal want publish ensure figures standard.publishing paper, still good follow guidelines figure formatting journal, know figures professional standards required field.Regardless guidelines specific journal, important figure clear enough understood. key conditions figure:Ensure axes names. e.g. Human population.Ensure axes names. e.g. Human population.Ensure brackets axes units. e.g. Human population (Number people)Ensure brackets axes units. e.g. Human population (Number people)Ensure axes tickmarks.Ensure axes tickmarks.Ensure data displayed. constraint values shown axes, sure remove data accident.Ensure data displayed. constraint values shown axes, sure remove data accident.Ensure lines axes black color. times axes colors grey. problem setting printed, axes may appear, depending good printer .Ensure lines axes black color. times axes colors grey. problem setting printed, axes may appear, depending good printer .Ensure thickness axes least 1 point. times lines thin, creates problems printing well.Ensure thickness axes least 1 point. times lines thin, creates problems printing well.possible use black white figures. color common, many people take photocopies papers reports common black white. cases color figure troubles.possible use black white figures. color common, many people take photocopies papers reports common black white. cases color figure troubles.pLets check common types plots R.","code":""},{"path":"basic-plots.html","id":"scatterplots","chapter":"4 Basic plots","heading":"Scatterplots","text":"Scatterplots allow see patterns variation two variables. create plot R, simply type plot(y~x). Lets say want plot second third column dataframe.Now comes different settings needed format figure. Almost attribute figure R can formatted.Next, show format parameters. know format given parameter figure, able format parameter. Obviously figure tens parameters can modify, expect know memory, able know find given parameter, now know asking friend Google.Let’s modify parameters figure .instance, axis names? can add axis names using command xlab ylab inside plot command, like :different type symbols?\nFigure 4.3: R plot symbols\nR offers 25 different symbol types (Figure ), can call using parameter pch, like :colors points?. controlled using col parameter. Like ,symbols can also control filling color, using bg parameter. Like ,can also control size symbols using cex parameter. Like ,Remember, tens parameters can modify plot. need know exactly standards required journal want publish ensure deliver best figures required.","code":"\n#Lets create some dummy data\nDataFrame<- data.frame( x1 = c(rep(1,250)),     # in Column 1 I repeat the number 1 for 250 times\n                        x2 = seq(1:250), #Column 2 I create a sequence of numbers from 1 to 250\n                        x3 = sample(seq(1:1000),250)) # select 250 random numbers between 1 and 10000\n#Now lets plot columns 2 and 3 of that data\nplot(DataFrame[,2]~DataFrame[,3])\n#You can also plot by column name using the $ sign as indicated earlier to call a column\nplot(DataFrame$x2~DataFrame$x3)\nplot(DataFrame[,2]~DataFrame[,3],xlab=\"Years\", ylab=\"Precipitation\")\nplot(DataFrame[,2]~DataFrame[,3],xlab=\"Years\", ylab=\"Precipitation\", pch=22)\nplot(DataFrame[,2]~DataFrame[,3],xlab=\"Years\", ylab=\"Precipitation\", pch=22, col=\"red\")\nplot(DataFrame[,2]~DataFrame[,3],xlab=\"Years\", ylab=\"Precipitation\", pch=22, col=\"red\", bg=\"blue\")\nplot(DataFrame[,2]~DataFrame[,3],xlab=\"Years\", ylab=\"Precipitation\", pch=22, col=\"red\", cex=2)"},{"path":"basic-plots.html","id":"histograms","chapter":"4 Basic plots","heading":"Histograms","text":"Histograms important type plot lets see frequency certain values appear data. type plot also call frequency distribution. create histogram R, use command hist(x), x, vector data want plot.Lets create frequency distribution GDP (Gross Domestic Producto) countries world, using csv file loaded earlier,Just scatterplot, can improve appearance figure. Lets start axis name.title?. pretty, ah?. default R. remove , set “main” parameter NULL, like :journals allow put tittles plots.want rather keep tittle, different tittle, replace NULL title want, like :","code":"\n#lets reload the data, just in case you have not loaded it\nGDPData=read.csv(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/Countries_GDP.csv\")\n\nhead(GDPData)   #now lets check the data##       country continent year gdpPercap\n## 1 Afghanistan      Asia 1952  779.4453\n## 2 Afghanistan      Asia 1957  820.8530\n## 3 Afghanistan      Asia 1962  853.1007\n## 4 Afghanistan      Asia 1967  836.1971\n## 5 Afghanistan      Asia 1972  739.9811\n## 6 Afghanistan      Asia 1977  786.1134\nhist(GDPData$gdpPercap) #now lets create a frequency of number of countries by GDP\nhist(GDPData$gdpPercap, xlab=\"GDP countries in USDollars\")\nhist(GDPData$gdpPercap, xlab=\"GDP countries in USDollars\",main=NULL) \nhist(GDPData$gdpPercap, xlab=\"GDP countries in USDollars\",main=\"Countries of the World\") "},{"path":"basic-plots.html","id":"density-plots","chapter":"4 Basic plots","heading":"Density plots","text":"times, use scatterplots many data points, chances points overlap, create misleading visual representation data overlapping data points appear single point.better representation data type case use density plots, space entire plot gridded equal size cells, number point overlapping cell counted displayed. Let’s example.figure can tell hard make sense pattern many points overlap. One solution use density plot. different packages . use hexbin package.Now can see data, plotting hexbin/grid. can play different settings hexbin package, typing ?hexbin R console.can also display plots side side using par function.","code":"\n#lets create a dummy dataset of many points\n# Create data\nx <- rnorm(mean=1.5, 5000)\ny <- rnorm(mean=1.6, 5000)\n\n#lets plot that data\nplot(y~x)\n# Packages\nlibrary(hexbin)\nlibrary(RColorBrewer) #This library allows you to create color scales, we will see this later.\n \n# Make the plot\nbin<-hexbin(x, y, xbins=40) #hexbin is the function to grid the points in the plot. You can use different number of grids.\nmy_colors=colorRampPalette(rev(brewer.pal(11,'Spectral'))) #this is the color scale\nplot(bin, main=\"\" , colramp=my_colors , legend=F )  #now lets plot the hexbin/grid\npar(mar = c(4, 4, .1, .1))\nplot(bin,colramp=my_colors)  #hexbin plot\nplot(y~x)                    #Scatter plot"},{"path":"basic-plots.html","id":"plotting-maps","chapter":"4 Basic plots","heading":"Plotting maps","text":"R also provides powerful tools analyze geographical data. Pretty much anything can ARCgis, can R; key difference R free!.Let’s see plot map R. Lets start getting spatial data.collected global data human population . page full types global scale data may find interesting.use package raster purpose loading plotting map.code , create variable called GlobalPopulation global data human population.Note load data raster, use method used load .csv file. , using path file, preceded command reads file.case, use command raster read file rather read.csv. data want load raster csv file.plot raster, plot variable, like :can use different color scale using RColorBrewer library. Lets try,also premade color blind friendly scales. commonly used called viridis. different options scales offer:\nFigure 4.4: Viridis color scales\nLets now plot map, using magma scaleWell, reason places world soo many people makes rest world look comparison like world empty. problem scale comparison.cases extremes data far part, recommended log transform data, brings extremes closer. Let’s see log-transforming ,Now can better appreciate patterns variation, need mindful data logarithmic.R also allows reproject data different projection types. aware many issues displaying maps different projections, topic another course.Hmm raster world’s population missing outline world. , package called maps. Let’s try.Hmm packages provides outline world points. really want lines. Ok, can use maptools convert points linesGreat, now raster world’s human population outline world. Let’s put together","code":"\nlibrary (raster)\nGlobalPopulation=raster(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/GlobalHumanPopulation2020.tif\") #load the raster.\nplot (GlobalPopulation)\nlibrary(RColorBrewer)  #this library allows you to create your own scales\n#Lets create a color scale between yellow and red colors\nColorScale <- colorRampPalette(c(\"yellow\",\"red\"))\nplot(GlobalPopulation,col =ColorScale(100)) #plot human population with 100 color in my scale\nlibrary(viridis)## Loading required package: viridisLite\nplot(GlobalPopulation,col =magma(1000)) #plot human population with 100 color in my scale\nplot(log(GlobalPopulation),col =magma(1000)) #log transform human population\nRaster <- projectRaster(GlobalPopulation, crs='+proj=moll', over=T) #reproject raster to mollweide projection## Warning in rgdal::rawTransform(projto_int, projfrom, nrow(xy), xy[, 1], : 55946\n## projected point(s) not finite\nplot(Raster)         \nlibrary(maps) # this library offers several choices for background maps## \n## Attaching package: 'maps'## The following object is masked from 'package:viridis':\n## \n##     unemp## The following object is masked from 'package:purrr':\n## \n##     map\nworldmap <- map(\"world\", plot=F,interior = F)   #create map of the world\nplot(worldmap) #check the map\nlibrary(maptools)    #library to convert points to lines## Checking rgeos availability: TRUE\nworldmapLines <- map2SpatialLines(worldmap, proj4string=CRS(\"+proj=longlat +datum=WGS84\")) \nplot( worldmapLines)     #check the map\n plot(GlobalPopulation)      #first plot your raster\n plot(worldmapLines,add=T)   #then add the outline of the world on top."},{"path":"basic-plots.html","id":"animated-plots","chapter":"4 Basic plots","heading":"Animated plots","text":"animated plots?. recall database socio-economic data countries world, notice variable collected different years. year display?. Well can display see pattern change time using animated plot displays year sequentially. animated plots, use ggplot2 gganimate libraries/packages. iAs customary, lets check data loaded display correctly.seems data loaded fine. three variables interest gdpPercap (GDP per capita), lifeExp (life expectancy), year continent. (note continent double, column dataset merged, specific merging continent well).Lets create animated plot data. Since code needed require several lines, recommended create code Tinn-R firts. done, copy paste R console.code generate plot , now appear working folder.can find working directory typing getwd() R console.can also set working folder different path using setwd(); brakets put path folder want R deposit result codes.\nFigure 4.5: Animated R plot\n","code":"\n#first lets bring the data.\nExpectancyData=read.csv(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/Countries_LifeExpectancy.csv\")\nGDPData=read.csv(\"https://raw.githubusercontent.com/Camilo-Mora/GEO380/main/Datasets/Countries_GDP.csv\")\n\n#lets merge those two databases, using the dplyr packaged that we used earlier.\nlibrary(dplyr)  #load package to merge database\n\n#merge the databases\nMergeData <- full_join(GDPData, ExpectancyData, by = c(\"country\",\"year\"))\ntail (MergeData)##       country continent.x year gdpPercap    X continent.y lifeExp\n## 1699 Zimbabwe      Africa 1982  788.8550 1699      Africa  60.363\n## 1700 Zimbabwe      Africa 1987  706.1573 1700      Africa  62.351\n## 1701 Zimbabwe      Africa 1992  693.4208 1701      Africa  60.377\n## 1702 Zimbabwe      Africa 1997  792.4500 1702      Africa  46.809\n## 1703 Zimbabwe      Africa 2002  672.0386 1703      Africa  39.989\n## 1704 Zimbabwe      Africa 2007  469.7093 1704      Africa  43.487\n# for the figures we will need \n    library(ggplot2)      #this package is to do all sorts of plots\n    library(gganimate)    #this package does the animation\n \n# Make a ggplot, but add frame=year: one image per year\n    ggplot(MergeData, aes(gdpPercap, lifeExp, color = continent.x)) +\n      geom_point() +\n      scale_x_log10() +\n      theme_bw() +\n# gganimate specific bits:\n      labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +\n      transition_time(year) +\n      ease_aes('linear')\n\n# Save at gif:\n    anim_save(\"AnimatedPlot.gif\")"},{"path":"basic-plots.html","id":"saving-plots","chapter":"4 Basic plots","heading":"Saving plots","text":"course, plot R want use somewhere else. quick dirty way get figure R use simple PrintScreen keyboard, create figure whatever screen moment.\nFigure 4.6: Pixelation effect figure format\nclicking Print screen, open software, like Paint, Word, PowerPoint, etc., right click new document click Paste display figure.course, R offers many formats save plots. save figure PDF using function “pdf”.Basically, function pdf requires write name want file (e.g. “RPlot.pdf”), big want plot, size letters, options. Type ?pdf see additional settings.way save figure R like : Firsts, write line code indicating type file want save . creates clean sheet, can place plot plots. done figure figures, need line code called dev.(); closes sheet save file. Lets try,now check working folder, file called RPlot.pdf, figure just created. course, can edit figure like, showed Scatterplot section.benefit l saving files PDF resolution never affected. can zoom PDF file resolution always . turn, types figures like jpeg, gif, png, etc. need define resolution advance, zoom type figure formats notice pixelation.\nFigure 4.7: Pixelation effect figure format\n","code":"\npdf(\"RPlot.pdf\", width = 3, height = 3,pointsize=8,paper=\"letter\")\nplot(bin,colramp=my_colors)  #hexbin plot\ndev.off()"},{"path":"basic-plots.html","id":"excersise","chapter":"4 Basic plots","heading":"Excersise","text":"Now know manipulate data basic figures. chapter’s exercise, please find guidelines figures journal Nature plot according standards required journal.Plot relationship GDP population size, using databases provided already, include basic criteria figures mentioned start chapter.Place plot Word document submitting homework chapter.","code":""},{"path":"descriptive-statistics.html","id":"descriptive-statistics","chapter":"5 Descriptive statistics","heading":"5 Descriptive statistics","text":"Ok, guys, now know :set question,reformulate question based literature review,set error proof experiment,enter manipulate data R anddo basic plots R.Nice, ah?.Now move analysis data collect. process called inference; basically, drowning conclusion based numbers interpretation numbers.iiiOnce finish experiment collect data, things :First, need visualize data, using plots learned prior chapter.Second, need use set available metrics describe data general. need get big picture first. BIG picture metrics called DESCRIPTIVE STATISTICS.Say get hired analyze visiting times costumers store. manager wants ensure costumers always attended wants hire people pick hours.tackled problem, probably want record time people walk store. Let’s say 100 people came day.want report findings manager, just go tell , first costumer came 7 , second 7:10, third 8:20 ….(one hour later)…100th costumer came 7:00pm.likely pattern data, manager really perceived data presented raw form. manager really make decision solve problem based , may reason keep .Really want describe data , facilitate decision.metrics used describe data overall called descriptive statistics. metrics commonly divided dealing middle data (-call metrics central tendency) dealing variable data (-call metrics dispersion).","code":""},{"path":"descriptive-statistics.html","id":"data-distributions","chapter":"5 Descriptive statistics","heading":"Data distributions","text":"mentioned several times class, first thing always analyzing data create visual representation. need see general tendencies data, commonly start frequency distribution.Lets image plot number seedlings (points) height nursery. Interesting, ahh?. type distribution called bimodal (two peaks data). Clearly, something going nursery, seedlings particularly better others.pThe distribution called uniform distribution, number just likely.oIn figure , can explore different distributions,","code":""},{"path":"descriptive-statistics.html","id":"central-tendency","chapter":"5 Descriptive statistics","heading":"Central tendency","text":"Central tendency refers metrics attempt describe middle data. main metrics central tendency mean (also called average), median, mode.\nFigure 5.1: Measures central tendency\nlLet’s create dummy data see metrics intended show, interpret use .","code":"\nset.seed (10)\ny <- rnorm(1000) # the function rnorm allows you to create a random set of numbers from a normal distribution\n\n#lets now plot that data using the hist function, you already know how to use:\nhist(y, main = \"Normal Distribution\",breaks = 30)"},{"path":"descriptive-statistics.html","id":"the-arithmetic-mean","chapter":"5 Descriptive statistics","heading":"The arithmetic mean","text":"arithmetic mean average numbers. easy calculate: add numbers, divide many numbers .Mathematically, expressed :\\[\\begin{equation}\n\\bar{X} = \\frac{\\sum_{=1}^n X_i}{n}\n\\end{equation}\\]mean sample denoted wit letter \\(\\bar{X}\\); times include horizontal bar letter.symbol looks like pacman, \\(\\sum_{}\\), call summation. lower letter \\(\\) indicates summation starts first number (.e., =1), higher letter n, means last number. \\(Xi\\) means value. short, numerator equation says: sum values starting first one last one. \\(n\\) indicates sample size total number values database (average population, likely see capital letter \\(N\\) instead lowercase \\(n\\) ).\nFigure 5.2: stupid mean\nyIn R, mean calculated function mean.may noted added ‘na.rm = TRUE’ mean function. command used caution calculate mean even empty values. Lets check,Now, include command ‘na.rm = TRUE’, re-calculation excluding missing value.Alright, lets keep going. can visualize mean histogram using function abline, put name using text function, like :","code":"\nMEAN=mean (y, na.rm = FALSE)  #here I calculate the mean, and assign it to a variable.\nMEAN           #to display the variable, simply type it, and click enter## [1] 0.01137474\nVectorMissingAValue <- c(12,7,3,4.2,18,2,54,-21,8,-5,NA)#here I created a vector of values, incluidng a missing value NA (NA in R stands for Not Available)\nmean (VectorMissingAValue)  #If I calculate the mean of a vector with missing values I get## [1] NA\nmean (VectorMissingAValue,na.rm = TRUE)  ## [1] 8.22\nhist(y, main = NULL,breaks = 30, ylim=c(0,100),)\nabline(v=MEAN, col=\"red\",lwd=5) #abline put a line in a figure...you use v for vertical and h for horizontal, the value that proceeds is where the line will be drawn.\n\n\ntext(\"Mean\",x=MEAN,y=100, col=\"blue\") #the text function places a label on your figure at the given x and y position you like...there are several other parameters you can control. You can also use the function *legend*, which allows you more controls, including background colors."},{"path":"descriptive-statistics.html","id":"the-trimmed-mean","chapter":"5 Descriptive statistics","heading":"The trimmed mean","text":"several variations calculate mean, instance trimmed mean. One problems arithmetic mean can strongly impacted extreme values. cases, recommend trim extremes calculate mean resulting values.Commonly, %5 trimmed mean satisfy. name indicates, remove top bottom 5% data, calculate mean values.Lets try simple example. Say measured time took 20 students run 100m.individual values seconds 10, 20, 23, 23, 22, 20, 25, 22, 20, 25, 22, 20, 25, 20, 21, 21, 23, 21, 24, 120.calculate R, put values vector calculate mean,data, can tell one student fast (took 10 secs) another one slow (took 120secs). Lets try 5% trimmed mean,First, sort data smallest largest,10,20,20,20,20,20,21,21,21,22,22,22,23,23,23,24,25,25,25,120Now remove first last (.e, 5% 20 1, delete bottom top one records, red numbers array).Now calculate mean resulting data -call 5% trimmed mean:5% trimmed mean 22.06 compared arithmetic mean 26.35.","code":"\nvals=c(10,20,23,23,22,20,25,22,20,25,22,20,25,20,21,21,23,21,24,120)\n  \n  mean(vals)## [1] 26.35\nTrimmedvals=c(20,23,23,22,20,25,22,20,25,22,20,25,20,21,21,23,21,24)\n  \nmean(Trimmedvals)## [1] 22.05556"},{"path":"descriptive-statistics.html","id":"the-weighted-average","chapter":"5 Descriptive statistics","heading":"The weighted average","text":"Sometimes wish average numbers, want assign importance, \nweight, numbers. used weighted average, calculated :\\[\\begin{equation}\nWeighted \\ average= \\frac{\\sum_{=1}^n (X_i * w)}{\\sum_{=1}^n  w}\n\\end{equation}\\]\\(Xi\\) data value w weight assigned data value.Lets try example.Suppose professor tells grade based midterm final exam, based 100 possible points. However, final exam worth 60% grade midterm 40%. determine average score reflect different weights? average need weighted average.scored 83 midterm 95 final, final grade?.\\[\\begin{equation}\nWeighted \\ average= \\frac{(83*40)+(95*60)}{(40+60)}\n\\end{equation}\\]final grade 90.2. average high enough earn , hope get class!. paying attention, two tokens: jj","code":""},{"path":"descriptive-statistics.html","id":"the-median","chapter":"5 Descriptive statistics","heading":"The median","text":"median (also referred 50th percentile) middle value sample ordered values. Half values median half median.calculate median, start sorting values lowest highest, median value middle.set numbers odd, median single value middle sorted list. vector values indicating price different candy.\nFigure 5.3: Median calculation odd number values\nset numbers even, problem two numbers right middle sorted vector. case report arithmetic mean two values middle.\nFigure 5.4: Median calculation even number values\nyIn R, median calculated function median.pLet’s plot median mean value histogram .","code":"\nMEDIAN=median (y)  #here I calculate the mean, and assign it to a variable.\nMEDIAN           #to display the variable, simply type it, and click enter## [1] -0.003001333\nhist(y, main = NULL,breaks = 30, ylim=c(0,110),)\n\n#lets plot the mean\nMEAN=mean(y)\nabline(v=MEAN, col=\"red\",lwd=5) \ntext(\"Mean\",x=MEAN,y=110, col=\"red\",pos=4) #pos=4 means, to place the text to the right of the coordinates xy.\n\n# now the median\nabline(v=MEDIAN, col=\"blue\",lwd=3, lty=2) #I plot the median in blue to distinguish from the mean\ntext(\"Median\",x=MEDIAN,y=100, col=\"blue\", pos=2) "},{"path":"descriptive-statistics.html","id":"the-mode","chapter":"5 Descriptive statistics","heading":"The mode","text":"mode simply common value data.R standard -built function calculate mode. create user function calculate mode dataset. function takes vector input gives mode value output.Now let’s use new functionUnlike mean median, mode can also used character data (.e., words). instance, want know common name USA?. can use mode.Let’s plot mode histogram mean median working .noted mean, median mode almost case. data normally distributed (follow normal distribution).Let’s see happens data skew.kIf see two skewed distributions , notice mean pulled extreme values distribution. critical consideration arithmetic mean, affected extreme values -call outliers.basic rule thumb look mean median. ’re can just use mean, ’s easy average reader understand. differ significantly report , just report medianWith skew distributions becomes important distinction mean median. Lets check example can deceive conclusion based reporting mean.\nFigure 5.5: Income distribution USA\nfigure shows household income people USA. Clearly, data follows right distribution. distribution, mean larger median mode. report mean , may create illusion people get paid well USA, reality get paid much less.case, mean increases primarily result wealthy becoming wealthier. concerned average American , median actually better measure understand status.figure summarizes central tendency metrics type data distribution.\nFigure 5.6: Central tendendy metrics skew distributions\n","code":"\ngetmode <- function(v) {   # the function will take a vector of values\n   uniqv <- unique(v)      #select all the unique values in the vector \n   uniqv[which.max(tabulate(match(v, uniqv)))] #stimate the number of times each value appears and return the largest\n}\nMODE=getmode(y)  #here I calculate the mode, and assign it to a variable.\nMODE           #to display the variable, simply type it, and click enter## [1] 0.01874617\n# Create the vector with characters.\nNAMES <- c(\"Peter\", \"Carl\", \"Darrell\", \"John\", \"Peter\")\n\ngetmode(NAMES)  #here I calculate the mode, and assign it to a variable.## [1] \"Peter\"\nhist(y, main = NULL,breaks = 30, ylim=c(0,110),)\n\n#lets plot the mean\nabline(v=MEAN, col=\"red\",lwd=6) \ntext(\"Mean\",x=MEAN,y=110, col=\"red\",pos=4) \n\n# now the median\nabline(v=MEDIAN, col=\"blue\",lwd=4, lty=2) #I plot the median in blue to distinguish from the mean\ntext(\"Median\",x=MEDIAN,y=100, col=\"blue\", pos=2) \n\n#now let's plot the mode\nMODE=getmode(y)\nabline(v=MODE, col=\"orange\",lwd=4, lty=3) #I plot the median in blue to distinguish from the mean\ntext(\"Mode\",x=MODE,y=90, col=\"orange\", pos=4) "},{"path":"descriptive-statistics.html","id":"dispersion","chapter":"5 Descriptive statistics","heading":"Dispersion","text":"Dispersion refers describing spread data. different metrics may help describe variability data.","code":""},{"path":"descriptive-statistics.html","id":"the-minimum-and-the-maximum","chapter":"5 Descriptive statistics","heading":"The minimum and the maximum","text":"basic metrics data dispersion minimum maximum. names indicate lowest highest values data.R, minimum maximum calculated function min max, respectively.Let’s plot :","code":"\nhist(y, main = NULL,breaks = 30, ylim=c(0,110),)\n\n#lets plot the mean\nabline(v=MEAN, col=\"red\",lwd=6) \ntext(\"Mean\",x=MEAN,y=110, col=\"red\",pos=4) \n\n# now the median\nabline(v=MEDIAN, col=\"blue\",lwd=4, lty=2) #I plot the median in blue to distinguish from the mean\ntext(\"Median\",x=MEDIAN,y=100, col=\"blue\", pos=2) \n\n#now let's plot the mode\nabline(v=MODE, col=\"orange\",lwd=4, lty=3) #I plot the median in blue to distinguish from the mean\ntext(\"Mode\",x=MODE,y=90, col=\"orange\", pos=4) \n\n\n#now let's plot the minimum\nMINIMUM=min(y)\nabline(v=MINIMUM, col=\"dark grey\",lwd=4, lty=3) #I plot the median in blue to distinguish from the mean\ntext(\"Minimum\",x=MINIMUM,y=90, col=\"dark grey\", pos=4) \n\n#now let's plot the maximum\nMAXIMUM=max(y)\nabline(v=MAXIMUM, col=\"dark grey\",lwd=4, lty=3) #I plot the median in blue to distinguish from the mean\ntext(\"Maximum\",x=MAXIMUM,y=90, col=\"dark grey\", pos=2) "},{"path":"descriptive-statistics.html","id":"the-range","chapter":"5 Descriptive statistics","heading":"The range","text":"Another simple metric describe dispersion data called range.u range difference smallest largest number data. course, within range everything possible, descriptive useful many situations, always best indicator inference.\nFigure 5.7: effect range\n","code":""},{"path":"descriptive-statistics.html","id":"the-percentile","chapter":"5 Descriptive statistics","heading":"The percentile","text":"percentile indicates percentage values smaller given value.example, score 75 points test, ranked 85th percentile, means 85% students took exam worse . way report like : “85th percentile 75 points”.percentile calculated?. Simple,Rank values database smallest largest, called sorted vector.Rank values database smallest largest, called sorted vector.Multiply number values database given percentile want find fraction (want 90th percentile, fraction 0.9), call resulting number index \\(Xth\\) pointMultiply number values database given percentile want find fraction (want 90th percentile, fraction 0.9), call resulting number index \\(Xth\\) pointNow go back sorted vector, starting first number vector move right value located Xth point. value located Xth point given percentile.Now go back sorted vector, starting first number vector move right value located Xth point. value located Xth point given percentile.Lets example,Take population ten rabbits , say want know 80th percentile height rabbits?\nFigure 5.8: rabbit population\ninterested height, measure heights. Say 37, 15, 35, 36, 5, 40, 41, 68, 45, 56cm (making numbers , overthink size rabbits).sort rabbits height. Say sorted heights 5, 15, 35, 36, 37, 40, 41, 45, 56 68cm.\nFigure 5.9: rabbits sorted height\nNext, multiply percentile interest (80th) fraction (.e., 0.8) number rabbits (10). 80th percentile height height whatever rabbit sitting 8th position. case number 45. 80th percentile rabbit population 45cm.\nFigure 5.10: 80th percentile\nR, percentile value vector values calculated function quantile. Basically, need enter array values, quantile need (fraction).Lets take height rabbits .","code":"\nMyRabbits=c(37, 15, 35, 36, 5, 40, 41, 68, 45, 56) #vector of rabbit height, it does no\n\nquantile(MyRabbits, .8,type = 1)                  # the type parameter allows you to use different ways to approximate the value. check ?quantile  for more details## 80% \n##  45"},{"path":"descriptive-statistics.html","id":"the-quantile","chapter":"5 Descriptive statistics","heading":"The quantile","text":"quantiles specific percentiles divide data equal amounts. Quantiles can take different names. instance, quartiles break data four groups, deciles ten groups, percentiles 100 groups.Lets take quartile example. case, data needs broken four groups, breaking points 0.25, 0.5, 0.75. break points create four different categories can group data (0 0.25], (0.25 0.5], (0.5 0.75] (0.75, 1]. can also called 1st quartile, 2nd quartile, 3rd quartile 4th quartile. can see indexes times called Q1, Q2, Q3, Q4.Lets display quartiles normal distribution.","code":"\nlibrary (RColorBrewer)\nlibrary(dplyr)\nlibrary(scales)\nset.seed(3)  \n\n\ndt <- data.frame(x=rbeta(20000,100,100)*20000)             #Lets create some dummy normal data\ndt$x <- rescale(dt$x,to = c(1, 100), from = range(dt$x))   #I rescale the data from 1 to 100 to better visualize the percentage results\n\n\ndt=dt %>% arrange(x)                  #Sort values from smallest to largest\ndt$Position=1:nrow(dt)                #Rank each value from smallest to largest\ndt$y=(dt$Position/nrow(dt)) *100      #Assign the percentile position of each value\n\n#Create colors to make the plot look nicer\nColSca <- brewer.pal(9, 'YlOrRd')   #Create a vector of nice colors in the  YlOrRd color scale\nColSca <- colorRampPalette(ColSca)  #create a color ramp for the colors above\nColors= ColSca(110) #create list of 100 colors in the ramp above\n\n#create histogram\nhist(dt$x, col=Colors,main = NULL,breaks = 100, ylim=c(0,800),xlab=\"Percent\", ylab=\"Frequency\")  \n\n#calculate and add the quartiles and their names to the histogram.\nProb=c(0.25,0.5,0.75,1)  # this is the list of values that define my four quartiles\nQuartiles=quantile(dt$x,Prob ,type = 1)  #calculate the quartiles of my data\n\nabline(v=Quartiles, col=\"grey\",lwd=4, lty=1) #I plot the quartiles\n\n# now lets put names \nNames=c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")   #vector of names for my quartiles\ntext(Names,x=Quartiles,y=800, col=\"black\", pos=2) #place quartile names at y=800 and x= quartile values"},{"path":"descriptive-statistics.html","id":"the-variance","chapter":"5 Descriptive statistics","heading":"The variance","text":"variance measures far set numbers spread average value. Put another way, variance measures average degree number different mean.sample, variance calculated :\\[\\begin{equation}\nVariance = s^2=\\frac{\\sum_{=1}^n (X_i-\\bar{X})^2}{n-1}\n\\end{equation}\\]population, variance calculated :\\[\\begin{equation}\nVariance = σ^2=\\frac{\\sum_{=1}^n (X_i-u)^2}{N}\n\\end{equation}\\]parameter \\((X_i-\\bar{X})^2\\) called sum squares. Becuase value compared mean, square , result zero negative values cancel positive values. Squaring difference \\((X_i-\\bar{X})\\) make quantity nonnegative.things may notice two equationss.equations almost identical arithmetic mean. Indeed, . variance can thought average differences value mean.equations almost identical arithmetic mean. Indeed, . variance can thought average differences value mean.calculating variance population use capital letter N lowercase letter n sample.calculating variance population use capital letter N lowercase letter n sample.variance population defined letter \\(σ^2\\); sample lowercase \\(s^2\\).variance population defined letter \\(σ^2\\); sample lowercase \\(s^2\\).calculating variance sample, denominator n-1 population N. Since random sample usually contain extreme data values (large small), divide \\(n-1\\) formula s make s little larger divided n. called unbiased estimate s. population data values, extreme data values , course, present, divide N instead \\(n-1\\).calculating variance sample, denominator n-1 population N. Since random sample usually contain extreme data values (large small), divide \\(n-1\\) formula s make s little larger divided n. called unbiased estimate s. population data values, extreme data values , course, present, divide N instead \\(n-1\\).Let’s calculate variance using neat example, took .group children measured height dogs mm.\nFigure 5.11: Sample dogs heights\nheights (shoulders) : 600mm, 470mm, 170mm, 430mm 300mm.Next, calculate sample mean height, 394 mm (green line figure ).j\nFigure 5.12: Sample dogs heights\nNext, dog, calculate difference height mean (Basically, height red green line ),\nFigure 5.13: Sample dogs heights\nLet’s isolate individual differences:\nFigure 5.14: Sample dogs heights\nFollowing equation variance sample, square difference, add divide sample size minus one.\\[\\begin{equation}\nVariance = s^2=\\frac{206^2 + 76^2 + (−224)^2 + 36^2 + (−94)^2}{5-1}\n\\end{equation}\\]\\[\\begin{equation}\nVariance = s^2=27130mm^2\n\\end{equation}\\]R, variance calculate function var,Hmm, right?. simplest variance understand variance = 0, means values . reality, however, variance results normally large numbers hard interpret intuitively. variance allows calculate standard deviation, actually much easy comprehend.","code":"\nHeightOfDog=c(600, 470, 170, 430 , 300)\n\nmean(HeightOfDog)## [1] 394\nHeightOfDog=c(600, 470, 170, 430 , 300)\n\nvar(HeightOfDog)## [1] 27130"},{"path":"descriptive-statistics.html","id":"the-standard-deviation","chapter":"5 Descriptive statistics","heading":"The standard deviation","text":"standard deviation calculated square root variance, units mean.\\[\\begin{equation}\nStandard \\ deviation= S = \\sqrt {s^2}\n\\end{equation}\\]R, standard deviation calculated function sd,can also try square root variance,Basically, SD= 164mm.Now lets interpret number….normal distribution, 95% observations within 2SD mean. 95% dogs sample 394-(164mm x 2) 394+(164mm x 2) 66mm 722mm.example dogs, problem low sample size. recall earlier chapter, problem low samples variability increases sample size decreases reflected standard deviation (SD).Lets try standard deviation large sample size.figure , ~95% data two red lines.","code":"\nHeightOfDog=c(600, 470, 170, 430 , 300)\n\nsd(HeightOfDog)## [1] 164.7119\nsqrt(var(HeightOfDog))## [1] 164.7119\ny <- rnorm(1000) # the function rnorm allows you to create a random set of numbers from a normal distribution\n\n#lets now plot that data using the hist function, you already know how to use:\nhist(y, main = NULL,breaks = 30,ylim=c(0,120))\n\nSD=sd(y)\nMean=mean(y)\n\n#plot the mean\nabline(v=(Mean), col=\"blue\",lwd=4)\ntext(\"Mean\",x=Mean,y=100, col=\"Blue\", pos=4) \n\n#add two standard deviations \nabline(v=(Mean+(SD*2)), col=\"red\") \ntext(\"+2 SDs\",x=(Mean+(SD*2)),y=100, col=\"red\", pos=4) \n\n\n#minus two standard deviations \nabline(v=(Mean-(SD*2)), col=\"red\") \ntext(\"-2 SDs\",x=(Mean-(SD*2)),y=100, col=\"red\", pos=4) "},{"path":"descriptive-statistics.html","id":"the-coefience-of-variance","chapter":"5 Descriptive statistics","heading":"The coefience of variance","text":"coefficient variation (CV) another metric dispersion. ratio standard deviation mean. commonly given percentage. Basically,\\[\\begin{equation}\nCV = \\frac{Standard \\ deviation}{\\bar{X}} *100\n\\end{equation}\\]Higher values indicate standard deviation relatively large compared mean.Lets try example, pizza restaurant measures delivery time minutes. mean delivery time 20 minutes standard deviation 5 minutes.Thus, coefficient variation 25% (people may give fraction, 0.25). value tells relative size standard deviation compared mean. example, standard deviation 25% size mean.value equals one 100%, standard deviation equals mean. Values less one indicate standard deviation smaller mean (typical), values greater one occur S.D. greater mean.","code":""},{"path":"descriptive-statistics.html","id":"exercises","chapter":"5 Descriptive statistics","heading":"Exercises","text":"questions may take load depending internet connection.oTake following numbers (8 2 7 2 6), using R console estimate mean, median, mode, standard deviation 80th percentile.","code":""},{"path":"descriptive-statistics.html","id":"homework-2","chapter":"5 Descriptive statistics","heading":"Homework","text":"Using Tinn-R R-Studio, write code :Creates sample 1000 points normal distribution, place data.frame, one column named X.Creates sample 1000 points normal distribution, place data.frame, one column named X.Estimate mean, median mode variable X; individual values stored variable names.Estimate mean, median mode variable X; individual values stored variable names.Estimate standard deviation place variable name.Estimate standard deviation place variable name.Make histogram data created numeral one. Adjust parameters figure guidelines good figures.Make histogram data created numeral one. Adjust parameters figure guidelines good figures.Place mean, median, mode 2SDs mean vertical lines. Make color lines distinctive.Place mean, median, mode 2SDs mean vertical lines. Make color lines distinctive.Name vertical lines . Work XY position ‘text’ labels look nice.Name vertical lines . Work XY position ‘text’ labels look nice.Save code email homework.Save code email homework.","code":""},{"path":"correlation-1.html","id":"correlation-1","chapter":"6 Correlation","heading":"6 Correlation","text":"One core goals statistics calculate strength relationship two variables. goal can applied broad diversity research questions.Say experiment test effect temperature plants say plantss growing different temperatures. case, probably like relate temperature dependent variable like say plant size.Instead, may interested see rain affects common cold, case may wish relate amount daily rainfall daily number hospitalizations cold….possibilities endless…end day…come simply assessing strength relationship two variables. specific purpose, use correlation /regression analysis..Expectation chapterAt end chapter, expected :Can create publication quality R scatterplot visualize relationship two variables.Can create publication quality R scatterplot visualize relationship two variables.Define type relationship two variables (e.g., positive, negative, non-linear, non-existent).Define type relationship two variables (e.g., positive, negative, non-linear, non-existent).Calculate coefficient correlation two variables understand tells relationship two variables.Calculate coefficient correlation two variables understand tells relationship two variables.Alright, lot cover, let’s get started.","code":""},{"path":"correlation-1.html","id":"visualization-of-relationships","chapter":"6 Correlation","heading":"Visualization of relationships","text":"looking correlations relationships main display tool scatterplot.already know use scatterplot Chapter 4. chapter, also already know criteria plot meet standards required publication.purpose displaying correlation /regression two variables, key consideration assume one variable influences .Chapter 1, section Experiments, learned variable influences another variable called independent variable. one variable affected called dependent variable.purpose study involve assessing one variable influences , matter variable use X- Y-axis.However, study assumes one variable influences another one, independent variable located X-axis, dependent variable located Y-axis.Let’s get work R. Let’s work interesting relationship sow New York Times, people voted Donald Trump State degree higher education States.First, download two databases .Next, load data R (remember Chapter 3, section loading data).Next check data loaded correctly review structure data:Review second database:data appear loaded correctly. data want two different data.frames, merge . case, one variable common two data.frames can use merge ; variable State. , let’s merge two data.frames State.p\niWhen merging databases, things can get tricky need least one column common merge . need ensure databases, field uses names data.instance, say common column call state, one database data shown full names abbreviate name.case, merge function return empty database, two databases variables can matched.Let’s review new merged database:\nuOk, now lets plot data. case, think fraction people voted Trump function educated , way around; like saying Trump affected degree education State….hmm…say like sound unlikely, ah?.distinction important need determine variable goes Y axis, one X-axis.think, votes Trump influenced level education, level education independent variable located X-Axis. reasoning, percent State’s population voted trump dependent variable, , located Y-axis. Lets plot:Hmm, visualization alone can tell something cooking …least educated states voted Trump States educated populations. Let’s explore relationship detail, case example.","code":"\nTrumpVoters_by_State <- read.csv(\"D:/GEO380/Datasets/TrumpVoters.csv\") #Fraction of people by State that voted for Trump\nHigherEducation_by_State <- read.csv(\"D:/GEO380/Datasets/US-Pop-HigherEducation.csv\") #Fraction of people by State that have higher education degrees\nhead (TrumpVoters_by_State)##        State TRUMPVoteAsFraction\n## 1    Alabama              0.6208\n## 2     Alaska              0.5128\n## 3    Arizona              0.4867\n## 4   Arkansas              0.6057\n## 5 California              0.3162\n## 6   Colorado              0.4325\nhead (HigherEducation_by_State)##        State BachelorDegreePerStateAsFraction\n## 1    Alabama                            0.087\n## 2     Alaska                            0.101\n## 3    Arizona                            0.102\n## 4   Arkansas                            0.075\n## 5 California                            0.116\n## 6   Colorado                            0.140\nData=merge(TrumpVoters_by_State,HigherEducation_by_State,by=\"State\")\nhead (Data)##        State TRUMPVoteAsFraction BachelorDegreePerStateAsFraction\n## 1    Alabama              0.6208                            0.087\n## 2     Alaska              0.5128                            0.101\n## 3    Arizona              0.4867                            0.102\n## 4   Arkansas              0.6057                            0.075\n## 5 California              0.3162                            0.116\n## 6   Colorado              0.4325                            0.140\nplot(Data$TRUMPVoteAsFraction~Data$BachelorDegreePerStateAsFraction, ylab=\"Trump voters by State (Fraction)\",xlab=\"High degree education (Fraction of population)\")"},{"path":"correlation-1.html","id":"linear-relationships","chapter":"6 Correlation","heading":"Linear relationships","text":"Generally speaking two variables can related three difference “fashions”: linear, non-linear, non-related. different mathematical approaches tackle type relationship. cover linear relationships, want learn least identify types.Let’s start linear relationships. Linear relationships, name sort indicates better described straight line. type relationships can separated positive relationships, Y-increases X-increases negative relationships, Y-decreases X-increases.Obviously, also option two variables relate (see figure )\nFigure 6.1: Types relationships\n","code":""},{"path":"correlation-1.html","id":"non-linear-relationships","chapter":"6 Correlation","heading":"Non-linear relationships","text":"Relationships well described linear model, called non-linear relationships. Non-linear relationships can take sorts shapes, names mathematical approaches define . covered part class, aware exist.\nFigure 6.2: Types relationships\n","code":""},{"path":"correlation-1.html","id":"the-covariance","chapter":"6 Correlation","heading":"The Covariance","text":"strength linear association two variables mathematically measured -call Correlation Coefficient. Correlation Coefficient abbreviated lowercase letter \\(r\\) (token). However, estimate Correlation Coefficient, need first estimate -call Covariance.Check brief explanation covariance following video:covariance extension variance calculation earlier measure spread data variable, covariance analyze two variables. fact, assess relationship variable , covariance identical variance.nutshell, covariance tells differences two variables trending direction.Mathematically, covariance calculated following equation:\\[\\begin{equation}\nCovariance = COV(XY) = \\frac{\\sum_{=1}^n (x -\\bar{x})*(y -\\bar{y})}{n-1}\n\\end{equation}\\]Let’s try simple example estimate Covariance. Let’s consider relationship exist time study class grade get.\nFigure 6.3: Time stuying relates test scores\nSay, asked five students long studied week grade got prior classes. data:\nTable 6.1: Grades time studying Stats\nalways, start plotting data:Lets break calculation covariance parts can better appreciate .First, calculate mean alll values X difference value mean:\nFigure 6.4: Differences X\nLet’s Y-axis:\nFigure 6.5: Difference Y\nFollowing equation covariance, first point data (.e., Peter), place difference mean X (.e, -2.1) difference mean Y (-19.2), numerator. Like :\nFigure 6.6: Difference X\ncan data points obtain:\\[\\begin{equation}\nCovariance = COV(XY) =\\frac{\\sum_{} (-2.1)(-19.2) + (-0.8)(-10.2) + (-0.2)(0.8) + (1.2)(7.8) + (1.9)(20.8)}{5-1}\n\\end{equation}\\]\n.\n\\[\\begin{equation}\nCovariance = COV(XY) =24.3 Hours*Test Score\n\\end{equation}\\]Hmm???, Right?…mentioned earlier score covariance hard interpret, may still provide useful information trend data…case covariance positive, indicating differences X trend positive direction differences Y. Basically, students study get higher grades…Please remember !…goes token jIn R, covariance calculated cov function:","code":"\nStudyingTimes= data.frame(\n  Names=c(\"Peter\",\"Laura\", \"John\", \"Chip\", \"Tom\"), #lets create a data.frame with three columns\n  Hours_Studying=c(0.5, 1.8, 2.4, 3.8, 4.5),\n  Score=c(55, 64, 75, 82,95))\n\n\n\n#now let's do the plot\nplot(Score~Hours_Studying,data=StudyingTimes,xlab=\"Hours a week studying\", ylab=\"Final class score (%)\")\ncov(StudyingTimes$Score,StudyingTimes$Hours_Studying, use = \"everything\",  method = \"pearson\")## [1] 24.3"},{"path":"correlation-1.html","id":"the-correlation-coefficient-r","chapter":"6 Correlation","heading":"The Correlation Coefficient, r","text":"indicated earlier, strength linear association two variables mathematically measured -call Correlation Coefficient. times, also called Pearson product-moment correlation coefficient, Karl Pearson, credited formulating r.Mathematically, correlation coefficient, \\(r\\), calculated following equation:\\[\\begin{equation}\nr = \\frac{cov (XY)}{Sx * Sy}\n\\end{equation}\\]Basically, correlation coefficient, \\(r\\),Covariance divided multiplication standard deviation data X standard deviation data Y.think equation, covariance product differences X Y. standard deviations independently differences X differences Y. , practical terms, correlation coefficient standardized metric. never smaller -1 larger 1.correlation coefficient nice term access tendency two variables. closer -1 know data probably follow strong negative trend. close 1, data follow positive strong trend. closer zero, data place (correlation). Towards end chapter, learn interpret correlation coefficient.Lets calculate ,coefficient correlation time study score class 0.98. means time study higher grade…nice, ah???R, coefficient correlation can calculated directly function cor,","code":"\nCOVXY= cov(StudyingTimes$Score,StudyingTimes$Hours_Studying, use = \"everything\",  method = \"pearson\") #Covariance\nSDX= sd(StudyingTimes$Hours_Studying)            #Standard deviation for X\nSDY= sd(StudyingTimes$Score)                     #Standard deviation for Y\nr=COVXY/(SDX*SDY)\nr## [1] 0.9817004\ncor(StudyingTimes$Score,StudyingTimes$Hours_Studying, method = \"pearson\")## [1] 0.9817004"},{"path":"correlation-1.html","id":"alternative-formulation","chapter":"6 Correlation","heading":"Alternative formulation","text":"looking correlation coefficient likely see alternative formulations yield close approximations.instance, may find formulated like :\\[\\begin{equation}\nr = \\frac{1}{n-1} \\sum_{}\\frac{x-\\bar{x}}{Sx}\\frac{y-\\bar{y}}{Sy}\n\\end{equation}\\]equation , pretty much used earlier, reorganizing parts.times, can also defined :\\[\\begin{equation}\nr = \\frac{n * \\sum_{} xy- (\\sum_{} x)*(\\sum_{} y)}{\\sqrt {n * \\sum_{} x^2- (\\sum_{} x)^2 } * \\sqrt {n * \\sum_{} y^2- (\\sum_{} y)^2 }}\n\\end{equation}\\]yield close approximation equation used earlier.equation , compute \\(\\sum_{}x\\), \\(\\sum_{}y\\), \\(\\sum_{}x^2\\), \\(\\sum_{}y^2\\), \\(\\sum_{}x*y\\). Let try, sake sure use tools R.results :\\(\\sum_{}x\\) = 13\\(\\sum_{}y\\) = 371\\(\\sum_{}x^2\\) = 43.94\\(\\sum_{}y^2\\) = 28495\\(\\sum_{}x*y\\) = 1061.8n = 5Now plug values coefficient correlation, r, equation:\\[\\\\[.0005in]\\]\\[\\begin{equation}\nr = \\frac{n * \\sum_{} xy- (\\sum_{} x)*(\\sum_{} y)}{\\sqrt {n * \\sum_{} x^2- (\\sum_{} x)^2 } * \\sqrt {n * \\sum_{} y^2- (\\sum_{} y)^2 }}\n\\end{equation}\\]\\[\\\\[.0005in]\\]\\[\\begin{equation}\nr = \\frac{5 * 1061.8- (13)*(371)}{\\sqrt {5 * 43.94- (13)^2 } * \\sqrt {5 * 28495- (371)^2 }}\n\\end{equation}\\]\\[\\\\[.0005in]\\]R, basically:\\[\\begin{equation}\nr = 0.98\n\\end{equation}\\]\\[\\\\[.0005in]\\]Hmm, think causing difference original calculation?","code":"\nY=StudyingTimes$Score\nX=StudyingTimes$Hours_Studying\n\n\nSumX= sum(X) #sum all values of x\nSumY= sum(Y)              #sum all values of y\nSumX2=sum (X^2) #sum all values of x^2..\nSumY2=sum (Y^2)      #   sprintf(\"%.0f\",sum (Y **2))    \nSumXY=sum (X*Y)  #sum all value of x * y\nn=length(Y) # the number of observations is basically the number of rows in the database\nr=(n*SumXY-(SumX*SumY))   /  ( sqrt(n*SumX2 -SumX^2)  * sqrt(n*SumY2 -SumY^2)   )\n\nr## [1] 0.9817004"},{"path":"correlation-1.html","id":"interpreting-r","chapter":"6 Correlation","heading":"Interpreting r","text":"correlation coefficient, \\(r\\), unitless…dividing standard deviations products differences x y, result loose units. means value can compared among studies set x y variables can also interpreted set standard values (.e., -1 1).short, correlation coefficient, \\(r\\), can range -1 (perfectly negative correlation) 1 (perfectly positive correlation). Like images .\nFigure 6.7: Examples correlation coefficients\n","code":""},{"path":"correlation-1.html","id":"causation","chapter":"6 Correlation","heading":"Causation","text":"correlation coefficient measures strength linear relationship two variables. Thus, makes implication cause effect. fact two variables tend increase decrease together mean change one causing change .times, two variables may strongly correlated equally correlated third (either known unknown) variable. variables called lurking variables. Lets take following example:\nFigure 6.8: Examples lurking variables\nfigure , dashed lines show association. solid red arrows show cause--effect link. variable x explanatory, y response variable, z lurking variable.Basically, example B, find strong correlation x y, causality related, strongly affected variable measure (.e., Z case example ) -call lurking variable. effect can make spurious conclusion interpret coefficient correlation cause effect.instance, know tropical countries strong correlation consumption ice cream shark attacks?. One conclude sharks like sweet people?. Hmm…think correlation….lurking variable ?. ?\nFigure 6.9: Example lurking variable\n","code":""},{"path":"correlation-1.html","id":"significance","chapter":"6 Correlation","heading":"Significance","text":"take two random variables correlate together, still get correlation value.may think two variables random, correlation close zero…well, wrong.turns even random chance alone, two variables may still correlated. chances getting higher correlation increase lower sample size.Just think , correlate two data points, almost certainly correlation 1 -1.address potential caveat, need assess “Significance” correlation. Basically, can correlation found emerge chance alone?word “significance significant” tricky implies level threshold error willing take. threshold called critical value, commonly identified letter alpha, \\(\\alpha\\). margin error willing accept error.biology, normally give 5% chance wrong (p<0.05). times, preferable certain take 1% chance (p<0.01). times rather, just provide exact probability correlation random, case provide exact p-value.","code":""},{"path":"correlation-1.html","id":"correlation-tables","chapter":"6 Correlation","heading":"correlation tables","text":"case correlation, significance correlation can assessed quickly probability table, one shown :\nFigure 6.10: Significance correlations\nLets use example working relationship time students study grades. case, \\(r\\)=0.98 sample size \\(n\\) 5 students.coefficient correlation significant?. Can obtain similarly high correlation, ifor similar set random variables?.find , first select critical value, \\(\\alpha\\), lets choose 0.05. case, second column table one interested .Next, scroll-column one sample size table matches (5).row, look value second column, coefficient correlation two random variables five points. case, value 0.88.correlation coefficients larger, \\(r\\)=0.98, meaning unlikely correlation occur chance alone.: time study better grades get, now demonstrated mathematically. Take couple tokens, gh, forget conclusion!","code":""},{"path":"correlation-1.html","id":"correlation-p-values","chapter":"6 Correlation","heading":"Correlation p-values","text":"times, want specific likely error correlation found can caused chance alone. case, need report exact p-value. Later studying p-values detail.R, exact p-value correlation calculated function cor.test.several things output R-function, cor.test, now, just need focus p-value number, case, correlation time studying grades, p-value=0.002963.Basically, given sample size, 0.3%, less 1% chance, correlation can emerge chance alone.\nconclusion, want good grade class really need take good time study. Mathematics tells way around ; nearly 99.9% legit correlation!.","code":"\nY=StudyingTimes$Score\nX=StudyingTimes$Hours_Studying\n\n\ncor.test (X,Y)## \n##  Pearson's product-moment correlation\n## \n## data:  X and Y\n## t = 8.9289, df = 3, p-value = 0.002963\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  0.7427169 0.9988455\n## sample estimates:\n##       cor \n## 0.9817004"},{"path":"correlation-1.html","id":"exercises-1","chapter":"6 Correlation","heading":"Exercises","text":"questions may take load depending internet connection.","code":""},{"path":"correlation-1.html","id":"homework-3","chapter":"6 Correlation","heading":"Homework","text":"studying crime levels among universities around country, scientists found following datax= 12.5, 30.0, 24.5, 14.3, 7.5, 27.7, 16.2, 20.1y= 26, 73, 39, 23, 15, 30, 15, 25Let x students enroll (thousands), y number burglaries given university campus.Make scatter diagram, adjust aesthetics figure follows publication guidelines.Make scatter diagram, adjust aesthetics figure follows publication guidelines.Display plot correlation coefficient.Display plot correlation coefficient.say correlation low, moderate, high? positive negative?say correlation low, moderate, high? positive negative?significant?significant?Place figure responses Word document email homework. Send nice looking document.","code":""},{"path":"regression-1.html","id":"regression-1","chapter":"7 Regression","heading":"7 Regression","text":"goal correlation give metric strength relationship two variables; goal regression give numerical representation tendency data. numerical representation called model describes line best represent tendency two variables. times, line can also called regression line trend line.working linear regression models…means find straight line best represent relationship two variables.instance, blue line appears represent well tendency exist variables Y X. goal chapter use mathematical procedure (linear regression) allows identify line.indicated prior chapter, relationships linear, also -call non-linear relationships. now, cover linear relationships, straight lines best summarize relationship two variables.cool benefits single line describing data:allows mathematically define two variables related. Like increase X 2 Y increases much?.allows mathematically define two variables related. Like increase X 2 Y increases much?.allow make predictions areas data. Like X 52.3 Y ?allow make predictions areas data. Like X 52.3 Y ?need carry/display data every time want work database.need carry/display data every time want work database.define best-fitting line, use called least squares method; sounds scary, actually simple.\\[\\\\[.0005in]\\]Expectation chapterAt end chapter, expected :Can estimate linear regression model defines linear relationship two variables using least-squares criterion.Can estimate linear regression model defines linear relationship two variables using least-squares criterion.able interpret results linear model.able interpret results linear model.Use equation regression model predict Y-values (interpolation extrapolation).Use equation regression model predict Y-values (interpolation extrapolation).Calculate coefficient determination understand tells relationship two variables.Calculate coefficient determination understand tells relationship two variables.Alright, let’s get .","code":""},{"path":"regression-1.html","id":"parts-of-a-line","chapter":"7 Regression","heading":"Parts of a line","text":"get needy-greedy linear regression models, start knowing line can constructed.practical terms, specific straight line, XY space, can drawn knowing just two parameters: intercept slope.\nFigure 7.1: slope intercept\nintercept basically position Y-axis regression line crosses, value Y X=0.slope inclination line, change Y divided X. also indicates mount Y changes unit change X; later.slope intercept can draw line like.Let’s check intercept slope line.plotting line R, use abline function, used drawing horizontal vertical lines. can also use R-function draw lines specific slopes intercepts. Let’s try.Lets plot three lines different slopes, intercept.Lets now change intercept, keep slope ","code":"\n#play around with the lines of code below to see how they work\n\n#First lets create an empty plot and make the x and y axis nicer.\nplot(0, 0,xlab=\"X\",ylab=\"Y\",  xlim=c(-4,4),ylim=c(-4,4.5),col=\"grey\")\n  abline(h=0,lwd=2, col=\"grey\",lty=1) \n  abline(v=0,lwd=2, col=\"grey\",lty=1) \n  \n# lets draw a first line with an intercept of 1, and a slope of 0.5. \n# In abline, the first number will be the intercept and the second will be the slope.\n  \nIntercept=1  #lets create a variable for the intercept, which i choose to call intercept and make that variable = 1\nSlope=0.5    #lets create a variable for the slope, which i choose to call slope and make that variable = 0.5\n\nabline(Intercept, Slope, col=\"orange\") #lets plot the line, with my slope and intercept and make it orange to differentiate it\n\n# now, draw another line keeping the intercept the same and increase the slope to 1.5\nSlope=1.5\nabline(Intercept, Slope, col=\"blue\") #lets make it blue to differentiate it\n\n# try keeping the intercept the same and increase the slope to 2.5\nSlope=2.5\nabline(Intercept, Slope, col=\"green\") #lets make it green to differentiate it\n\n#We can verify the intercept, by plotting the point in Y, where the line intercept.\npoints(0,Intercept, pch=\"*\",cex=3, col=\"red\") #remember the intercept is when x=0.\n#play around with the parameters in the code below to see how they work\n\n#plot first\nplot(0, 0,xlab=\"X\",ylab=\"Y\",  xlim=c(-4,4),ylim=c(-4,4.5),col=\"grey\")\n  abline(h=0,lwd=2, col=\"grey\",lty=1) \n  abline(v=0,lwd=2, col=\"grey\",lty=1) \n  \n# now try a combination of difference intercepts but the same slope.\n  \nIntercept=1  \nSlope=0.5   \n\nabline(Intercept, Slope, col=\"orange\") #lets plot the line, and make it orange to differentiate it\n\n# keep the slope the same and increase the Intercept to 2\nIntercept=2\nabline(Intercept, Slope, col=\"blue\") #lets make it blue to differentiate it\n\n# keep the slope the same and increase the Intercept to 3\nIntercept=3\nabline(Intercept, Slope, col=\"green\") #lets make it green to differentiate it"},{"path":"regression-1.html","id":"how-to-interpret-the-slope","chapter":"7 Regression","heading":"How to interpret the slope","text":"slope interpreted amount change Y single unit change X.Let’s say, told given relationship total rainfall (litters) amount time (hours) 500. slope alone, can tell now extra hour, 500 litters water falling.contextualize slope graphically, can take point along trendline, move horizontally one unit; difference Y-point first X Y-point X+1, slope…Lets check.","code":"\n#plot first\nplot(0, 0,xlab=\"X\",ylab=\"Y\",  xlim=c(0,10),ylim=c(0,5000),col=\"grey\")\n  abline(h=0,lwd=2, col=\"grey\",lty=1) \n  abline(v=0,lwd=2, col=\"grey\",lty=1) \n\n#lets draw a trend line with a slope of 500, that intercepts the origin.\nIntercept=0  \nSlope=500  \n\nabline(Intercept, Slope, col=\"orange\") #lets plot the trend line, and make it orange to differentiate it\n\n\n#lets move one unit along X, starting at zero\nsegments (0,0,1,0, col=\"red\",lwd=3) #lets make that segment red\n\n#from that point, X+1, lets move up 500 units, if the calculation is correct, then that segment of 500 units in Y should finish at the interception with the trend line...lets see\n\nsegments (1,0,1,500, col=\"blue\",lwd=3) #here I draw a segment starting a x=1, y=0...until x=1, y=500"},{"path":"regression-1.html","id":"how-to-interpret-the-intercept","chapter":"7 Regression","heading":"How to interpret the intercept","text":"intercept expected value Y X=0.Say among children relationship age (years) size (centimeters), Y-intercept 35cm. tell ?.since Y-intercept value X=0, Y-intercept 35cm means size child zero years age. Basically, children average born 35cm size.","code":""},{"path":"regression-1.html","id":"purpuse-of-the-regression-line","chapter":"7 Regression","heading":"Purpuse of the regression line","text":"indicated earlier, common name intercept lowercase letter \\(b\\) common name slope lowercase letter \\(m\\), regression model come together :\\[\\begin{equation}\nY = mX + b\n\\end{equation}\\]beauty regression model knowing \\(m\\), \\(b\\), can predict value Y, know X.Say relationship years higher education salary, well defined regression equation intercept $25,000 slope $10,000 dollars/year. Given units given, predict salary Y-axis years education X-axis. can turn equation, like:\\[\\begin{equation}\nSalary = 10,000 * \\text{(Years Education)} + 25,000\n\\end{equation}\\]can also display, line XY plot, using abline function:can also ask questions, like average salary person studies 4 years higher education?..simply replace \\(x\\) variable equation number 4 mathematical calculation get average expected salary.\\[\\begin{equation}\nSalary = 10,000 * 4 + 25,000\n\\end{equation}\\]expected salary person studies four years higher education $65.000.Ok, moment know basics linear regression model. nutshell, linear regression model mathematical equation includes slope intercept allows draw line, can also predict value Y given values X.","code":"\n#plot first\nplot(0, 0,xlab=\"Years of education\",ylab=\"Salary (in US dollars)\",  xlim=c(0,10),ylim=c(0,150000),col=\"grey\")\n  abline(h=0,lwd=2, col=\"grey\",lty=1) \n  abline(v=0,lwd=2, col=\"grey\",lty=1) \n\n#lets draw a trend line with the given parameters\nIntercept=25000  \nSlope=10000  \n\nabline(Intercept, Slope, col=\"orange\") #lets plot the trend line, and make it orange to differentiate it"},{"path":"regression-1.html","id":"the-least-squares-line","chapter":"7 Regression","heading":"The least-squares line","text":"now, know formulation (.e., \\(Y= mX + b\\)) general purpose (.e., predict Y, given values X) linear regression model. next task chapter figure get best line can drawn two variables want relate.Obviously, can draw infinite number straight lines trhough set datapoints; key question line best describe data?. goal linear regression model: draw best-fit line datapoints.best fitting line line minimizes distance point line. mathematical terms, line called least-squares regression line. moment, see name (least-squares regression line) speaks ; hope moment see term self-explanatory.","code":""},{"path":"regression-1.html","id":"understanding-the-least-squares-line","chapter":"7 Regression","heading":"Understanding the least-squares line","text":"Let’s use analogy, imagine best fitting line knife cut cake.Take figure example. blue line knife red dotted lines pieces cake person. good cut? best-fitting line?quite s. can imagine Laura happy getting smaller piece cake. may complain four guys support , likely happy getting bigger shares cake. case, line best describing data.line ?. good-fitting line data?Well, may …may think complains Laura Peter getting smaller pieces balanced extra happiness Chip John getting larger shares cake.However, justified complains can avoided better cut cake; cut can reduce complains every body. can done drawing line minimizes distance point line, -called “least-square regression line”.","code":""},{"path":"regression-1.html","id":"deciphering-the-least-squares-line","chapter":"7 Regression","heading":"Deciphering the least-squares line","text":"lines can draw set data points, can know best-fit line?, one everybody happy using cake analogy?. actually different ways get line…let’s start using brutal force, may actually help us understand idea behind “least-squares”.know fact ‘best-fitting line’ pass XY coordinates defined mean values X mean value values Y. inflection point, data X data Y evenly separated, best fitting-line pass given point.Let’s plot mean value X mean value Y (Dashed grey-lines image ) interception lines let’s plot mean X mean Y (red dot image ).Next, draw inclined line passing trough inflection point defined coordinates Mean-X Mean-Y. Like image .Next, measure distance point line (red-dashed lines), indicate red numbers image .(Remember, best line one smallest distance point given line)difference point best-fitting line (red-dashed lines red-numbers) called residuals. may also named residual errors.call residual also error?. well, case linear regression, want model best describes data. Unfortunately, best-line pass every single one points, difference point line error model.Next, add residual errors. Remember, best fitting line one least residual error:\\((2.124)\\) + \\((-0.036)\\) + \\((0.614)\\) + \\((-0.276)\\) + \\((-2.426)\\) = \\(0\\)Hmm, make sense, sum 0; yet know Laura alone, residual error \\((2.124)\\).can add positive negative errors, cancel ?. know….hope say “squaring” pr elevating given number power 2. recall last chapter, approach squaring value allows convert values positive negative non-negative values…lets try.\\((2.124)^2\\) + \\((-0.036)^2\\) + \\((0.614)^2\\) + \\((-0.276)^2\\) + \\((-2.426)^2\\) =\\(10.8513\\)Ok, like . value just calculated call Sum Square Errors SSE. best fitting line, one SSE smallest. approach finding best finding line called “least squares”.Lets finish exercise brutal force, drawing lines different inclinations estimating SSE. Like figure .\nFigure 7.2: Finiding line least-squares error\ncan compare sum squares errors, SSE, line find one least, like :seems winner, line number 30 one lowest sum squares, separate :Ok, hope clear least squares approach find best fitting line. Next, learn estimate parameters intercept, \\(b\\), slope, \\(m\\), define line linear regression model, smart easy way.","code":""},{"path":"regression-1.html","id":"estimating-the-least-squares-line","chapter":"7 Regression","heading":"Estimating the least-squares line","text":"ultimate goal linear regression model identify parameters intercept, \\(b\\), slope, \\(m\\), line minimizes sum square errors also called least-square errors.","code":""},{"path":"regression-1.html","id":"refreshing-the-slope","chapter":"7 Regression","heading":"Refreshing the Slope","text":"get mathematical equation describe slope linear regression model, lets review 4th grade geometry calculate slope two points.recall Ms. Smith, Match teacher 4th grade, told slope two points can calculated :\\[\\begin{equation}\nSlope = m = \\frac{\\Delta y}{\\Delta x}= \\frac{y_{2}-y_{1}}{x_{2}-x_{1}}\n\\end{equation}\\]Basically, change Y divided change X. Put another way, change X 1 unit, much Y change?Lets check math, using line know slope, using R-function abline, earlier.Continuing example , change Y, also called \\(\\Delta y\\), 4. change X, also called \\(\\Delta x\\), 2. , slope can calculated :\\[\\begin{equation}\nm = \\frac{\\Delta y}{\\Delta x}= \\frac{4}{2}=2\n\\end{equation}\\]exactly, slope set abline, serve purpose illustrate slope line simply change Y divided change X.mind lets now calculate slope regression line","code":"\nSlope= 2  #lets set a line with a slope of 2\nIntercept=1 # We do not need the intercept but lets use a value of 1 as an example\n\nplot(0,0,xlab=\"X\",ylab=\"Y\", col=\"blue\",pch=\".\", cex=2, xlim=c(-0,4),ylim=c(0,8), yaxs=\"i\", xaxs=\"i\") #lets create an empty plot\n\n#Next we draw the line with the known slope:\nabline(Intercept, Slope ,col=\"blue\",lwd=1) \n\n#Now place two points along that line...say a point at the coordinates (1,3) and another point at the coordinates (3,8).\n#If you recall, the coordinates of a point are x and y given between parenthesis.\n\n# draw Point 1 in the plot and put a label to it.\npoints(1,3,pch=21, col=\"black\",bg=\"yellow\",cex=2,lwd=.1) #First point\ntext(1,3, labels=\"(1,3)\",pos=2) #lets create a label\n\n# do the same for Point 2\npoints(3,7,pch=21, col=\"black\",bg=\"yellow\",cex=2,lwd=.1) #second point\ntext(3,7, labels=\"(3,7)\",pos=2) #lets create a label  \n\n#lets draw a segment for the change X: is x0=1, and x1=3, then the difference is 2.\nsegments(x0=1,y0=3,x=3,y=3, col=\"red\", lty=2,cex=2) #lets draw the segment for the difference in x between the two points, and make it red\ntext(2,3, labels=\"2\",col=\"red\",pos=1) #lets create a label for that segment\n\n#lets draw the difference in Y, which basically y0=3, and y=7, so the difference, delta, is 4.\nsegments(x0=3,y0=3,x=3,y=7, col=\"blue\", lty=2,cex=2) #lets draw the segment for the difference in y between the two points\ntext(3,5, labels=\"4\",col=\"blue\",pos=4) #lets create a label  "},{"path":"regression-1.html","id":"the-slope","chapter":"7 Regression","heading":"The slope","text":"use Ms. Smith way calculate slope regression model?. Well, use principle, difference Y divided difference X, use formula case regression model two points.numerous ways calculate slope, \\(m\\), linear regression model. However, simplest :\\[\\begin{equation}\nSlope = m = \\frac{\\sum(x-\\bar{x})*(y-\\bar{y})}{\\sum(x-\\bar{x})^2}\n\\end{equation}\\]seen terms . numerator included covariance (.e., two variables trend together) denominator included variance (.e., disperse data one variable).think …equation speaks .mentioned earlier, slope line can described change Y divided change X.Chapter 5, Section Dispersion, may recall best indicator variability variable variance, term \\(\\sum(x-\\bar{x})^2\\). chapter 6, may recall best indicator tendency two variables covariance \\(\\sum(x-\\bar{x})*(y-\\bar{y})\\)., want slope among set points follows central tendency, change X \\(\\sum(x-\\bar{x})^2\\), change Y Y varies X, mathematically \\(\\sum(x-\\bar{x})*(y-\\bar{y})\\).can phrase equation slope regression line different way, X changes variance X, Y change covariance Y X.Ok, now equation slope clear, lets calculate .Let’s use data using time studying grades,\nTable 7.1: Grades time studying Stats\n\naSo, replace differences X difference Y slope formula:\\[\\begin{equation}\nslope = m = \\frac{(-2.1*-19.2) + (-0.8*-10.2) + (-0.2*0.8) + (1.2*7.8) +(1.9*20.8)}   { (-2.1)^2 + (-0.8)^2 + (-0.2)^2 + (1.2)^2 +(1.9)^2}\n\\end{equation}\\]\\[\\begin{equation}\nslope = m = 9.6\n\\end{equation}\\]slope, m, equal 9.59. units units Y (.e., grade), divided units x (.e., hours studying). unit change X one hour unit change Y 9.59 points higher grade.Put another way, extra hour study week, can expect 9.59 points higher grade, neat ?.mention several ways calculate slope linear regression model, find bit complicated difficult understand. prefer use simple formula , aware ways get slope least-squares line.","code":""},{"path":"regression-1.html","id":"the-intercept","chapter":"7 Regression","heading":"The intercept","text":"numerous combulated equations calculate intercept linear regression model. want us use procedure probably learned 6th grade.look linear regression model equation,\\[\\begin{equation}\nY = mX + b\n\\end{equation}\\]isolate intercept, \\(b\\), :\\[\\begin{equation}\nb = Y - mX\n\\end{equation}\\]recall, line least-squares regression line pass coordinates defined mean value X mean value X. estimate intercept replace \\(X\\) \\(Y\\) parameters linear regression equation mean X, \\(\\bar{x}\\), mean Y, \\(\\bar{y}\\). Like :\\[\\begin{equation}\nb = \\bar{y} - m\\bar{x}\n\\end{equation}\\]also know slope prior section. parameters equation stimate intercept.Let’s estimate intercept relationship time studying grades. data, mean X, \\(\\bar{x}\\), 2.6, mean Y, \\(\\bar{y}\\), 74.2. , intercept linear regression :\\[\\begin{equation}\nIntercept = b =74.2 - 2.6*9.586\n\n\\end{equation}\\]\\[\\begin{equation}\nIntercept = b =49.277\n\n\\end{equation}\\]Y-Intercept least-square line relationship grades time studying \n49.28. can interpret value grade can expect class study single hour week. Hmm, good.","code":""},{"path":"regression-1.html","id":"linear-regression-in-r","chapter":"7 Regression","heading":"Linear regression in R","text":"now know equation linear regression model, idea behind least-squares approach, calculate interpret different elements equation.R can calculate equations automatically using lm function, stands linear model. cool think can now interpret results function. Lets try using data grades time studying.\nFigure 7.3: Linear regression output R\n","code":"\n#lets start by bringing back the data \nHours_Studying=c(0.5, 1.8, 2.4, 3.8, 4.5)\nGrade=c(55, 64, 75, 82,95)\n\n# the function lm, requires you to simply set the model as y ~ x. In our case, grades are the dependent variable, so it goes on the Y-axis, and time studying is the independent variable, so it goes in the x-axis.\nlm (Grade~Hours_Studying)"},{"path":"regression-1.html","id":"the-coeficient-of-determination","chapter":"7 Regression","heading":"The coeficient of determination","text":"one final cool thing linear regression model: allows quantify neat parameter called coefficient determination, \\(r^2\\).parameter useful two main reasons:tells good relationship two variables, although sort know correlation coefficient, \\(r\\), estimated earlier.tells good relationship two variables, although sort know correlation coefficient, \\(r\\), estimated earlier.tells percent variance Y explained X.tells percent variance Y explained X.Say found relationship plant size nutrient input \\(r^2\\) 85%. tells 85% variability among plants can explained input nutrients.words, relationship positive, plants grew lot lots nutrients, plants grow well nutrients. given high \\(r^2\\), probably good idea add nutrients plants.Say opposite found \\(r^2\\) 5%. 5% variability plant size can explained nutrient input. case, may wasteful add nutrients plants, since affect little plants grow. may case good soil, , need nutrients.example nutrients plants, can see \\(r^2\\) let make inferences strength relationships.One bad thing \\(r^2\\), oppose correlation coefficient, \\(r\\), know direction relation (.e., whether positive negative). may still relay correlation coefficient, \\(r\\), know direction two variables related.get mathematics \\(r^2\\), check brief explanation:coefficient determination, \\(r^2\\), mathematically calculated :\\[\\begin{equation}\n\\text{Coefficient Determination} = r^2 = \\frac{SSmean - SSfit}{SSmean}\n\\end{equation}\\]Let’s break equation pieces see .\\(SSmean\\), stands Sum Squares Mean. term used \\(\\sum(y - \\bar y)^2\\). Basically, far mean point. divide number samples, get variance studied earlier.Just refresh, take mean values Y (horizontal line, image ), point measure distance mean (dotted lines), square value add together. square , summing , result zero.\nFigure 7.4: Sum Squares Mean, SSmean\nneed think Sum Squares Mean, \\(SSmean\\), variability Y.\\(SSfit\\), stands Sum Squares around Fit. Let’s see means.Take data grades time studying, relate grades times studying, find best line (Orange line figure ). point measure distance point line, -call residuals (red-dotted lines). Take residual, square , add together. get Sum Squares around Fit, \\(SSfit\\).\nFigure 7.5: Sum Squares around Fit, SSfit\nneed think Sum Squares around Fit, \\(SSfit\\), variability Y explained X.Remember, regression line mathematical formulation Y relates X, whatever accounted line residuals, variation Y, remains accounted ., look formulation \\(r^2\\), basically, trying quantify fraction variability Y accounted relationship Y X. Easy right?Let’s calculate \\(r^2\\),, \\(r^2\\) relationship grades time studying 0.96. fraction variability grades explained amount time students study. can also report \\(r^2\\) percentage multiplying fraction 100.R, \\(r^2\\) outputted part lm function combination function summary, like :\nFigure 7.6: lm outputs\n","code":"\n#take the data on grades and time studying\nX=c(0.5, 1.8, 2.4, 3.8, 4.5) #hours studying\nY=c(55, 64, 75, 82,95)       #grades\n\n# lets estimate the regression line using lm, and lets put that model in a variable\nLM = lm (Y~X)   #this is the linear model between Grades~Hours_Studying\n\n#you can find out the residuals of that model using the R-Function residuals.\nResiduals= residuals (LM)  #here we create a vector with the residuals from our model\n\n#Estimate SSfit\nSSFit= sum (Residuals^2)  # here you are squaring each residual, then adding them\n\n#Lets now estimate SSMean\nDeltaY=Y-mean(Y)  # here you take each value in Y and subtract it to the mean of Y\nSSMean= sum(DeltaY^2) #here you square each score in the line above, sum them together\n\n#we have all we need for the calculation of the R2.\n\nR2=(SSMean-SSFit)/SSMean\nR2## [1] 0.9637357\nsummary (LM)   #summary results of the lm we created in the code above.  "},{"path":"regression-1.html","id":"predict-interpolation-extrapolation","chapter":"7 Regression","heading":"Predict: Interpolation, Extrapolation","text":"Ok, now know build linear regression model form:\\[\\begin{equation}\nY = mX + b\n\\end{equation}\\]Isn’t beauty?equation describes, best possible, Y relates X. extra support Coefficient Determination, \\(r^2\\), can also know strong relationship .just keep giving. relationship, can now predict value Y, given value X. replace X parameter equation , value like, run calculation get expected value Y.\nFigure 7.7: Predictions linear models\nLet’s try. relationship grades time studying, already know intercept, \\(b\\), \n49.28, slope, \\(m\\), 9.59. , linear model can formulated :\\[\\begin{equation}\nY = 9.59X + 49.28\n\\end{equation}\\], given model, expected grade person studying 4 hours week?. Simple, replace X 4, run calculation done,\\[\\begin{equation}\nY = 9.59* 4 + 49.28\n\\end{equation}\\]\\[\\begin{equation}\nY = 87.64\n\\end{equation}\\]person studies four hours week expected grade 87.64.","code":""},{"path":"regression-1.html","id":"interpolation-and-extrapolation","chapter":"7 Regression","heading":"Interpolation and Extrapolation","text":"Predictions based linear model can separated within data , case prediction called “interpolation”. prediction beyond values X , prediction call extrapolation.\nFigure 7.8: Interpolation Extrapolation\nNeedless say, extrapolate, always risk forecast wrong. model created modeled relationship Y X, data . Pass set data, relationship may different, always important careful extrapolations.Predicting Y values X values observed X values data set called interpolation.R, can predict value linear model, using predict function, let’s try.predictions , can see model wrongly predicts person studies 100 hours week, get 1000.7 grade class. Obviously, can get 100%. helps illustrate caution needed extrapolating linear model beyond limits data.Two statisticians traveling airplane LA New York.hour flight, pilot announced lost engine. “Don’t worry”, says pilot, “three left; , instead 5 hours take 7 hours get New York”.little later, pilot announced second engine failed. “Don’t worry”, says pilot, “two left; , instead 5 hours take 10 hours get New York”.Somewhat later, pilot came intercom announced third engine died. “Never fear”, announced, “plane can fly single engine. However, now take 18 hours get NewYork”, pilot added.","code":"\n#take the data on grades and time studying\nX=c(0.5, 1.8, 2.4, 3.8, 4.5) #hours studying\nY=c(55, 64, 75, 82,95)       #grades\n\n# lets estimate the regression line using lm, and lets put that model in a variable\nLM = lm (Y~X)   #this is the linear model between Grades~Hours_Studying\n\n# lets now predict, the expected grades for three students that studied 1 hour, 3 hours and 10 hours\nPredictGradres=data.frame(X = c(1,3,100)) #here I create a data.frame with the times studied by the three students. You need to create a column, with the same name, as the model, so lm can know which one is  the X-variable\n\npredict(LM, PredictGradres)##          1          2          3 \n##   58.86272   78.03432 1007.85680"},{"path":"regression-1.html","id":"outliers","chapter":"7 Regression","heading":"Outliers","text":"One critical issues regression models, can influenced extreme points. extreme points clearly follow main pattern called outliers.Sometimes, outliers measurement errors, times also indicate influence variables measure. always good visualize data scatterplot see cases examples outliers exist data.Outliers can also tested mathematically, re-running linear model without , check effect removing linear model.several approaches test effect removing outlier significant linear model, cover . need know.\nFigure 7.9: outlier\n","code":""},{"path":"regression-1.html","id":"the-significance","chapter":"7 Regression","heading":"The significance","text":"Several times book, mentioned always chance result can arise chance alone.\nlinear regression model different. may still chance find \\(r^2\\) similar one found use independent variable .rule possibility, use called F-test. review F-statistics detail later Chapter hypothesis testing.Basically, people taken time run millions simulations “fake” “random” datasets, created linear models varying sample sizes number parameters, estimated fitness models. , put results “random” models F-tables, can find end books stats.beauty tables can compare model, given number samples number variables, find fraction models similar happened chance.compare model , need:F-value model, get sec.number variables model (purpose comparison tables, call value \\(v1\\))parameter, call \\(v2\\), number datapoints model minus number predictors model plus one.\\(v1\\) \\(v2\\) just parameters needed compare random models similar parameters.model similar , , results emerged simple chance. results different, relationship found legit. work later .Ok, need estimate F-Value model. specific equation calculate F-value F-statistics linear regression model. However, can also predicted using \\(r^2\\), use simplicity, using following equation:\\[\\begin{equation}\nF_{statistics} = \\frac{r^2}{1-r^2} *\\frac{v2}{v1}\n\\end{equation}\\]\\(r^2\\), coefficient determination; \\(v1\\) number predictors model; \\(v2\\) number datapoints minus number predictors model plus one.think formula , estimating standard metric variance explained, \\(r^2\\), variance explained, \\(1-r^2\\), model certain characteristics sample size variables used.variance can explain case always just 100%, metric assumed standard among model random . , can compare results legit data fake data, see result different random.parameters hand model, need look F-table estimate critical F-value. critical F-value expected F-value certain fraction random models occur. Let’s take moment understand .Image statistician runs one million regressions random data using certain number samples independent variables model estimates F-value . creates frequency distribution number models F-value, like figure .\nFigure 7.10: F-distribution\ndistribution, can now find F-value say 90% random models occur; value critical F-value, like image .say model F-value larger critical F-value 90% sure model emerge chance.Alternatively, say model significant p>0.1, complement 90% 0.9 look fractions. p-value also called critical p-value times also named alpha, \\(\\alpha\\).\nFigure 7.11: Critical f-Value 90% p=0.1\nLets estimate F-value regression model grades time studying, know \\(r^2\\) \\(0.96\\). \\(v1\\), number predictors model 1, one independent variable (.e., time studying) , \\(v2\\) 3; recall \\(v2\\) number datapoints (five student) minus number predictors (one case) plus one. \\[\\begin{equation}\nF_{statistics} = \\frac{0.96}{1-0.96} *\\frac{3}{1}\n\\end{equation}\\]\\[\\begin{equation}\nF_{statistics} = 79.7259164\n\\end{equation}\\]F-value model \\(79.73\\). Now need find critical F-value, lets take \\(\\alpha =0.05\\). use F-table, like one , can find books stats.\\(v1\\) = 1 case, select first column, scroll \\(v2\\) gray column equal 3, interception F-critical. F-value 95% random models occurred. similar tables like \\(\\alpha\\).model like , 95% random models critical F-value smaller 10.13. However, model F-value = 79.7259164. model different random expectation, also-called significantly different p>0.05.\nFigure 7.12: lm outputs\nR, F-value produced automatically \\(lm\\) function \\(summary\\) function. outputs linear model, lm, also include exact probability model random, see image .\nFigure 7.13: lm outputs\nconclusion, significantly strong relations (\\(r^2 = 0.96\\)) p<0.05 studying class getting nice grade. go, keep studying.","code":"\nsummary (LM)   #Here LM is the linear model, lm, we create in the code just above.  "},{"path":"regression-1.html","id":"multiple-regression","chapter":"7 Regression","heading":"Multiple regression","text":"now, used linear regression model predict Y terms one variable, X. However, may noted examples , rare model single independent variable predict fully dependent variable…residuals left tell something else may influence dependent variable.Linear regression allows check effect additional variables, using principle.Think way…run linear regression model one independent variable residuals left.Take residuals independent variable second linear model, relate residuals another variable, see much unexplained variation first independent variable explained second independent variable.can keep going , potentially find set variables explain response variable.example oversimplification multiple regression works, collinearities among independent variables handle. now just want know linear regression allows test additional variables trying explain unexplained variation Y additional variables. -call multiple regression analysis.Let’s take data using, say, also got data amount debt student…variable may indicate level stress student, likelihood job prevents working fully well, etc…second variable influences grades students class?.Let’s check..\nFigure 7.14: R multiple regression results\noutputs sow . unique intercept, now slope variable. also need pay attention second result, p-values individual variables, indicate image . Plus, p-value full model.case, full model significant, individual variables .specific case, happening sample size small, bring caution need running multiple regression analysis: adding variables, increase predictive power model, also increase chances results may happen chance.","code":"\n#lets start by bringing back the data on time studying and grades\nNames=c(\"Peter\",\"Laura\", \"John\", \"Chip\", \"Tom\")\nHours_Studying=c(0.5, 1.8, 2.4, 3.8, 4.5)\nGrade=c(55, 64, 75, 82,95)\n\n#here is the data for the second independent variable for the same students\nDebt=c(80, 60, 55, 15, 5) #debt of students in thousands of dollars\n\n# we use the same lm function we used before and add debt as independent variable, like this:\nMultipleRegression=lm (Grade ~ Hours_Studying + Debt)\n\n#next we check the results\nsummary(MultipleRegression)"},{"path":"regression-1.html","id":"non-linear-regression","chapter":"7 Regression","heading":"Non-linear regression","text":"numerous instances variable Y relate linearly variable X. Think growth people, instance.Early life person grow fast, time growth reduce, eventually leveling . types relationships well described linear models; non-linear models come .R, non-linear regression models handled specific function call \\(nlm\\), can also linearize variable use linear model used .Take example , showing relationship age height random person. Let’s start fitting linear model .\\(R^2\\) pretty good, \\(r^2\\)=0.9383925.can try non-linear model, transforming data…numerous types transformations possible, many give different types fit using linear models. approach called model selection comes , find models fit data best. quite endeavor cover basic stats class, know selecting among different types models non-trivial.sake seeing non-linear model done, let’s try logarithmic transformation data used height age.can now see non-linear modeling variables gives even better \\(r^2\\)=0.9930516.numerous complexities use non-linear models, addressed …main goal introductory level know regression modeling can done non-linear relationships.","code":"\n#let's create a variable for height (dependent variable) and other for age (independent variable)\nAge=c(2,4,6,8,10,12,14,16,18,20,22,24,26,28,30)\nHeight=c(50, 65,85, 95, 110, 120,130,140,145, 152, 158, 169, 170, 171, 171.2)\n\n  \nLM=lm(Height~Age) #here is the linear model\n\nplot(Height~Age)\nabline(coef = coef(LM))\nsummary(LM)## \n## Call:\n## lm(formula = Height ~ Age)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -18.257  -5.947   3.235   7.426  11.253 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  59.3638     5.6038   10.59 9.18e-08 ***\n## Age           4.3364     0.3082   14.07 3.03e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 10.31 on 13 degrees of freedom\n## Multiple R-squared:  0.9384, Adjusted R-squared:  0.9337 \n## F-statistic:   198 on 1 and 13 DF,  p-value: 3.028e-09\nAge=c(2,4,6,8,10,12,14,16,18,20,22,24,26,28,30)\nHeight=c(50, 65,85, 95, 110, 120,130,140,145, 152, 158, 169, 170, 171, 171.2)\n\n#to log transform simply use the log function:\nLogHeight=log(Height) #log transforming the variable Y\nLogAge=log(Age)       #log transforming the variable X\n\nLogLM=lm(LogHeight~LogAge) #now we re-run the model, but with the transformed variables\n\nplot(LogHeight~LogAge, ylab=(\"Log height (cm)\"), xlab=(\"Log age (years)\"))\nabline(coef = coef(LogLM))\nsummary(LogLM)## \n## Call:\n## lm(formula = LogHeight ~ LogAge)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.06615 -0.01057  0.01062  0.02135  0.03612 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.56706    0.02982   119.6  < 2e-16 ***\n## LogAge       0.48275    0.01120    43.1 2.04e-15 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.03277 on 13 degrees of freedom\n## Multiple R-squared:  0.9931, Adjusted R-squared:  0.9925 \n## F-statistic:  1858 on 1 and 13 DF,  p-value: 2.043e-15"},{"path":"regression-1.html","id":"exercises-2","chapter":"7 Regression","heading":"Exercises","text":"questions may take load depending internet connection.","code":""},{"path":"regression-1.html","id":"homework-4","chapter":"7 Regression","heading":"Homework","text":"biologist monitoring population wolfs caribou several years Denali National Park, Alaska.Let x represents caribou population (hundreds) y wolf population park.x = 30 34 27 25 17 23 20\ny = 66 79 70 60 48 55 60Make scatter plot data, adjust aesthetics figure follows publication guidelines.Make scatter plot data, adjust aesthetics figure follows publication guidelines.equation defines linear relationship wolfs caribou.equation defines linear relationship wolfs caribou.wolf population caribou.wolf population caribou.increase wolf population hundred caribou.increase wolf population hundred caribou.expected wolf population, say 1000 caribou?. caution prediction?expected wolf population, say 1000 caribou?. caution prediction?strong relationship?. evidence can provide?strong relationship?. evidence can provide?significant, evidence can provide?. also mean significant?significant, evidence can provide?. also mean significant?Place figure responses Word document email homework. Send nice looking document.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"8 Hypothesis testing","heading":"8 Hypothesis testing","text":"prior chapters, dealing three core goals statistics: visualization data (.e., scatterplots, histograms, etc.), description data (.e., mean, mode, SD, etc), relationships among variables (e.g., correlation, regression). chapter, deal fourth main goal statistics: tell something (one thing) somethings (many things) different.amazing level complexity single question, whether thing set things different. chapter, want break complexity peaces, can better comprehend results test aimed testing significant differences.\nFigure 8.1: Rejecting extremes special\nExpectation chapterAt end chapter, expected :Can state null hypothesis alternative hypothesis.Can state null hypothesis alternative hypothesis.Can interpret level significance critical values.Can interpret level significance critical values.Can interpret p-value.Can interpret p-value.Can interpret different types errors making conclusion hypothesis.Can interpret different types errors making conclusion hypothesis.Alright, let’s get .","code":""},{"path":"hypothesis-testing.html","id":"background-info","chapter":"8 Hypothesis testing","heading":"Background info","text":"question asked something different, know thing different? rare case two things identical, everything different?. statistic, commonly use term significantly different indicate precisely level something different. get moment.question formulated whether something significantly different; inherently assume couple things:reference point comparing . reference commonly, almost always, metric obtained population. compared data population know something different.\nFigure 8.2: Population, sample, individual\nsecond thing implied threshold beyond assume something different. determines level something different?. -call level significance, times appear named alpha, \\(\\alpha\\).mentioned earlier, biology sciences, generally accept \\(\\alpha\\) smaller 0.05. Basically, assume something significantly different, larger smaller top bottom 5% individuals population.\nFigure 8.3: p<0.05 feels like\ncourse, can use different levels significance, cases means : threshold beyond assume something different.particular value distribution given \\(\\alpha\\) occurs call critical value. Say want test hypothesis given rabbit significantly larger common rabbit want test hypothesis level significance 0.1. case, need know size 10% common rabbit occurs.example , 10% rabbits larger 7in. case, critical value level significance 0.1 7in.called critical value, cut determine sample significantly different .example , rabbit want compare 6.8in tall, significance level=0.01, rabbit significantly large.\nFigure 8.4: Critical value\nway, 1 - \\(\\alpha\\) call level confidence. Think , conclude something significantly different \\(\\alpha\\)=0.05, confidence complement , 0.95 95%.Let’s put together data population level significance better know make call whether something different.","code":""},{"path":"hypothesis-testing.html","id":"p-value-and-alpha","chapter":"8 Hypothesis testing","heading":"p-value and alpha","text":"Early , studied population can characterized based mean value individuals variability individuals, -call standard deviation. two parameters alone can know entire population looks like.Lets look example. USA, average men 177.8cm height standard deviation 7.62cm. Lets plot population.figure , can see men average 177.8 cm tall, men can get tall others short. just know, distribution , tallest men \\(225.48\\) cm shortest \\(134.96\\) cm.One cool property population data, specially data normally distributed, can tell relatively well fraction individuals away mean knowing standard deviation.recall Chapter 5, mentioned 95% individuals normally distributed population within two-standard deviations mean. Lets check .figure , illustrate random samples males taken US men height population. count fraction men two standard deviations mean height (percentage red numbers shown figure) sample, see sample cumulatively almost always 5%, 2.5% tail distribution. Cool ah?\nFigure 8.5: Fraction population beyond 2SD l\ngets even better, can know precisely, fraction individuals population given standard deviation.Let’s say found men 193.04cm tall. fraction men can taller ?case, guy 2SD (Standard deviations) mean. average height \\(177.8\\) one standard deviation, SD, \\(7.62\\). , \\(177.8\\) + (2 *\\(7.62)\\) = \\(193.04\\).know mean 50% men, two standard deviations mean 47.5%. 97.5% men shorter guy. guys tall tallest 2.5% men th USA. assume level significance 5%, can claim one guy significantly tall.\nFigure 8.6: like ?\nmathematic property normal population also works reverse. Let’s say found men \\(162.56\\)cm tall?. fraction can shorter ?case, guy 2SD (Standard deviations) mean. average height \\(177.8\\) one standard deviation, SD, \\(7.62\\). \\(177.8\\) - (2 *\\(7.62)\\) = \\(162.56\\).know mean 50% men, two standard deviations mean 47.5%. 97.5% men taller guy. guy short shortest 2.5% men th USA. assume level significance 5%, can claim one guy significantly short.statistics, fraction individuals, members, data points, etc. given sample value population called p-value.example , conclusion one guy significantly shorter p-value = 0.025 2.5%.assume level significance, \\(\\alpha\\), 0.05, assuming something significantly smaller taller, short tall shortest tallest 5% population.R, can find critical value distribution data given significance level using \\(qnorm\\) function, used earlier. Worth nothing function assumes population normally distributed. use fucntion briefly.example just , short guy \\(162.56\\)cm tall, short shortest 2.5% population. person significantly small \\(\\alpha\\) 0.05. fact, can confident conclusion p-value 0.025; know 97.5% US population taller .Multiple academic discussions taken place around need report level significance p-value accurate. least now know mean.example , can see overall approach test something significantly different relatively straightforward.need know many standard deviations mean given individual sample . can know fraction individuals given number (p-value). can compare p-value level significance, \\(\\alpha\\), want use. p-value smaller level significance conclude one thing significantly different given \\(\\alpha\\).Lets finish section looking fraction individuals population increasing larger standard deviation. short fractions tail distributiona re predictable know standard deviation population.\nFigure 8.7: Significance level\n","code":"\nMean_Height=177.8   # height of average male in the USA\nSD_Heigh=7.62       # Standard deviation of male population in the USA\n\nMenUSPop<- rnorm(164000000,Mean_Height,SD_Heigh) #we select from a population with that mean and SD, the 164 million men in the use. This will be the entire population....this line may take a while, dependenting how good your computer is...you are taking over 160 million values...you can click scape if it take to long and use rather take a still large sample of 1.6 million men, for contnuing with the execersize.\n\nbreaks = seq(100, 240, length.out = 80) #I create a set of bins for the x-axis of the distribution\n\n#next I plot the data for the size of the entire population of men in the USA\n hist(MenUSPop, main=NA,xlim=c(100, 240),ylim=c(0, 20000000),breaks = breaks, xlab = \"US men heigth (cm)\",ylab = \"Number of people\")\n \n \n#plot the mean height of men\nabline(v=Mean_Height, lwd=2, col=\"blue\", lty=2) \n\n#lets add a label to mean label\ntext(Mean_Height,20000000,labels=\"Mean\",pos=4, col=\"blue\") "},{"path":"hypothesis-testing.html","id":"approach-to-testing-a-hyphothesis","chapter":"8 Hypothesis testing","heading":"Approach to testing a hyphothesis","text":"prior section, sow test something significantly different . overtime can get right away, know ritual/approach test hypothesis. goes like :State null alternative hypothesis.State null alternative hypothesis.Chose level significance.Chose level significance.Find critical values.Find critical values.Compare sample value critical value.Compare sample value critical value.Draw conclusion.Draw conclusion.","code":""},{"path":"hypothesis-testing.html","id":"stating-hyphotheses-and-tails","chapter":"8 Hypothesis testing","heading":"Stating hyphotheses and tails","text":"statistical approach hypothesis testing reduce likely options binary choice null hypothesis alternative hypothesis.null hypothesis denoted letters \\(Ho\\). alternative hypothesis denoted letters \\(H1\\).null hypothesis always making reference things commonly , can also make references option -difference something equal given value. alternative hypothesis null hypothesis .Check following video, state hypothesis.\nstatistics, can reject null hypothesis fail reject null hypothesis (synonym accept null hypothesis, term accepted never certain). Along lines, reject null hypothesis, accept alternative hypothesis.\nFigure 8.8: Painfull rejection narrative\nseveral ways state hypotheses. Let’s try examples clarify:Say burger company claims Combo #1 1,800 calories, variability (Standard deviation, SD) 50 calories. test true can set hypotheses different ways, like:Null hypothesis, Ho: Combo1 = 1,800 calories.Alternative hypothesis, H1: Combo1 \\(\\neq\\) 1,800 calories.form, asking burger equal 1,800 calories. case, alternative burger different 1,800cal. different, burger much smaller 1,800cal can also much larger 1,800 calories.take several burgers, measure caloric content, can reject null hypothesis sample took much higher lower number calories critical value significance level, \\(\\alpha\\), chosen falls.call two-tail test. Basically, divide level significance two testing sample much smaller much larger. sample falls red areas, image , reject null hypothesis, means one sample much larger upper 97.5% much lower 2.5%, \\(\\alpha\\)=0.05. Let’s visualize R,hypotheses also stated :Null hypothesis, Ho: Combo1 <= 1,800 calories.Alternative hypothesis, H1: Combo1 > 1,800 calories.example , specific, testing null hypothesis average burger less 1,800 caloriess; alternative hypothesis ti burger 1,800 calories.take several burgers, measure caloric content, can reject null hypothesis sample took much higher number calories critical value significance level, \\(\\alpha\\), chosen falls. call right-tail test. Lets visualize R,hypotheses also set like :Null hypothesis, Ho: Combo1 >= 1,800 calories.Alternative hypothesis, H1: Combo1 < 1,800 calories.example , testing burgers calories company claims. alternative hypothesis, burgers less 1,800 calories.take several burgers, measure caloric content, can reject null hypothesis sample took much fewer number calories critical value significance level chosen falls. call left-tail test. Lets visualize R,","code":"\nmean=1800 # this is the mean number of calories in their burger. We can think of this as the population mean\nsd=50     #this is the variability in calories\n\n# create a normal distribution of burgers with the given mean and SD\nx <- seq(-4,4,length=100)*sd + mean  # This w\ny <- dnorm(x,mean,sd)\n\nplot(x, y, type=\"l\", xlab=\"Calories per burger\", ylab= \"Fraction of burgers\",ylim=c(0,0.009),main=\"Ho: Combo1 = 1,800 calories\") # this is how the calories of the population of burgers should look like\n\n#because this is a two tail distribution, I mean something will be different if it is much larger or much smaller, then you have to look for the critical value at alpha divided by 2. \n\nLowerCriticalVal=qnorm(0.025,mean,sd) # we need to find the critical value at 2.5% and the upper 97.5%...that is a significance level of 5%\nUpperCriticalVal=qnorm(0.975,mean,sd) # upper critical value, or value above which 97.5% of the population occurs.\n  \n#plot the critical thresholds set by alpha\nabline(v=UpperCriticalVal, lwd=2, col=\"red\", lty=2) \nabline(v=LowerCriticalVal, lwd=2, col=\"red\", lty=2) \n\n#Lets plot the critical areas\npolygon(c(x[x>=UpperCriticalVal], UpperCriticalVal), c(y[x>=UpperCriticalVal], y[x==max(x)]), col=\"red\") #right hand tail\npolygon(c(x[x<=LowerCriticalVal], LowerCriticalVal), c(y[x<=LowerCriticalVal], y[x==max(x)]), col=\"red\") #right hand tail\n\n\n#let's make this fancier and put arrows to indicate rejection areas. We will use the package shape for this\n#install.packages(\"shape\")\nlibrary(shape)\nArrows(LowerCriticalVal,0.006,LowerCriticalVal-50,0.006,lwd=2, arr.type=\"triangle\")\ntext(LowerCriticalVal,0.0065,\"Reject\",pos=2)\n\n#we can do add the same arrow for the upper tail of rejection zone\nArrows(UpperCriticalVal,0.006,UpperCriticalVal+50,0.006,lwd=2, arr.type=\"triangle\")\ntext(UpperCriticalVal,0.0065,\"Reject\",pos=4)\n\n#while we are at it, lets indicate the zone of the level of confidence\nArrows(LowerCriticalVal,0.0085,UpperCriticalVal,0.0085,lwd=2, arr.type=\"curved\",code=3)\ntext(mean,0.0085,\"Level of confidence \",pos=3)\nmean=1800 # this is the mean number of calories in their burger. We can think of this as the population mean\nsd=50     #this is the variability in calories\n\n# create a normal distribution of burgers with the given mean and SD\nx <- seq(-4,4,length=100)*sd + mean  \ny <- dnorm(x,mean,sd)\n\nplot(x, y, type=\"l\", xlab=\"Calories per burger\", ylab= \"Fraction of burgers\",main=\"Ho: Combo1 <= 1,800 calories\") # this is how the calories of the population of burgers should look like\n\nUpperCriticalVal=qnorm(0.95,mean,sd) #in this case I am looking for the upper 5% of the individuals..or the threshold at which 95% of the population occurs\n\n#plot the critical thresholds set by alpha\nabline(v=UpperCriticalVal, lwd=2, col=\"red\", lty=2) \n\n#Lets plot the one critical area\npolygon(c(x[x>=UpperCriticalVal], UpperCriticalVal), c(y[x>=UpperCriticalVal], y[x==max(x)]), col=\"red\") #right hand tail\nmean=1800 # this is the mean number of calories in their burger. We can think of this as the population mean\nsd=50     #this is the variability in calories\n\n# create a normal distribution of burgers with the given mean and SD\nx <- seq(-4,4,length=100)*sd + mean  # This w\ny <- dnorm(x,mean,sd)\n\nplot(x, y, type=\"l\", xlab=\"Calories per burger\", ylab= \"Fraction of burgers\",main=\"Ho: Combo1 >= 1,800 calories\") # this is how the calories of the population of burgers should look like\n\n\nUpperCriticalVal=qnorm(0.05,mean,sd) #in this case I am looking for the lower 5% of the individuals..or the threshold at which 5% of the population occurs\n\n\n\n#Lets plot the one critical area\npolygon(c(x[x<=UpperCriticalVal], UpperCriticalVal), c(y[x<=UpperCriticalVal], y[x==max(x)]), col=\"red\") #right hand tail\n\n#plot the critical thresholds set by alpha\nabline(v=UpperCriticalVal, lwd=2, col=\"red\", lty=2) "},{"path":"hypothesis-testing.html","id":"accepting-or-rejecting-the-null-hypothesis","chapter":"8 Hypothesis testing","heading":"Accepting or rejecting the null hypothesis","text":"nutshell, idea testing hypothesis see given individual sample larger smaller population cutoff set level significance, \\(\\alpha\\).two tail test, null hypothesis rejected sample value larger smaller critical value. contrary, sample value within range outlined critical value, conclude failed reject null-hypothesis. Please remember statistics “fail reject” “reject” null hypothesis never prove alternative hypothesis reject null hypothesis.right tail test, null hypothesis rejected sample value larger critical value.\nFigure 8.9: Types tests\nleft tail test, null hypothesis rejected sample value smaller critical value.Hypotheses can also tested simply comparing chosen level significance, \\(\\alpha\\), p-value. Every time p-value smaller \\(\\alpha\\) reject null hypothesis.\nFigure 8.10: P low, Ho must go\nThink moment.Let’s say testing heart rate person significantly larger average population using level significance 0.05.case, assuming heart rate significantly larger heart rate faster top 5% hearth rates human population.Let’s say measured hearth rate person estimated p-value 0.02.means heart rate one person fast top 2% fastest hearth rates population.case, p-value smaller \\(\\alpha\\), reject null hypothesis, conclude indeed hearth rate given individual significantly larger expected average human population.\nFigure 8.11: P-value\n","code":""},{"path":"hypothesis-testing.html","id":"testing-a-hypothesis-by-brutal-force","chapter":"8 Hypothesis testing","heading":"Testing a hypothesis by brutal force","text":"following chapters, introduce standardized ways test hypotheses comparing sample values critical values; want finish chapter illustrating ultimate idea behind testing hypothesis running brief simulation. simulation aim show general approach hypothesis testing.Lets say work FDA, commissioned provide evidence lawsuit case involving calories MacDonals burgers (fictitious example).pending lawsuit refers person suffered heart attack cholesterol levels increased considerably. Prior heart attack, doctor person recommended kept daily diet 2000 calories day, satisfied weakness burgers eating new type MacDonals burger claimed less 1,500 calories (Standard deviation, SD= 50).Let say collected random sample ten burgers found average 1600 calories. question , claim individual hold right?Let’s start stating hypotheses:Null hypothesis, Ho: burger <= 1,500 calories.Alternative hypothesis, H1: burger > 1,500 calories.case, specifically want know burgers less 1500 calories claimed company.want test hypothesis \\(\\alpha\\), level significance, 0.05 5%.Alright, lets start simulation.Next, can plot critical value alpha 0.05 population mean 1500 standard deviation 50.case, critical value \\(\\alpha\\)=0.05, simply cutoff 95% calories MacDonals burgers occurs. assuming population data normal mean 1500 Standard deviation, SD, 50, can find critical value using \\(qnorm\\) function R.comparison critical value sample value, can already observe sample burgers reality calories claimed MacDonals significance level, \\(\\alpha\\), 0.05.Lets try test building actual population expected burgers. , take one random sample normal population mean 1500 standard deviation, SD, 50. R, can take number individuals randomly normally distributed population using function \\(rnorm\\).one sample burger population mean 1500 standard deviation, SD, 50 \\(1508.21\\).Hmm, ok, one random sample. robust, probably take 100,000 random samples see top 5% random samples, critical threshold, larger smaller observed sample value.run simulation, can use loop function R. Lets try. Let explain function example.Ok, just created population 100,000 random samples normal population mean 1500 standard deviation, SD, 50. Let’s histogram databaseLooking good….lets draw line 5% level significance expected distribution. use R function \\(quantile\\), used earlier, find value located 95% percentile, outline position right 5% cases occur. Let’s call modeled critical value, differentiate statistical critical value calculated earlier.Now can compare average calorimetric content actual sample 10 burgers (sample value) value located 5% mark (.e., level significance).Pretty neat, ah?. modeled statistical critical value identical. sample value. short, sample ten burgers (Blue line figure ) much larger critical value 5% (red lines), reject null hypothesis burgers less 1,500 calories, embrace alternative hypothesis burgers 1500 calories. can surmise report judge one guy lawsuiting MacDonals deceived. potential case false advertisement.","code":"\nMeanCal = 1600 #calories in the sample of burgers\n\nplot(1, type=\"n\", xlab=\"Total calories in MacDonal's bugers\", ylab=\"Percent of burgers\", xlim=c(1000, 2000), ylim=c(0, 10)) # lets create an empty plot\n\n#plot the sample value\nabline(v=MeanCal, lwd=2, col=\"blue\", lty=2) \n\n#lets name the mean sample value\ntext(MeanCal,10,labels=\"Sample value\",pos=4, col=\"blue\")\nCriticalVal=qnorm(0.95,1500,50) # here we want to know the cutoff at which 95% of the observations occur in a population with a mean of 1500 and an SD of 50\n\nplot(1, type=\"n\", xlab=\"Total calories in MacDonal's bugers\", ylab=\"Percent of burgers\", xlim=c(1000, 2000), ylim=c(0, 10)) # lets create an empty plot\n\n\n#plot the sample value\n  abline(v=MeanCal, lwd=2, col=\"blue\", lty=2) \n  #lets name the mean sample value\n  text(MeanCal,10,labels=\"Sample value\",pos=4, col=\"blue\")\n\n#plot the critical value\n  abline(v=CriticalVal, lwd=2, col=\"red\", lty=2) \n  #lets name the statistical critical value\n  text(CriticalVal,10,labels=\"Statistical critical value\",pos=2, col=\"red\")\nMeanPopulation=1500\nSDPopulation=50\nRandomSample1<- rnorm(1,MeanPopulation,SDPopulation) \n\nRandomSample1## [1] 1508.21\npopulation= c()  #we create an empty vector where we will store the random averages of our 1000 random samples of ten burgers\nfor (sampleI in 1:100000) { # here I set a variable called sampleI that will loop from 1 to 1000\n  \nmeanRandomSampleI<- rnorm(1,MeanPopulation,SDPopulation) #take a random value\n\n#lets place the value for that sample in the vector\npopulation=c(population, meanRandomSampleI ) #basically I am appending the value of every sample in every loop to the vector\n}\n# the code between {} will run for 100,000 times. to test lest count the number of entries in the vector\n\nlength(population)## [1] 100000\nbreaks = seq(1200, 1800, length.out = 100) #lets create a set of bins\n\nhist(population,main=NA,xlim=c(1200, 1800),ylim=c(0, 5000),breaks = breaks, xlab = \"Total calories in MacDonal's bugers\",ylab = \"Number of ramdon samples\")\nModelledCriticalValue=quantile(population,0.95,type=1) #quantile finds the value in the population of calories located at the top 5% percentile\nModelledCriticalValue##      95% \n## 1582.898\nhist(population,main=NA,xlim=c(1200, 1800),ylim=c(0, 6000),breaks = breaks, xlab = \"Caloric content of burgers\",ylab = \"Number of ramdon samples\")\n\n\n#plot the sample value\n    abline(v=MeanCal, lwd=2, col=\"blue\", lty=2) \n    #lets use a label for it\n    text(MeanCal,6000,labels=\"Sample value\",pos=4, col=\"blue\")\n\n\n#plot the 5% modeled critical value \nabline(v=ModelledCriticalValue, lwd=4, col=\"orange\", lty=2) \n#lets name the critical value\ntext(ModelledCriticalValue,6000,labels=\"Modeled critical value\",pos=2, col=\"orange\")\n\n\n\n#plot the 5% statistical critical value\n  abline(v=CriticalVal, lwd=2, col=\"red\", lty=2) \n  #lets name the mean sample value\n  text(CriticalVal,5500,labels=\"Statistical critical value\",pos=2, col=\"red\")"},{"path":"hypothesis-testing.html","id":"error-types","chapter":"8 Hypothesis testing","heading":"Error types","text":"probably noted level caution used testing hypotheses. work probabilities, never certain.hypothesis testing, deal primarily things never know sure; always chance wrong making conclusion. chance wrong can separated two different types errors called Type Type II errors.found couple neat examples online check clarification Type-Type-II errors hereLets try one example going hell heaven depending threshold qualifies good bad thing…example goes like :\nFigure 8.12: Errors send hell\nGod, never met person, holds ultimate threshold actions qualify go heaven . know guy, fully clear guidelines, may speculation threshold. point ultimate threshold, ultimate truth, know certain.side problem judgment God mean threshold . ten commitments nice start, mean teacher?. Bible says others want others . mean another person take points score go heaven?. play save nice everyone, including teacher, uncertain mean reduces score going--heaven ticket.point ultimate threshold defines truth, threshold know certain, can approximate. approximation threshold called \\(\\alpha\\) earlier: chance giving wrong decisions.human \\(\\alpha\\) threshold matches divine threshold, got lucky, right every time something life. errors . right things knowingly knowing end heaven wrong things knowingly knowing end hell.However, threshold low lot mean things, turned bad reduced going--heaven-score, threshold error let conclude certain things ok, truth . think type error, accepted hypothesis certain things ok, turned fine. call false negative, Type II error.Say opposite threshold define right high. may help minimize Type II error, high threshold means probably things ok, things may make life nicer. high threshold lead call false positive Type error. Rejecting things turned ok.\nFigure 8.13: Type Type II errors\nfalse positive, also call Type error, reject null hypothesis , fact, true.","code":""},{"path":"hypothesis-testing.html","id":"exercises-3","chapter":"8 Hypothesis testing","heading":"Exercises","text":"questions may take load depending internet connection.","code":""},{"path":"hypothesis-testing.html","id":"homework-5","chapter":"8 Hypothesis testing","heading":"Homework","text":"annual migration bird watershed Florida remained stable several years average 1,2 million birds standard deviation 100,000 birds. last year, number birds 700,000. numerous concerns development project may damaging habitats bird. first order inquiry, need know year’s number significantly lower prior years. Please test hypothesis 5% level confidence?exercise, please:Write null alternative hypothesis.Write null alternative hypothesis.Please run R-simulation test hypothesis.Please run R-simulation test hypothesis.Create frequency distribution plot indicating expected distribution birds mark line observed value last year. Also mark figure 5% boundary expected distribution.Create frequency distribution plot indicating expected distribution birds mark line observed value last year. Also mark figure 5% boundary expected distribution.Word document write answers, figure code.","code":""},{"path":"standard-hypothesis-tests.html","id":"standard-hypothesis-tests","chapter":"9 Standard hypothesis tests","heading":"9 Standard hypothesis tests","text":"prior chapter, learned basic principle hypothesis testing find given value (sample) extremes population. threshold mean extreme determined \\(\\alpha\\) value. can test hypothesis brutal force running simulation, can also run set available tests tell position sample relation population.diversity statistical tests available testing hypotheses, deal tests intended test one thing, two things two things different.way, suitability available tests depends whether data normally distributed (please recall chapter 3 normally distributed data looks like bell-shape curve).\nFigure 9.1: Data distribution\nTests normally distributed data call parametric tests. cases, data normal (e.g., biased, homogeneous) requires different set tests called non-parametric tests. cover non-parametric need aware distinction.Expectation chapterAt end chapter, expected can identify case want test (.e., one, two sample tests), select proper statistical method test significant differences case.","code":""},{"path":"standard-hypothesis-tests.html","id":"alternative-types-of-tests","chapter":"9 Standard hypothesis tests","heading":"Alternative types of tests","text":"comparing samples, broad terms, three likely options:","code":""},{"path":"standard-hypothesis-tests.html","id":"one-sample-test-1","chapter":"9 Standard hypothesis tests","heading":"One sample test","text":"type case relates situations sample parameter want compare population.Say disappointed much smaller candy bars store look like. Say take samples candy bars found average 180g. label says average 200g +/-10g. case one-sample test. Basically, one sample want find different expected value population.Let’s visualize :","code":"\nSampleWeight=180  # this is the average weight of the samples you took\nPopulationWeight=200   # Average weight reported in the lable of the candy bar. This of this as the population mean.\nSD=10       # reported Standard deviation for the candy bars. Think if this as the population standard deviation\n\nSimulatedPopulation<- rnorm(10000,PopulationWeight,SD) #lets simulate a population of 10000 candy bars.\n\nbreaks = seq(150, 250, length.out = 80) #I create a set of bins for the x-axis of the distribution, this will determine how many bis you have\n\n#next I plot the data\n hist(SimulatedPopulation, main=NA,xlim=c(150, 250),ylim=c(0, 800),breaks = breaks, xlab = \"Candy bar weight (g)\",ylab = \"Number of candies\")\n \n \n#plot the sample mean\nabline(v=SampleWeight, lwd=2, col=\"red\", lty=2) \n\n#lets add a label to mean label\ntext(SampleWeight,700,labels=\"Sample\",pos=4, col=\"red\") "},{"path":"standard-hypothesis-tests.html","id":"two-sample-test-1","chapter":"9 Standard hypothesis tests","heading":"Two sample test","text":"cases want compare samples two different populations.Say noted fuel-car gas station , can take average one trip work fuel-car gas station B. suspecting gas station B giving less gas suppose .can report consumer group, likely test take samples one gallon gas stations measure actual volume dispense. Say sample 50 trials yields volumes 1.1 gal +/-.05gal Gas station 1.01 gal +/-.02gal Gas station B.case two-sample test. case, can treat samples independent, assume come independent populations similar.Lets visualize :","code":"\nMeanGasA=1.1  # average gas volume for a suspected 1 gallon dispensing at gas station A\nSDGasA=0.05   # SD for sample from gas station A\n\nMeanGasB=1.01  # average gas volume for a suspected 1 gallon dispensing at gas station B\nSDGasB=0.02   # SD for sample from gas station B\n\n\nSimulatedGasA<- rnorm(10000,MeanGasA,SDGasA) #lets simulate a population for gas station A.\nSimulatedGasB<- rnorm(10000,MeanGasB,SDGasB) #lets simulate a population for gas station B.\n\n\nbreaks = seq(0.7, 1.4, length.out = 100) #I create a set of bins for the x-axis of the distribution, this will determine how many bis you have\n\n#next I plot the data. because we want to plot two distributions on top of each other. we need to create each distribution independently and then add them to a  single plot\n\n#histogram for gas station A.\nGasA= hist(SimulatedGasA, xlim=c(0.7, 1.4),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n#histogram for gas station B.\nGasB= hist(SimulatedGasB, xlim=c(0.7, 1.4),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n#because you are plotting two distributions, it will be nice to use different colors. and because they likely overlap, you should use semitransparent colors\nLightBlue <- rgb(173,216,230,max = 255, alpha = 5) #the function rgb lets you select one color, and the alpha gives you how transparent\nDarkRed <- rgb(255,192,203, max = 255, alpha = 95)\n\n\n#lets plot the first distribution\nplot(GasA, main=NA,xlim=c(0.7, 1.4),ylim=c(0, 1500),breaks = breaks, xlab = \"Dispensed gas volume for a reported 1 gallon (in gallons)\",ylab = \"Number of trials\" ,col=LightBlue)\n\nplot(GasB, add=T ,col=DarkRed)  #note how for the parameter col, you indicate the color you create as a variable above"},{"path":"standard-hypothesis-tests.html","id":"more-than-two-sample-test-1","chapter":"9 Standard hypothesis tests","heading":"More than two sample test","text":"cases want compare samples two different populations.Say visited three countries noticed men different height. use men USA, already established average height 177.8cm +/-SD 7.62 cm. France, 172.8cm +/-SD 5.62 cm North Korea 155.5 cm +/- 8.5cm.case three samples, times called multiple samples.Lets visualize :","code":"\nUSA_Height=177.8   # height of average male in the USA\nUSA_SD=7.62       # Standard deviation of male population in the USA\n\nFrance_Height=172.8   # France data\nFrance_SD=5.62       # SD for france\n\nNKorea_Height=155.5   # North Korea data\nNKorea_SD=8.5       # SD for North Korea\n\n\nSimulatedUSA<- rnorm(10000,USA_Height,USA_SD) #lets simulate a population for USA\nSimulatedFrance<- rnorm(10000,France_Height,France_SD) #lets simulate a population for France\nSimulatedNKorea<- rnorm(10000,NKorea_Height,NKorea_SD) #lets simulate a population for NKorea\n\n\nbreaks = seq(120, 220, length.out = 100) #bins for the distribution\n\n#histogram for USA\nUSA= hist(SimulatedUSA, xlim=c(120,220),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n#histogram for FCrance\nFrance= hist(SimulatedFrance, xlim=c(120,220),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n#histogram for USA\nNKorea= hist(SimulatedNKorea, xlim=c(120,220),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n\n\n#because you are plotting three distributions, it will be nice to use different colors. and because they likely overlap, you should use semitransparent colors\nLightBlue <- rgb(173,216,230,max = 255, alpha = 100) #the fucntion rgb lets your select one color, and the alpha gives you how tranparent\nDarkRed <- rgb(255,192,203, max = 255, alpha = 95)\nMiddleOrange <- rgb(255,69,0, max = 255, alpha = 95)\n\n#lets plot the first distribution\nplot(USA, main=NA,xlim=c(120, 220),ylim=c(0, 800),breaks = breaks, xlab = \"Men size (cm)\",ylab = \"Number of people\" ,col=LightBlue)\n\n#now add the second distribution to the first plot, using the parameter add=TRUE, or add=T, theya re both the same\nplot(France, add=T ,col=DarkRed)  #note how for the parameter col, you indicate the color you create as a variable above\n\nplot(NKorea, add=T ,col=MiddleOrange)  #note how for the parameter col, you indicate the color you create as a variable above"},{"path":"standard-hypothesis-tests.html","id":"selecting-the-right-test","chapter":"9 Standard hypothesis tests","heading":"Selecting the right test","text":"moment able identify cases involving comparisons one, two samples.interested testing significant differences cases select among tests called Z-test, T-test ANOVA (also -called analysis variances).test use based primarily number samples , whether know variance population whether sample size larger 30 individuals .need use following chart select proper test. Please remember parametric tests, meaning useful cases data normally distributed.\nFigure 9.2: Selecting statistical test\nAlso take moment review hypotheses stated, important moment select right type test.","code":""},{"path":"standard-hypothesis-tests.html","id":"homework-6","chapter":"9 Standard hypothesis tests","heading":"Homework","text":"Create publication quality plot case examples. plot, indicate inside plot case one, two samples:Chevrolet Honda strongly competing produce hybrid cars option electrical cars. Honda model drives 50mpg (miles per gallon) +/-5mpg Chevrolet model drives 55mpg (miles per gallon) +/-7mpg.Chevrolet Honda strongly competing produce hybrid cars option electrical cars. Honda model drives 50mpg (miles per gallon) +/-5mpg Chevrolet model drives 55mpg (miles per gallon) +/-7mpg.Students school got average GPA 3.8, considered award among best national level, average GPA 3.5 +/-0.12.Students school got average GPA 3.8, considered award among best national level, average GPA 3.5 +/-0.12.China currently looking optimize food production within borders run experiment biomass production wheat, rice corn. annual yields 55500 tns +/-500tns wheat, 45500 tns +/-200tns rice, 35500 tns +/-255tns corn.China currently looking optimize food production within borders run experiment biomass production wheat, rice corn. annual yields 55500 tns +/-500tns wheat, 45500 tns +/-200tns rice, 35500 tns +/-255tns corn.Generate quality plots, need code report.","code":""},{"path":"one-sample-tests.html","id":"one-sample-tests","chapter":"10 One sample tests","heading":"10 One sample tests","text":"One sample tests cases one sample, determine belongs certain population. Like:gas Hawaii significantly expensive rest USA?.10 year old girl taller expected?types questions can answered either Z-test T-Test, introduce chapter. tests suited one-sample test, Z-test used cases know population standard deviation (SD) sample size larger 30 observations. contrary, know population SD sample size smaller 30 observations, used T-Test.\nFigure 10.1: Z-score fucntion\nend chapter, expected :Run one sample Z-test interpret results R.Run one sample Z-test interpret results R.Run one sample T-test interprets results R.Run one sample T-test interprets results R.","code":""},{"path":"one-sample-tests.html","id":"the-one-sample-z-test-by-hand","chapter":"10 One sample tests","heading":"The one-sample Z-test by hand","text":"mentioned earlier, Z-test used cases want run one-sample test, know population standard deviation sample size larger 30 individuals. (grabs token L).principle Z-score straightforward. Basically, score allows know many Standard deviations mean given sample .indicated several times book, relatively easy know proportion individuals population certain standard deviations mean (data normally distributed, course).example, plus minus two standard deviations mean includes 95% individuals population (assuming population normally distributed).Given principle can easily know fraction individuals certain standard deviations mean.z-cores basically index allows convert/standardize value given number standard deviations mean.\nFigure 10.2: Z-test fucntion\nLets try example.Say want know USA female team run particularly faster 100m race teams.studeid 31 girls times runing 100m seconds :9.7, 9.7, 8.9, 9.2, 9.4, 9.1, 9.5, 9.6, 8.9, 9.1, 9.5, 9.2, 9.5, 9.4, 9.6, 9.2, 9.9, 10, 9.3, 9.6, 9.1, 9.5, 9.2, 9.5, 9.4, 9.6, 9.2, 9.9, 10, 9.3, 9.6.turn, historical time running race 9.5sec +/-0.2sec.example, looks like one sample want compare population. standard deviation, SD, population sample size larger 30, best test Z-test.customary, start stating hypothesis:H0: Time USA team = 9.5 sec null hypothesis things suppose …means, historical time 9.5secH1: Time USA team < 9.5 sec alternative hypothesis interested , claiming…USA team faster 9.5secLet’s calculate z-score:Now need recall chapter 8 find left-, right- two tail test. forgotten, check video refreshers:, alternative hypothesis stating sample smaller , use left-sided test.\nFigure 10.3: Types tests\nlook significance level (\\(\\alpha\\)) Z-table left-sided test, like one (tables back stats book online).Z-table give p-value given Z-value…words, fraction population beyond given z-score.\nFigure 10.4: Left-sided Z-table\nfind p-value given Z-score left-sided Z-table, scroll first column looking first decimal point calculated z-score. case -1.9.row, go back first row, move horizontally column second decimal point calculated Z-score, case 0.Basically, looking value interception first decimal point calculated z-score indicated first column, second decimal z-score indicated first row Z-table.case, p-value Z-score -1.90 0.0287.tells girls USA team fast top 2.87% teams.compare significance level, \\(\\alpha\\), 0.05, calculated p-value 0.0287, can observed p-value smaller \\(\\alpha\\), Ho (null hypothesis) must go.Basically, reject null hypothesis 100m run time team 9.5sec higher conclude girls indeed run faster historical average.","code":"\nSample=c(9.7, 9.7, 8.9, 9.2, 9.4, 9.1, 9.5, 9.6, 8.9, 9.1, 9.5, 9.2, 9.5, 9.4, 9.6, 9.2, 9.9, 10, 9.3, 9.6, 9.1, 9.5, 9.2, 9.5, 9.4, 9.6, 9.2, 9.9, 10, 9.3, 9.6) #lets put the values in a vector\n\nSampleMean=mean(Sample) #mean time racing for the girls sampled\nSampleSize= length(Sample)  # this is the sample size or number of girls measured\n\nPopulationMean= 9.5 #this is the population mean...or the historical time it has taken people to run 100m\nPopulationSD=0.2 #this is the population standard deviation\n\n\n#let's now estimate the z-score using the equation above.\n\nZTest=(SampleMean-PopulationMean)/(PopulationSD/sqrt(SampleSize))\nZTest## [1] -1.70625"},{"path":"one-sample-tests.html","id":"the-one-sample-z-test-in-r","chapter":"10 One sample tests","heading":"The one-sample Z-test in R","text":"can run test R, using package BSDA, function z.test. Lets try .results look like image , nearly identical hand calculation. \nFigure 10.5: R-results one-sample z-test\n","code":"\n# install.packages(\"BSDA\")   #first install the library, if you have not this library installed....simply remove the # sign and run this line\nlibrary (\"BSDA\")           #load the library\nSample=c(9.7, 9.7, 8.9, 9.2, 9.4, 9.1, 9.5, 9.6, 8.9, 9.1, 9.5, 9.2, 9.5, 9.4, 9.6, 9.2, 9.9, 10, 9.3, 9.6) #lets put the values in a vector\nPopulationMean= 9.5 #this is the population mean...or the historical time it has taken people to run 100m\nPopulationSD=0.2 #this is the population standard deviation\n\nz.test(x=Sample, alternative = \"less\", mu = PopulationMean, sigma.x = PopulationSD, conf.level = 0.95)\n\n#the parameters needed to run a Z-test are self-explanatory. x is the array with your sample data. alternative is the type of test to run, in this case we want to check is the sample is less than the population mean. mu is the population mean, and sigma.x is the standard deviation of the population. This function ask for the confidence level, which as we indicated before is the complement to the level of significance we use, in our case our significance level is 0.05, so the confidence level will be 0.95"},{"path":"one-sample-tests.html","id":"the-one-sample-t-test-by-hand","chapter":"10 One sample tests","heading":"The one-sample T-test by hand","text":"perform one-Sample t-test want compare sample mean population mean know population standard deviation sample size small, n < 30. difference Z Test information Population Variance . use sample standard deviation instead population standard deviation case.\nFigure 10.6: R-results one-sample z-test\nLets try example.Let’s say want determine average girls score 600 points given exam. information related variance (standard deviation) girls’ scores, take randomly scores 10 girls. choose \\(\\alpha\\) value (significance level) 0.05.scores ten girl :587, 602, 627, 610, 619, 622, 605, 608, 596, 592.Lets’ set hypothesisH0: \\(\\mu\\) =< 600 true expected valueH1: \\(\\mu\\) > 600 question interest, case know girsl scored higherIn case, one-sample comparison, know population variance, sample size 10 individuals, T-test best suited .Let’s one hand,estimated T-value 1.64.Now, need find critical t-value 0.05 significance level. , need estimate something call Degrees freedom, case simply sample size minus one. case, degrees freedom, , 9.information \\(\\alpha\\) value (.e., 0.05 case) degrees freedom, DF (.e, 9 case), can look critical T-value table, like one .Basically, scroll first column looking 9 DF, move horizontally column displaying 0.05 level significance, intercept critical t-value. case number 1.8331.\nFigure 10.7: R-results one-sample z-test\ncritical t-value 9DF \\(\\alpha\\)=0.05 1.8331. means 5% given population T-value 1.8331.case, calculated t-value 1.64, smaller critical value, fail reject null hypothesis don’t enough evidence support hypothesis average, girls score 600 exam.one T-table cases left-, right-, two-tail test. need left-side score, simply remove sign look critical t-value table . T-distribution symmetric mean: right left.need two-tail test, divide significance level 2, look value T-table. Say, using significance level 0.05 testing alternative hypothesis something different, running two-tail test, meaning looking see sample value either tail population distribution. case, need divide significance level (\\(\\alpha\\)) 2 account fact checking two-tails distribution.","code":"\nSample=c(587, 602, 627, 610, 619, 622, 605, 608, 596, 592) #lets put the values in a vector\n\nSampleMean=mean(Sample) #mean score of the girls sampled\nSampleSD=sd(Sample) #this is the sample standard deviation\nSampleSize= length(Sample)  # this is the sample size \n\nPopulationMean= 600 #this is the true, expected value, think of it as the population mean...\n\n#let's now estimate the T-score using the equation above.\n\nTTest=(SampleMean-PopulationMean)/(SampleSD/sqrt(SampleSize))\nTTest"},{"path":"one-sample-tests.html","id":"the-one-sample-t-test-in-r","chapter":"10 One sample tests","heading":"The one-sample T-test in R","text":"can run T-test R, using package BSDA, function tsum.test. Lets try .results look like image , nearly identical hand calculation.\nFigure 10.8: R-results one-sample z-test\n","code":"\nlibrary (\"BSDA\")           #load the library\nSample=c(587, 602, 627, 610, 619, 622, 605, 608, 596, 592) #lets put the values in a vector\n\nSampleMean=mean(Sample) #this is the sample mean\nSampleSD= sd(Sample)    #this is the sample standard deviation\nSampleSize=length(Sample)  #sample size\n\nPopulationMean= 600 #this is the population mean...or the expected score, which is assumed to be 600 points\n\ntsum.test(mean.x=SampleMean, s.x = SampleSD, n.x = SampleSize, alternative = \"greater\", mu = PopulationMean, conf.level = 0.95)\n\n\n#the parameters needed to run a T-test are self-explanatory. mean.x is the mean of your sample data. alternative is the type of test to run, in this case we want to check is the sample is greater than the population mean. mu is the population mean, and s.x is the standard deviation of the sample. This function ask for the confidence level, which as we indicated before is the complement to the level of significance to use, in our case our significance level is 0.05, so the confidence level will be 0.95"},{"path":"one-sample-tests.html","id":"homework-7","chapter":"10 One sample tests","heading":"Homework","text":"problems :State null alternative hypothesis.one tail two-tail test?.Indicate type test use (Z-test T-test).Run given test R, hand, ever easier.Report results top publication quality plot.Describe conclusion.Problem 1:\nPublic safety standards indicate CO2 emissions gasoline cars 8.89kilogram +/-.2 kg gallon gasoline used.car company sued costumers claim cars produce much carbon emissions. sample 500 cars given company used measure carbon emissions results indicated average cars produced 9.2 CO2kg/gallon gas. data support claim costumers?Problem 2:\nenergy drink company recently purchased bottling machine 250ml trade-mark product. releasing product, factory manager wants confirm right volume liquid dispensed machine. measured volume liquid several samples, 245.5, 249.2, 251.2, 251.1, 252ml. Given data, recommendation starting pack product machine?","code":""},{"path":"two-sample-tests.html","id":"two-sample-tests","chapter":"11 Two sample tests","heading":"11 Two sample tests","text":"Two sample tests cases want compare two independent samples. Like:students school yielding better math scores students School B?.apples heavier oranges?.premise similar two samples, less likely significantly different.\nFigure 11.1: Two populations different means, n=5\ntypes questions can answered either Z-test T-Test, introduce chapter. tests suited two-sample tests, Z-test preferred t-test large samples (n > 30) population variance known.\nFigure 11.2: Z-test T-test?\nend chapter, expected :Run two sample Z-test interpret results R.Run two sample Z-test interpret results R.Run two sample T-test interprets results R.Run two sample T-test interprets results R.","code":""},{"path":"two-sample-tests.html","id":"the-two-sample-z-test-by-hand","chapter":"11 Two sample tests","heading":"The two-sample Z-test by hand","text":"two-sample Z-test used compare means two different samples, know population standard deviation sample size larger 30 individuals.\nFigure 11.3: Z-test fucntion two samples\nLets try example.researcher wants determine given drug different placebo affecting physical endurance (.e, time takes 20 push-ups).Nine hundred subjects given drug prior testing, whereas 1000 subjects receive placebo.drug group, took 9.78sec average (S.D. = 4.05) 20 push-ups, whereas placebo group took 15.10sec average (S.D. = 4.28).drug effect physical performance? Let’s test hypothesis \\(\\alpha\\) 0.05,5%.Lets start visualizing data:Lets state hypotheses:H0: Drug performance time = placebo time null hypothesis two groups take time.H1: Drug performance time \\(\\neq\\) placebo time alternative hypothesis different.read carefully question, see motivation researcher see drug “different”. purpose, can state alternative hypothesis accordingly.Perhaps better statement drug better, case null hypothesis greater , case need right-hand test, oppose two-tail test asked different. comes statistics, things life, always written, supporting evidence.test use?. Well, sample size larger 30, Z-test seems appropriated.Lets calculate Z-score comparing two samplesBy now, know well two standard deviations mean include 95% observations normally distributed population. value -27.82 standard deviations away mean even appear traditional z-tables, can certainly reject null hypothesis conclude drug indeed different placebo.","code":"\nDrug_Mean=9.78   \nDrug_SDSD=4.05\n\nPlacebo_Mean=15.10\nPlacebo_SD=4.28\n\nSimulatedDrug<- rnorm(10000,Drug_Mean,Drug_SDSD)\nSimulatedPlacebo<- rnorm(10000,Placebo_Mean,Placebo_SD)\n\nbreaks = seq(-20,40, length.out = 50) #bins for the distribution\n\n#histogram for drug\nDrug= hist(SimulatedDrug, xlim=c(-20,40),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n#histogram for Placebo\nPlacebo= hist(SimulatedPlacebo, xlim=c(-20,40),ylim=c(0, 500),breaks = breaks,  plot = FALSE)\n\n\n#because you are plotting two distributions, it will be nice to use different colors. and because they likely overlap, you should use semitransparent colors\nLightBlue <- rgb(173,216,230,max = 255, alpha = 100) #the function rgb lets your select one color, and the alpha gives you how transparent\nDarkRed <- rgb(255,192,203, max = 255, alpha = 95)\n\n\n#lets plot the first distribution\nplot(Drug, main=NA,xlim=c(-20,40),ylim=c(0, 1500),breaks = breaks, xlab = \"Time to do 20 push-up (Seconds)\",ylab = \"Number of people\" ,col=LightBlue)\n\n#now add the second distribution to the first plot, using the parameter add=TRUE, or add=T, theya re both the same\nplot(Placebo, add=T ,col=DarkRed)  #note how for the parameter col, you indicate the color you create as a variable above\nDrug_Mean=9.78   \nDrug_SDSD=4.05\nDrug_n =900   #sample size for the drug treatment\n\nPlacebo_Mean=15.10\nPlacebo_SD=4.28\nPlacebo_n=1000 #sample size for the placebo treatment\n\n \nZ_Score_Numerator= (Drug_Mean-Placebo_Mean) -0  #because we assume that the two treatments have the same effect, we then have to assume that the difference between the population means is zero.\n\nZ_Score_denominator= sqrt(((Drug_SDSD^2)/Drug_n)+((Placebo_SD^2)/Placebo_n))\n                          \nZ_score=Z_Score_Numerator/Z_Score_denominator\nZ_score## [1] -27.82961"},{"path":"two-sample-tests.html","id":"the-two-sample-z-test-in-r","chapter":"11 Two sample tests","heading":"The two-sample Z-test in R","text":"can run test R, using package BSDA, function z.test. Lets try .\nFigure 11.4: Z-test results two samples R\n","code":"\n# install.packages(\"BSDA\")   #first install the library, if you have not this library installed....simply remove the # sign and run this line\nlibrary (\"BSDA\")           #load the library\n\nDrug_Mean=9.78   \nDrug_SDSD=4.05\nDrug_n =900   #sample size for the drug treatment\n\nPlacebo_Mean=15.10\nPlacebo_SD=4.28\nPlacebo_n=1000 #sample size for the placebo treatment\n\nzsum.test(mean.x=Drug_Mean, sigma.x = Drug_SDSD, n.x = Drug_n,\n          mean.y = Placebo_Mean, sigma.y = Placebo_SD, n.y = Placebo_n, \n          alternative = \"two.sided\", mu = 0,conf.level = 0.95)\n\n\n#the parameters needed to run a Z-test are self-explanatory, similar to the one-sample test. x would indicate the data for the drug and y the data for the placebo. In this case, we are testing a two-tail hypothesis."},{"path":"two-sample-tests.html","id":"the-two-sample-t-test-by-hand","chapter":"11 Two sample tests","heading":"The two-sample T-test by hand","text":"perform Two-Sample t-test want compare mean two samples, sample sizes smaller 30.\nFigure 11.5: T-test fucntion two samples\nLets try example.Historically, males scored 15 points girls given exam. standard deviations exists. test true today, researcher performed test 10 males 10 females found males scored 630.1 average (+/- 13.42SD) females 606.8 (+/- 13.14 SD). wants test significance conclusion \\(\\alpha\\) value (significance level) 0.05.Let’s start stating hypotheses:H0: Men scores -(minus) Female scores <= 15, null hypothesis complement alternative hypothesis, set one firstH1: Men scores-Female scores > 15 question interest males get 15 points females. difference male female scores larger 15 points.test use?. Well sample size smaller 30, need use T-Test.calculations, lets start visualizing data:Lets calculate T-score comparing two samples:Next, look t-critical value t-table 18 degrees freedom. case two sample t-test, degrees freedoms equal sample size one plus sample size two minus two) level significance \\(\\alpha\\) 0.05 (looking one tail test, alternative hypothesis states one mean larger ).\nFigure 11.6: R-results one-sample z-test\ncritical t-Score 1.734.Since calculated t-value (.e., 1.397465) smaller critical t-value (1.734), fail reject null hypothesis. Males doe get 15 points higher females exam historically.","code":"\nMales_Mean=630.1  \nMales_SDSD=13.42\n\nFemales_Mean=606.8\nFemales_SD=13.14\n\nSimulatedMales<- rnorm(10000,Males_Mean,Males_SDSD)\nSimulatedFemales<- rnorm(10000,Females_Mean,Females_SD)\n\nbreaks = seq(500,700, length.out = 50) #bins for the distribution\n\n#histogram for drug\nMales= hist(SimulatedMales,breaks = breaks,  plot = FALSE)\n\n#histogram for Placebo\nFemales= hist(SimulatedFemales, breaks = breaks,  plot = FALSE)\n\n\n#because you are plotting two distributions, it will be nice to use different colors. and because they likely overlap, you should use semitransparent colors\nLightBlue <- rgb(173,216,230,max = 255, alpha = 100) #the function rgb lets your select one color, and the alpha gives you how tranparent\nDarkRed <- rgb(255,192,203, max = 255, alpha = 95)\n\n\n#lets plot the first distribution\nplot(Males, main=NA,xlim=c(500,700),ylim=c(0, 1500),breaks = breaks, xlab = \"Score test\",ylab = \"Number of people\" ,col=LightBlue)\n\n#now add the second distribution to the first plot, using the parameter add=TRUE, or add=T, they are both the same\nplot(Females, add=T ,col=DarkRed)\nMales_Mean=630.1  \nMales_SDSD=13.42\n\nFemales_Mean=606.8\nFemales_SD=13.14\n\nSampleSize= 10  #we can use this variable for both males and females, since in both cases 10 people were analyzed\n\n \nT_Score_Numerator= (Males_Mean-Females_Mean) -15  #because we assume that males score 15 point more, we need to assume that the difference between the population means is 15 points\n\nT_Score_denominator= sqrt(((Males_SDSD^2)/SampleSize)+((Females_SD^2)/SampleSize))\n                          \nT_score=T_Score_Numerator/T_Score_denominator\nT_score## [1] 1.397465"},{"path":"two-sample-tests.html","id":"the-two-sample-t-test-in-r","chapter":"11 Two sample tests","heading":"The two-sample T-test in R","text":"can run T-test R, using package BSDA, function tsum.test. Lets try .\nFigure 11.7: R-results two-sample T-test\n","code":"\nlibrary (\"BSDA\")           #load the library\nMales_Mean=630.1  \nMales_SDSD=13.42\n\nFemales_Mean=606.8\nFemales_SD=13.14\n\nSampleSize= 10\n\ntsum.test(mean.x=Males_Mean, s.x = Males_SDSD, n.x = SampleSize,\n          mean.y=Females_Mean, s.y = Females_SD, n.y = SampleSize,\n          alternative = \"greater\", mu = 15, conf.level = 0.95)\n\n\n#the parameters needed to run a T-test are self-explanatory. x parameters would be for males and y parameters for females, mu is the expected difference between the population means, which we know from the example is 15 score points"},{"path":"two-sample-tests.html","id":"homework-8","chapter":"11 Two sample tests","heading":"Homework","text":"problems :State null alternative hypothesis.one tail two-tail test?.Indicate type test use (Z-test T-test).Run given test R.Report results top publication quality plot.Describe conclusion.Problem 1:\nTwo competing headache remedies claim give fast-acting relief. experiment performed compare mean lengths time required bodily absorption brand brand B headache remedies. lengths time minutes drugs reach specified level blood recorded. Results follow:Brand : Mean time= 21.8 min; sd= 8.7 min; n=500.Brand B: Mean time= 18.9 min; sd= 7.5 min; n=350.two drugs different?. Test significance level 0.05Problem 2:\nconsumer group testing two camp stoves. test heating capacity stove, measures time required bring 2 quarts water 50°F boiling (sea level). following results obtained:Model 1: Mean time = 11.4 min; sd= 2.5 min; n= 10 stoves.Model 2: Mean time = 9.9 min; s2=3.0 min; n=12 stoves.Assume time required bring water boil normally distributed stove. difference performances two models? Use 5% level significance.","code":""},{"path":"multiple-sample-test.html","id":"multiple-sample-test","chapter":"12 Multiple sample test","heading":"12 Multiple sample test","text":"chapter describes mathematical approach check differences among two independent groups, -call ANOVA, Analysis Variance. Although name technique refers variances, main goal ANOVA investigate differences among means.numerous ways can look differences among groups, determine type ANOVA use. Lets check examples, clarify distinctions.Say International Olympic Association wants endorse energy drink athletes two different companies send samples products.first order question drinks make difference endurance athletes. can compare, say times running 100m groups athletes given two types drinks control given water. case, want test, least one three groups different, case, use call one-way ANOVA. one factor, drink type.\nFigure 12.1: One-Way ANOVA\nSay, however, also interested knowing effect varies men females. case, two factors need know effect drink effect gender. type cases, use called two-way ANOVA.two factors (drink type gender).\nFigure 12.2: Two-Way ANOVA\nnow want check effect drinks among different types sports, now third factor (sport type), use three-way ANOVA, three factors: drink type, gender, sport type.course, study one-way ANOVAS. also aware run ANOVA need test different key assumptions, study later chapter.data normally distributed. mentioned earlier, assumption key types parametric tests. Basically, need know data follows bell shape, can approximate distribution data.data normally distributed. mentioned earlier, assumption key types parametric tests. Basically, need know data follows bell shape, can approximate distribution data.variances among different groups homogeneous, -call homogeneity variance. learn soon, ANOVA based ratio variance groups variance within groups. variances non homogeneous among groups bias ANOVA test.variances among different groups homogeneous, -call homogeneity variance. learn soon, ANOVA based ratio variance groups variance within groups. variances non homogeneous among groups bias ANOVA test.observations independent.observations independent.outliers present.outliers present.end chapter, expected :Run ANOVA R, interpret results.Run ANOVA R, interpret results.Run post-hoc test, identify differences among specific pairs groups.Run post-hoc test, identify differences among specific pairs groups.","code":""},{"path":"multiple-sample-test.html","id":"anova-reasoning","chapter":"12 Multiple sample test","heading":"ANOVA reasoning","text":"Take moment check video explaining calculate ANOVA hand…get deep mathematical equations, learn overall idea testing significant differences among groups.comparing different groups observations, can divide variance data three different ways:better visualize approach, keep sum squares degrees freedom separated component.Total variance: Total Sum Squares (SSt), forget observations belong group, simply add difference, observation grand mean, squared. total degrees freedom (DFt) total number observations minus one.\nFigure 12.3: Total Sum Squares (SSt) total degrees freedom (DFt)\ntotal variance can now divided variance occurs among groups:\nFigure 12.4: within group variance\ngroups variance: Sum Squares groups (SSb) summation difference, group mean grand mean, squared multiplied number observations group (Formula ). group degrees freedom (DFb) total number groups minus one. case, obtaining information groups.\nFigure 12.5: group variance degrees freedom, DF\nWithin groups variance: Sum Squares within groups (SSw) summation difference, observation group mean group, squared. within group degrees freedom (DFw) total number observations (n) minus total number groups (k).\nFigure 12.6: Within group variance degrees freedom, DF\ntake within group variance within group degrees freedom add , get total variance total degrees freedom.idea behind ANOVA estimate ration variance groups variance within groups, also called F-statistics, Sir Ronald . Fisher, came idea back 1920s.\nFigure 12.7: F-statistics ratio group variance within group variance\ndivide variance groups variance within groups, resulting F-value smaller one, indicates significant differences means samples compared.However, higher ratio implies variation among group means greatly different compared variation individual observations group. variance groups larger variance within groups, means likely different.said likely different, still get F-critical value, indicate extreme F-value calcualted.","code":""},{"path":"multiple-sample-test.html","id":"anova-by-hand","chapter":"12 Multiple sample test","heading":"ANOVA by hand","text":"Lets run ANOVA hand.Say farmer interested finding differences three available varieties tomatoes. numbers tomatoes three varieties:Variety = 3, 2, 1Variety B = 5, 3, 4Variety C = 5, 6, 7","code":""},{"path":"multiple-sample-test.html","id":"stating-hyphotheses","chapter":"12 Multiple sample test","heading":"Stating Hyphotheses","text":"start stating hypothesesHo: Mean Variety = Mean Variety B = Mean Variety CHa: Mean Variety \\(\\neq\\) Mean Variety B \\(\\neq\\) Mean Variety CLets test hypotheses using level significance, \\(\\alpha\\), 0.05.","code":""},{"path":"multiple-sample-test.html","id":"total-variance","chapter":"12 Multiple sample test","heading":"Total variance","text":"Next calculate total variance:\nFigure 12.8: Total variance degrees freedom, DF\n","code":""},{"path":"multiple-sample-test.html","id":"between-group-variance","chapter":"12 Multiple sample test","heading":"Between group variance","text":"Next calculate variance groups. words, group mean differs grand mean:\nFigure 12.9: group variance degrees freedom, DF\n","code":""},{"path":"multiple-sample-test.html","id":"within-group-variance","chapter":"12 Multiple sample test","heading":"Within group variance","text":"Next calculate within group variance. Basically, observation differs group mean.\nFigure 12.10: Within group variance degrees freedom, DF\n","code":""},{"path":"multiple-sample-test.html","id":"variance-partitioning","chapter":"12 Multiple sample test","heading":"Variance partitioning","text":"indicated earlier, within group variance degrees freedom add total variance total degrees freedom. Lets check putting results together:\nFigure 12.11: Within group Sums Aquares degrees freedom, DF\n","code":""},{"path":"multiple-sample-test.html","id":"f-statistics","chapter":"12 Multiple sample test","heading":"F-Statistics","text":"F-statistics simply ratio group within group variance.\nFigure 12.12: F-Statistic\n, F-statistic 12. fact larger one provides good hints significant. still need find given degrees freedoms, number groups level significance (\\(\\alpha\\)), critical F-Value.calculated F-value larger, reject null hypothesis conclude indeed significant differences…drill done .","code":""},{"path":"multiple-sample-test.html","id":"critical-f-value","chapter":"12 Multiple sample test","heading":"Critical F-value","text":"last step ANOVA find critical F-Value, get F-table given \\(\\alpha\\). tables available statistics books online (Example . )need select specific table given (\\(\\alpha\\)), columns represent degrees freedom, rows within group degrees freedom. case, degrees freedom 2, within group degrees freedoms 6.\nFigure 12.13: Within group variance degrees freedom, DF\ninterception column DF=2 row DF= 6, cell 5.1433, critical F-statistics.Just remember, calculated F-statistics 12, much larger critical F-statistics \\(\\alpha\\) 0.05, 5.1433.Thus, reject null hypothesis conclude indeed significant differences amount tomatoes produced three varieties level significance 0.05.","code":""},{"path":"multiple-sample-test.html","id":"ploting-the-data","chapter":"12 Multiple sample test","heading":"Ploting the data","text":"always case, visualize data. case, box plot effective visualization tool.Boxplots allow visualize mean standard deviations group. plot , can see clearly mean tomato production three varieties different, variances overlap.","code":"\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix) # we load this libraries, which we use to sumamrise the results\n\n#We start by putting the data in a dataframe, which two columns. one for the variety type, and the other for the number of tomatoes \nData=data.frame(Variety=c(rep(\"VarA\",3),rep(\"VarB\",3),rep(\"VarC\",3)), NumTomatoes=c(1,2,3, 3,4,5, 5,6,7))\n\nggboxplot(Data, x = \"Variety\", y = \"NumTomatoes\")"},{"path":"multiple-sample-test.html","id":"anova-in-r","chapter":"12 Multiple sample test","heading":"ANOVA in R","text":"numerous R-packages allow run ANOVAs, lets try couple:\nFigure 12.14: Anova R using anova_test\ncan also run ANOVA R using aov function, part default functions R.\nFigure 12.15: Anova R using aov\ncan see different set results aov function, using summary function.\nFigure 12.16: Anova R using aov\n","code":"\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix) # we load this libraries, which we use to sumamrise the results\n\n#We start by putting the data in a dataframe, which two columns. one for the variety type, and the other for the number of tomatoes \nData=data.frame(Variety=c(rep(\"VarA\",3),rep(\"VarB\",3),rep(\"VarC\",3)), NumTomatoes=c(1,2,3, 3,4,5, 5,6,7))\n\n#The ANOVA function is anova_test, which simply requires the response variable (number of tomatoes in our case) equal to the independent variable or factor (Variety of tomatoes in our case)\nres.aov <- Data %>% anova_test(NumTomatoes ~ Variety)\nData=data.frame(Variety=c(rep(\"VarA\",3),rep(\"VarB\",3),rep(\"VarC\",3)), NumTomatoes=c(1,2,3, 3,4,5, 5,6,7))\n\naovAnova <- aov(NumTomatoes ~ Variety, data = Data)\nData=data.frame(Variety=c(rep(\"VarA\",3),rep(\"VarB\",3),rep(\"VarC\",3)), NumTomatoes=c(1,2,3, 3,4,5, 5,6,7))\n\naovAnova <- aov(NumTomatoes ~ Variety, data = Data)\nsummary(aovAnova)"},{"path":"multiple-sample-test.html","id":"post-hoc-test-in-r","chapter":"12 Multiple sample test","heading":"Post-hoc test in R","text":"significant one-way ANOVA means least one group means different ones. ones different?.find , need run called post-hoc test, basically compares possible pair-wise comparisons find , ones different.R, can run post-hoc test R function: tukey_hsd() [packgae rstatix].Lets try:comparison, can tell significant differences Variety Variety C . Cool, ah?.looking plot, one concluded different. look actual data, see variety B, data common varieties C, given small sample size, led pairs similar.","code":"\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(rstatix) # we load this libraries, which we use to sumamrise the results\n\n#We start by putting the data in a dataframe, which two columns. one for the variety type, and the other for the number of tomatoes \nData=data.frame(Variety=c(rep(\"VarA\",3),rep(\"VarB\",3),rep(\"VarC\",3)), NumTomatoes=c(1,2,3, 3,4,5, 5,6,7))\n\npwc <- Data %>% tukey_hsd(NumTomatoes ~ Variety) #PairWise Comparisons\npwc## # A tibble: 3 x 9\n##   term    group1 group2 null.value estimate conf.low conf.high   p.adj\n## * <chr>   <chr>  <chr>       <dbl>    <dbl>    <dbl>     <dbl>   <dbl>\n## 1 Variety VarA   VarB            0        2   -0.505      4.51 0.109  \n## 2 Variety VarA   VarC            0        4    1.49       6.51 0.00649\n## 3 Variety VarB   VarC            0        2   -0.505      4.51 0.109  \n## # ... with 1 more variable: p.adj.signif <chr>"},{"path":"multiple-sample-test.html","id":"checking-assumptions","chapter":"12 Multiple sample test","heading":"Checking assumptions","text":"Perhaps first step ANOVA test different assumptions. decided leave last chapter, get understand ANOVA meant first.","code":""},{"path":"multiple-sample-test.html","id":"outliers-1","chapter":"12 Multiple sample test","heading":"Outliers","text":"Outliers can easily identified using box plot method used early spotted mathematically R function identify_outliers() [rstatix package].result function yields zero rows meaning outliers database. outlier, recommended run analysis without , see level effect make judgment call whether remove now, justify choice make.","code":"\nData %>%  group_by(Variety) %>% identify_outliers(NumTomatoes)## [1] Variety     NumTomatoes is.outlier  is.extreme \n## <0 rows> (or 0-length row.names)"},{"path":"multiple-sample-test.html","id":"normality","chapter":"12 Multiple sample test","heading":"Normality","text":"normality assumption can checked using one following two approaches:Analyzing ANOVA model residuals check normality groups together. approach easier ’s handy many groups data points per group.check normality model residuals, use QQ plot Shapiro-Wilk test. QQ plot draws correlation given data normal distribution.plot abive, can see values within confidence limits expected normality, deviations occurred. data perfectly normal, point falls along normality line (black line plot ).second method check normality uses Shapiro-Wilk test. approach might used groups many data points per group.analysis reveals data used -normally distributed. specific case, small sample size. deviation affect results significantly. Commonly, however, transform data (e.g., applying log function value) normalize data. Different data transformations vailable, need run, tested normality, running ANOVA.","code":"\n# Build the linear model\nmodel  <- lm(NumTomatoes ~ Variety, data = Data)\n# Create a QQ plot of residuals\nggqqplot(residuals(model))\n# Build the linear model\nmodel  <- lm(NumTomatoes ~ Variety, data = Data)\n# run the Shapiro test\nshapiro_test(residuals(model))## # A tibble: 1 x 3\n##   variable         statistic p.value\n##   <chr>                <dbl>   <dbl>\n## 1 residuals(model)     0.823  0.0373"},{"path":"multiple-sample-test.html","id":"homogneity-of-variance","chapter":"12 Multiple sample test","heading":"Homogneity of variance","text":"Homogeneity variance can checked plotting residuals versus fits valued.plot , evident relationships residuals fitted values (mean groups), good. , can assume homogeneity variances.One can also use Levene’s test check homogeneity variances:output , can see p-value > 0.05, significant. means , significant difference variances across groups. Therefore, can assume homogeneity variances different treatment groups.","code":"\nplot(model, 1)\nData %>% levene_test(NumTomatoes ~ Variety)## # A tibble: 1 x 4\n##     df1   df2 statistic     p\n##   <int> <int>     <dbl> <dbl>\n## 1     2     6  4.62e-33     1"},{"path":"multiple-sample-test.html","id":"homework-9","chapter":"12 Multiple sample test","heading":"Homework","text":"problem :State null alternative hypothesis.Indicate type test use.Test assumptions outliers, normality homogeneity variances.Run ANOVA R.Run post-hoc test.Report results top publication quality plot.Describe conclusion.Problem:\nresearcher grown plants ambient CO2, two CO2 treatments increased CO2 50ppm (Treatment1) 100ppm (Treatment2). weight plants grams :Control = 4.81, 4.17, 4.41, 3.59, 5.87, 3.83, 6.03, 4.89, 4.32, 4.69Treatment1 = 4.17, 5.58, 5.18, 6.11, 4.5, 4.61, 5.17, 4.53, 5.33, 5.14Treatment2 = 6.31, 5.12, 5.54, 5.5, 5.37, 5.29, 4.92, 6.15, 5.8, 5.26Test significant differences among three groups using significant level 0.05.","code":""},{"path":"final-project.html","id":"final-project","chapter":"13 Final project","heading":"13 Final project","text":"start book, told collect tokens (letters located belong) dispersed throughout book.motivation collect data along book, face realities data collection, like doubting observation correct , test methodical collect data, run analysis, critically ensure read entire book.Now database tokens following:Search explain knowing frequency letters may importance?Search explain knowing frequency letters may importance?Plot frequency distribution tokens.Plot frequency distribution tokens.Test frequent letter significantly different. question left broad vague set question way desire.Test frequent letter significantly different. question left broad vague set question way desire.thinking question, realize may elements answer specific question may want, may need collect extra data answer questions want part reality scientific process, need become resourceful ask question data, extra data can easily collected.Indicate test run, report given test statistics, critical value, p-value. Test significance level 0.05.student aiming get + class deliver work, student need get extra credit better grade.WARNING: Sharing tokens considered cheating, reported ethical violations evidence suggest tokens shared. share tokens.","code":""}]
